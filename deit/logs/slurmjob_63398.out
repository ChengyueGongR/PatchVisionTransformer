Sat Jan  2 18:29:29 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 410.129      Driver Version: 410.129      CUDA Version: 10.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |
| N/A   39C    P0   140W / 300W |   8932MiB / 32480MiB |     19%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla V100-SXM2...  On   | 00000000:07:00.0 Off |                    0 |
| N/A   54C    P0   228W / 300W |   4956MiB / 32480MiB |     97%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla V100-SXM2...  On   | 00000000:0A:00.0 Off |                    0 |
| N/A   54C    P0   149W / 300W |   4962MiB / 32480MiB |     71%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla V100-SXM2...  On   | 00000000:0B:00.0 Off |                    0 |
| N/A   44C    P0   136W / 300W |   4960MiB / 32480MiB |     86%      Default |
+-------------------------------+----------------------+----------------------+
|   4  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |
| N/A   51C    P0   162W / 300W |   4954MiB / 32480MiB |     80%      Default |
+-------------------------------+----------------------+----------------------+
|   5  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |
| N/A   35C    P0    45W / 300W |      0MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   6  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |
| N/A   35C    P0    46W / 300W |      0MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   7  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |
| N/A   32C    P0    44W / 300W |      0MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0     59541      C   python                                      8927MiB |
|    1      1475      C   /u/yzhao/miniconda3/bin/python3             4945MiB |
|    2      1476      C   /u/yzhao/miniconda3/bin/python3             4951MiB |
|    3      1477      C   /u/yzhao/miniconda3/bin/python3             4949MiB |
|    4      1478      C   /u/yzhao/miniconda3/bin/python3             4943MiB |
+-----------------------------------------------------------------------------+
top - 18:29:30 up 16 days,  7:03,  0 users,  load average: 44.27, 47.85, 46.49
Tasks: 955 total,  10 running, 453 sleeping,   0 stopped,   0 zombie
%Cpu(s): 31.4 us,  3.5 sy,  0.0 ni, 64.2 id,  0.8 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem : 52826339+total,  6155480 free, 26215488 used, 49589241+buff/cache
KiB Swap:        0 total,        0 free,        0 used. 49745724+avail Mem 

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
59541 yzp12     20   0 24.032g 2.889g 193340 R  1300  0.6 107290:00 python tra+
 2789 yzhao     20   0 24.160g 657948 146588 R 438.1  0.1  86:30.53 /u/yzhao/m+
 2267 yzhao     20   0 24.273g 621244 146492 S 419.0  0.1  82:57.26 /u/yzhao/m+
 2266 yzhao     20   0 24.257g 644988 147040 R 414.3  0.1  85:47.72 /u/yzhao/m+
 2264 yzhao     20   0 24.196g 597280 149936 R 357.1  0.1  85:43.32 /u/yzhao/m+
 2790 yzhao     20   0 24.263g 615624 147792 S 352.4  0.1  83:36.77 /u/yzhao/m+
 2265 yzhao     20   0 24.249g 604196 146564 S 328.6  0.1  86:23.31 /u/yzhao/m+
 2787 yzhao     20   0 24.271g 617416 147436 S 304.8  0.1  83:21.84 /u/yzhao/m+
 2788 yzhao     20   0 24.233g 601076 146472 R 300.0  0.1  85:06.54 /u/yzhao/m+
 1475 yzhao     20   0 33.740g 3.147g 597580 R 100.0  0.6  45:09.12 /u/yzhao/m+
 1476 yzhao     20   0 33.654g 3.139g 593744 R 100.0  0.6  45:10.18 /u/yzhao/m+
 1477 yzhao     20   0 33.662g 3.148g 599272 R 100.0  0.6  45:09.63 /u/yzhao/m+
 1478 yzhao     20   0 33.660g 3.144g 601280 R  95.2  0.6  45:09.68 /u/yzhao/m+
 4045 yzhao     20   0 24.158g 605864 147096 S  42.9  0.1  82:28.01 /u/yzhao/m+
60603 cygong    20   0   39860   4164   2904 R  23.8  0.0   0:00.11 top -bn 1 +
 1377 root       0 -20       0      0      0 I   4.8  0.0   0:21.92 [kworker/3+
10823 root      20   0       0      0      0 I   4.8  0.0   0:00.81 [kworker/7+
17737 root      20   0       0      0      0 I   4.8  0.0   0:00.53 [kworker/5+
35163 root       0 -20       0      0      0 I   4.8  0.0   1:12.78 [kworker/1+
77896 root       0 -20       0      0      0 I   4.8  0.0   5:19.29 [kworker/3+
77960 root       0 -20       0      0      0 I   4.8  0.0   0:16.79 [kworker/2+
Processing /u/cygong/Desktop/timm_mlp
Requirement already satisfied: torch>=1.0 in /u/cygong/anaconda/envs/dgx/lib/python3.8/site-packages (from timm==0.3.2) (1.7.1)
Requirement already satisfied: torchvision in /u/cygong/anaconda/envs/dgx/lib/python3.8/site-packages (from timm==0.3.2) (0.8.2)
Requirement already satisfied: typing_extensions in /u/cygong/anaconda/envs/dgx/lib/python3.8/site-packages (from torch>=1.0->timm==0.3.2) (3.7.4.3)
Requirement already satisfied: numpy in /u/cygong/anaconda/envs/dgx/lib/python3.8/site-packages (from torch>=1.0->timm==0.3.2) (1.19.2)
Requirement already satisfied: pillow>=4.1.1 in /u/cygong/anaconda/envs/dgx/lib/python3.8/site-packages (from torchvision->timm==0.3.2) (8.0.1)
Building wheels for collected packages: timm
  Building wheel for timm (setup.py): started
  Building wheel for timm (setup.py): finished with status 'done'
  Created wheel for timm: filename=timm-0.3.2-py3-none-any.whl size=240805 sha256=a1cd59493606b5d43680a3c2b5db393f37c864b7402a10c13d379fc195d62d7e
  Stored in directory: /tmp/pip-ephem-wheel-cache-3ugdh5qn/wheels/7c/92/4d/f70b9c15c01aed89852b0201dd28cb5d80a328aa9b8459f535
Successfully built timm
Installing collected packages: timm
  Attempting uninstall: timm
    Found existing installation: timm 0.3.2
    Uninstalling timm-0.3.2:
      Successfully uninstalled timm-0.3.2
Successfully installed timm-0.3.2
| distributed init (rank 2): env://
| distributed init (rank 1): env://
| distributed init (rank 0): env://
Namespace(aa='rand-m9-mstd0.5-inc1', batch_size=340, clip_grad=None, color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='/scratch/cluster/dilin/datasets/imagenet', data_set='IMNET', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, drop=0.0, drop_block=None, drop_path=0.1, epochs=300, eval=False, gpu=0, inat_category='name', input_size=224, lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model='deit_small_patch16_224', model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, momentum=0.9, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='/scratch/cluster/cygong/vision_transformer_small_coefficient', patience_epochs=10, pin_mem=True, rank=0, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='/scratch/cluster/cygong/vision_transformer_small_coefficient/checkpoint.pth', sched='cosine', seed=0, smoothing=0.1, start_epoch=0, train_interpolation='bicubic', warmup_epochs=5, warmup_lr=1e-06, weight_decay=0.05, world_size=3)
Creating model: deit_small_patch16_224
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (blocks): ModuleList(
    (0): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_post): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp1): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp2): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp3): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre3): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
    )
    (1): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_post): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp1): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp2): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp3): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre3): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
    )
    (2): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_post): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp1): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp2): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp3): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre3): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
    )
    (3): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_post): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp1): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp2): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp3): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre3): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
    )
    (4): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_post): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp1): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp2): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp3): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre3): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
    )
    (5): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_post): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp1): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp2): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp3): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre3): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
    )
    (6): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_post): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp1): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp2): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp3): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre3): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
    )
    (7): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_post): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp1): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp2): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp3): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre3): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
    )
    (8): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_post): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp1): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp2): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp3): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre3): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
    )
    (9): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_post): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp1): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp2): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp3): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre3): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
    )
    (10): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_post): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp1): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp2): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp3): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre3): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
    )
    (11): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_post): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp1): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp2): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp3): Mlp(
        (fc1): Linear(in_features=384, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=384, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (norm_pre3): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
    )
  )
  (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
  (head): Linear(in_features=384, out_features=1000, bias=True)
)
number of params: 22147432
Warning: module PatchEmbed is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module LayerNorm is treated as a zero-op.
Warning: module Attention is treated as a zero-op.
Warning: module Identity is treated as a zero-op.
Warning: module GELU is treated as a zero-op.
Warning: module Mlp is treated as a zero-op.
Warning: module Block is treated as a zero-op.
Warning: module DropPath is treated as a zero-op.
Warning: module VisionTransformer is treated as a zero-op.
Warning: module DistributedDataParallel is treated as a zero-op.
DistributedDataParallel(
  22.015 M, 99.404% Params, 4.25 GMac, 100.000% MACs, 
  (module): VisionTransformer(
    22.015 M, 99.404% Params, 4.25 GMac, 100.000% MACs, 
    (patch_embed): PatchEmbed(
      0.295 M, 1.333% Params, 0.058 GMac, 1.362% MACs, 
      (proj): Conv2d(0.295 M, 1.333% Params, 0.058 GMac, 1.362% MACs, 3, 384, kernel_size=(16, 16), stride=(16, 16))
    )
    (pos_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
    (blocks): ModuleList(
      21.335 M, 96.332% Params, 4.192 GMac, 98.629% MACs, 
      (0): Block(
        1.778 M, 8.028% Params, 0.349 GMac, 8.219% MACs, 
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          0.591 M, 2.670% Params, 0.116 GMac, 2.734% MACs, 
          (qkv): Linear(0.444 M, 2.003% Params, 0.087 GMac, 2.050% MACs, in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
          (proj): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (drop_path): Identity(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_post): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp1): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp2): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp3): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (conv): Conv2d(0.004 M, 0.017% Params, 0.001 GMac, 0.018% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
      )
      (1): Block(
        1.778 M, 8.028% Params, 0.349 GMac, 8.219% MACs, 
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          0.591 M, 2.670% Params, 0.116 GMac, 2.734% MACs, 
          (qkv): Linear(0.444 M, 2.003% Params, 0.087 GMac, 2.050% MACs, in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
          (proj): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_post): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp1): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp2): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp3): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (conv): Conv2d(0.004 M, 0.017% Params, 0.001 GMac, 0.018% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
      )
      (2): Block(
        1.778 M, 8.028% Params, 0.349 GMac, 8.219% MACs, 
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          0.591 M, 2.670% Params, 0.116 GMac, 2.734% MACs, 
          (qkv): Linear(0.444 M, 2.003% Params, 0.087 GMac, 2.050% MACs, in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
          (proj): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_post): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp1): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp2): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp3): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (conv): Conv2d(0.004 M, 0.017% Params, 0.001 GMac, 0.018% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
      )
      (3): Block(
        1.778 M, 8.028% Params, 0.349 GMac, 8.219% MACs, 
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          0.591 M, 2.670% Params, 0.116 GMac, 2.734% MACs, 
          (qkv): Linear(0.444 M, 2.003% Params, 0.087 GMac, 2.050% MACs, in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
          (proj): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_post): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp1): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp2): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp3): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (conv): Conv2d(0.004 M, 0.017% Params, 0.001 GMac, 0.018% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
      )
      (4): Block(
        1.778 M, 8.028% Params, 0.349 GMac, 8.219% MACs, 
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          0.591 M, 2.670% Params, 0.116 GMac, 2.734% MACs, 
          (qkv): Linear(0.444 M, 2.003% Params, 0.087 GMac, 2.050% MACs, in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
          (proj): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_post): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp1): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp2): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp3): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (conv): Conv2d(0.004 M, 0.017% Params, 0.001 GMac, 0.018% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
      )
      (5): Block(
        1.778 M, 8.028% Params, 0.349 GMac, 8.219% MACs, 
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          0.591 M, 2.670% Params, 0.116 GMac, 2.734% MACs, 
          (qkv): Linear(0.444 M, 2.003% Params, 0.087 GMac, 2.050% MACs, in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
          (proj): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_post): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp1): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp2): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp3): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (conv): Conv2d(0.004 M, 0.017% Params, 0.001 GMac, 0.018% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
      )
      (6): Block(
        1.778 M, 8.028% Params, 0.349 GMac, 8.219% MACs, 
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          0.591 M, 2.670% Params, 0.116 GMac, 2.734% MACs, 
          (qkv): Linear(0.444 M, 2.003% Params, 0.087 GMac, 2.050% MACs, in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
          (proj): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_post): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp1): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp2): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp3): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (conv): Conv2d(0.004 M, 0.017% Params, 0.001 GMac, 0.018% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
      )
      (7): Block(
        1.778 M, 8.028% Params, 0.349 GMac, 8.219% MACs, 
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          0.591 M, 2.670% Params, 0.116 GMac, 2.734% MACs, 
          (qkv): Linear(0.444 M, 2.003% Params, 0.087 GMac, 2.050% MACs, in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
          (proj): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_post): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp1): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp2): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp3): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (conv): Conv2d(0.004 M, 0.017% Params, 0.001 GMac, 0.018% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
      )
      (8): Block(
        1.778 M, 8.028% Params, 0.349 GMac, 8.219% MACs, 
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          0.591 M, 2.670% Params, 0.116 GMac, 2.734% MACs, 
          (qkv): Linear(0.444 M, 2.003% Params, 0.087 GMac, 2.050% MACs, in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
          (proj): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_post): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp1): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp2): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp3): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (conv): Conv2d(0.004 M, 0.017% Params, 0.001 GMac, 0.018% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
      )
      (9): Block(
        1.778 M, 8.028% Params, 0.349 GMac, 8.219% MACs, 
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          0.591 M, 2.670% Params, 0.116 GMac, 2.734% MACs, 
          (qkv): Linear(0.444 M, 2.003% Params, 0.087 GMac, 2.050% MACs, in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
          (proj): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_post): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp1): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp2): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp3): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (conv): Conv2d(0.004 M, 0.017% Params, 0.001 GMac, 0.018% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
      )
      (10): Block(
        1.778 M, 8.028% Params, 0.349 GMac, 8.219% MACs, 
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          0.591 M, 2.670% Params, 0.116 GMac, 2.734% MACs, 
          (qkv): Linear(0.444 M, 2.003% Params, 0.087 GMac, 2.050% MACs, in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
          (proj): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_post): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp1): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp2): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp3): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (conv): Conv2d(0.004 M, 0.017% Params, 0.001 GMac, 0.018% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
      )
      (11): Block(
        1.778 M, 8.028% Params, 0.349 GMac, 8.219% MACs, 
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          0.591 M, 2.670% Params, 0.116 GMac, 2.734% MACs, 
          (qkv): Linear(0.444 M, 2.003% Params, 0.087 GMac, 2.050% MACs, in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
          (proj): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_post): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp1): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp2): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (mlp3): Mlp(
          0.296 M, 1.335% Params, 0.058 GMac, 1.367% MACs, 
          (fc1): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (act): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
          (fc2): Linear(0.148 M, 0.668% Params, 0.029 GMac, 0.683% MACs, in_features=384, out_features=384, bias=True)
          (drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.0, inplace=False)
        )
        (norm_pre3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
        (conv): Conv2d(0.004 M, 0.017% Params, 0.001 GMac, 0.018% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
      )
    )
    (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (384,), eps=1e-06, elementwise_affine=True)
    (head): Linear(0.385 M, 1.738% Params, 0.0 GMac, 0.009% MACs, in_features=384, out_features=1000, bias=True)
  )
)
('4.25 GMac', '22.15 M')
3
Start training
Epoch: [48]  [   0/1255]  eta: 4:45:22  lr: 0.001250  loss: 5.1613 (5.1613)  time: 13.6438  data: 8.9191  max mem: 28523
Epoch: [48]  [ 100/1255]  eta: 0:29:57  lr: 0.001250  loss: 4.4894 (4.2874)  time: 1.4118  data: 0.0003  max mem: 28602
Epoch: [48]  [ 200/1255]  eta: 0:26:08  lr: 0.001250  loss: 3.9485 (4.2060)  time: 1.4231  data: 0.0004  max mem: 28602
Epoch: [48]  [ 300/1255]  eta: 0:23:16  lr: 0.001250  loss: 3.8252 (4.1406)  time: 1.4064  data: 0.0003  max mem: 28602
Epoch: [48]  [ 400/1255]  eta: 0:20:40  lr: 0.001250  loss: 4.2193 (4.1540)  time: 1.4239  data: 0.0003  max mem: 28602
Epoch: [48]  [ 500/1255]  eta: 0:18:11  lr: 0.001250  loss: 4.2163 (4.1475)  time: 1.4168  data: 0.0003  max mem: 28602
Epoch: [48]  [ 600/1255]  eta: 0:15:44  lr: 0.001250  loss: 4.4790 (4.1561)  time: 1.4040  data: 0.0004  max mem: 28602
Epoch: [48]  [ 700/1255]  eta: 0:13:18  lr: 0.001250  loss: 3.9775 (4.1476)  time: 1.4400  data: 0.0004  max mem: 28602
Epoch: [48]  [ 800/1255]  eta: 0:10:53  lr: 0.001250  loss: 4.1663 (4.1495)  time: 1.4103  data: 0.0003  max mem: 28602
Epoch: [48]  [ 900/1255]  eta: 0:08:28  lr: 0.001250  loss: 4.2049 (4.1321)  time: 1.4094  data: 0.0003  max mem: 28602
Epoch: [48]  [1000/1255]  eta: 0:06:05  lr: 0.001250  loss: 4.2998 (4.1305)  time: 1.4152  data: 0.0003  max mem: 28602
Epoch: [48]  [1100/1255]  eta: 0:03:41  lr: 0.001250  loss: 4.0925 (4.1292)  time: 1.4342  data: 0.0004  max mem: 28602
Epoch: [48]  [1200/1255]  eta: 0:01:18  lr: 0.001250  loss: 4.2924 (4.1372)  time: 1.4133  data: 0.0003  max mem: 28602
Epoch: [48]  [1254/1255]  eta: 0:00:01  lr: 0.001250  loss: 4.0823 (4.1332)  time: 1.3830  data: 0.0006  max mem: 28602
Epoch: [48] Total time: 0:29:53 (1.4295 s / it)
Averaged stats: lr: 0.001250  loss: 4.0823 (4.1219)
Test:  [  0/123]  eta: 0:28:57  loss: 1.0694 (1.0694)  acc1: 75.2451 (75.2451)  acc5: 92.4020 (92.4020)  time: 14.1258  data: 12.4866  max mem: 28602
Test:  [ 10/123]  eta: 0:03:22  loss: 1.0835 (1.1857)  acc1: 74.5098 (72.8832)  acc5: 92.1569 (91.0428)  time: 1.7877  data: 1.2683  max mem: 28602
Test:  [ 20/123]  eta: 0:02:16  loss: 1.0835 (1.1137)  acc1: 74.5098 (74.9066)  acc5: 92.1569 (91.8301)  time: 0.6894  data: 0.2848  max mem: 28602
Test:  [ 30/123]  eta: 0:01:46  loss: 1.2282 (1.1888)  acc1: 71.0784 (72.1300)  acc5: 92.1569 (91.8248)  time: 0.7899  data: 0.3813  max mem: 28602
Test:  [ 40/123]  eta: 0:01:30  loss: 1.2581 (1.1548)  acc1: 68.6275 (72.9376)  acc5: 93.8726 (92.4020)  time: 0.8283  data: 0.4082  max mem: 28602
Test:  [ 50/123]  eta: 0:01:15  loss: 1.0870 (1.1687)  acc1: 74.0196 (72.7268)  acc5: 93.8726 (92.1569)  time: 0.8740  data: 0.4499  max mem: 28602
Test:  [ 60/123]  eta: 0:01:02  loss: 1.4021 (1.2700)  acc1: 62.2549 (70.4998)  acc5: 87.2549 (90.7345)  time: 0.8042  data: 0.3827  max mem: 28602
Test:  [ 70/123]  eta: 0:00:51  loss: 1.7201 (1.3251)  acc1: 61.5196 (69.5699)  acc5: 83.8235 (89.8647)  time: 0.8072  data: 0.3889  max mem: 28602
Test:  [ 80/123]  eta: 0:00:40  loss: 1.8195 (1.3912)  acc1: 61.5196 (68.2886)  acc5: 82.1078 (88.8768)  time: 0.8234  data: 0.4125  max mem: 28602
Test:  [ 90/123]  eta: 0:00:30  loss: 1.8193 (1.4313)  acc1: 58.0882 (67.4154)  acc5: 81.6177 (88.3565)  time: 0.7937  data: 0.3862  max mem: 28602
Test:  [100/123]  eta: 0:00:21  loss: 1.7843 (1.4643)  acc1: 60.2941 (66.7734)  acc5: 84.0686 (87.8276)  time: 0.7774  data: 0.3629  max mem: 28602
Test:  [110/123]  eta: 0:00:11  loss: 1.9032 (1.5017)  acc1: 59.0686 (65.9800)  acc5: 81.3726 (87.3432)  time: 0.8254  data: 0.4124  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.6898 (1.4985)  acc1: 59.8039 (65.9739)  acc5: 85.2941 (87.4291)  time: 0.7986  data: 0.3903  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.6395 (1.4906)  acc1: 61.2745 (66.1260)  acc5: 87.5000 (87.5040)  time: 0.7928  data: 0.3903  max mem: 28602
Test: Total time: 0:01:49 (0.8912 s / it)
* Acc@1 66.126 Acc@5 87.504 loss 1.491
Accuracy of the network on the 50000 test images: 66.1%
Max accuracy: 66.13%
Epoch: [49]  [   0/1255]  eta: 4:23:30  lr: 0.001247  loss: 4.9456 (4.9456)  time: 12.5984  data: 8.8116  max mem: 28602
Epoch: [49]  [ 100/1255]  eta: 0:30:27  lr: 0.001247  loss: 4.3496 (4.1548)  time: 1.4833  data: 0.0004  max mem: 28602
Epoch: [49]  [ 200/1255]  eta: 0:26:34  lr: 0.001247  loss: 4.0678 (4.1779)  time: 1.4221  data: 0.0003  max mem: 28602
Epoch: [49]  [ 300/1255]  eta: 0:23:49  lr: 0.001247  loss: 4.2093 (4.1328)  time: 1.4955  data: 0.0004  max mem: 28602
Epoch: [49]  [ 400/1255]  eta: 0:21:04  lr: 0.001247  loss: 3.4427 (4.1070)  time: 1.4196  data: 0.0003  max mem: 28602
Epoch: [49]  [ 500/1255]  eta: 0:18:29  lr: 0.001247  loss: 3.7251 (4.0980)  time: 1.4626  data: 0.0004  max mem: 28602
Epoch: [49]  [ 600/1255]  eta: 0:16:04  lr: 0.001247  loss: 3.7742 (4.1003)  time: 1.4844  data: 0.0004  max mem: 28602
Epoch: [49]  [ 700/1255]  eta: 0:13:42  lr: 0.001247  loss: 3.8642 (4.0792)  time: 1.4250  data: 0.0003  max mem: 28602
Epoch: [49]  [ 800/1255]  eta: 0:11:10  lr: 0.001247  loss: 4.2032 (4.0787)  time: 1.4172  data: 0.0004  max mem: 28602
Epoch: [49]  [ 900/1255]  eta: 0:08:41  lr: 0.001247  loss: 4.4256 (4.0849)  time: 1.4213  data: 0.0003  max mem: 28602
Epoch: [49]  [1000/1255]  eta: 0:06:13  lr: 0.001247  loss: 3.7086 (4.0775)  time: 1.4417  data: 0.0003  max mem: 28602
Epoch: [49]  [1100/1255]  eta: 0:03:46  lr: 0.001247  loss: 4.0303 (4.0809)  time: 1.4624  data: 0.0003  max mem: 28602
Epoch: [49]  [1200/1255]  eta: 0:01:20  lr: 0.001247  loss: 4.4344 (4.0824)  time: 1.4152  data: 0.0003  max mem: 28602
Epoch: [49]  [1254/1255]  eta: 0:00:01  lr: 0.001247  loss: 3.6073 (4.0768)  time: 1.4461  data: 0.0005  max mem: 28602
Epoch: [49] Total time: 0:30:30 (1.4589 s / it)
Averaged stats: lr: 0.001247  loss: 3.6073 (4.0779)
Test:  [  0/123]  eta: 0:24:01  loss: 0.9525 (0.9525)  acc1: 78.1863 (78.1863)  acc5: 93.8726 (93.8726)  time: 11.7221  data: 11.2826  max mem: 28602
Test:  [ 10/123]  eta: 0:03:24  loss: 1.0677 (1.0866)  acc1: 73.7745 (74.7103)  acc5: 92.8922 (92.2683)  time: 1.8128  data: 1.4007  max mem: 28602
Test:  [ 20/123]  eta: 0:02:17  loss: 1.0677 (1.0707)  acc1: 75.4902 (75.7703)  acc5: 92.8922 (92.4837)  time: 0.8142  data: 0.4052  max mem: 28602
Test:  [ 30/123]  eta: 0:01:45  loss: 1.2108 (1.1249)  acc1: 72.3039 (73.4029)  acc5: 93.1373 (92.7261)  time: 0.7550  data: 0.3404  max mem: 28602
Test:  [ 40/123]  eta: 0:01:30  loss: 1.1666 (1.0952)  acc1: 68.8726 (74.0615)  acc5: 94.3627 (93.1552)  time: 0.8230  data: 0.4034  max mem: 28602
Test:  [ 50/123]  eta: 0:01:15  loss: 1.0952 (1.1182)  acc1: 74.5098 (73.7457)  acc5: 93.8726 (92.8201)  time: 0.8791  data: 0.4536  max mem: 28602
Test:  [ 60/123]  eta: 0:01:02  loss: 1.4872 (1.2336)  acc1: 66.4216 (71.1869)  acc5: 85.7843 (91.2729)  time: 0.7940  data: 0.3712  max mem: 28602
Test:  [ 70/123]  eta: 0:00:51  loss: 1.7186 (1.2880)  acc1: 60.5392 (70.2534)  acc5: 84.0686 (90.5033)  time: 0.8043  data: 0.3924  max mem: 28602
Test:  [ 80/123]  eta: 0:00:40  loss: 1.7426 (1.3545)  acc1: 60.7843 (68.9361)  acc5: 83.0882 (89.5334)  time: 0.8163  data: 0.4062  max mem: 28602
Test:  [ 90/123]  eta: 0:00:30  loss: 1.8072 (1.3948)  acc1: 60.2941 (68.2396)  acc5: 82.3529 (88.8817)  time: 0.7800  data: 0.3648  max mem: 28602
Test:  [100/123]  eta: 0:00:20  loss: 1.7293 (1.4333)  acc1: 62.2549 (67.5718)  acc5: 84.8039 (88.3057)  time: 0.7492  data: 0.3301  max mem: 28602
Test:  [110/123]  eta: 0:00:11  loss: 1.8159 (1.4707)  acc1: 60.7843 (66.7660)  acc5: 82.1078 (87.7782)  time: 0.8132  data: 0.3931  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.5452 (1.4673)  acc1: 61.2745 (66.7659)  acc5: 87.0098 (87.9031)  time: 0.8084  data: 0.3935  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.4703 (1.4605)  acc1: 64.4608 (66.9220)  acc5: 88.3929 (87.9760)  time: 0.7976  data: 0.3935  max mem: 28602
Test: Total time: 0:01:48 (0.8850 s / it)
* Acc@1 66.922 Acc@5 87.976 loss 1.461
Accuracy of the network on the 50000 test images: 66.9%
Max accuracy: 66.92%
Epoch: [50]  [   0/1255]  eta: 3:53:32  lr: 0.001243  loss: 4.8253 (4.8253)  time: 11.1656  data: 8.8493  max mem: 28602
Epoch: [50]  [ 100/1255]  eta: 0:29:28  lr: 0.001243  loss: 3.9927 (4.1535)  time: 1.4089  data: 0.0004  max mem: 28602
Epoch: [50]  [ 200/1255]  eta: 0:25:49  lr: 0.001243  loss: 4.2438 (4.1813)  time: 1.3996  data: 0.0004  max mem: 28602
Epoch: [50]  [ 300/1255]  eta: 0:23:02  lr: 0.001243  loss: 4.1723 (4.1342)  time: 1.4049  data: 0.0003  max mem: 28602
Epoch: [50]  [ 400/1255]  eta: 0:20:26  lr: 0.001243  loss: 4.1802 (4.0820)  time: 1.4016  data: 0.0003  max mem: 28602
Epoch: [50]  [ 500/1255]  eta: 0:17:56  lr: 0.001243  loss: 4.2534 (4.0858)  time: 1.3870  data: 0.0003  max mem: 28602
Epoch: [50]  [ 600/1255]  eta: 0:15:32  lr: 0.001243  loss: 4.2397 (4.0751)  time: 1.4071  data: 0.0003  max mem: 28602
Epoch: [50]  [ 700/1255]  eta: 0:13:09  lr: 0.001243  loss: 4.5005 (4.0727)  time: 1.4066  data: 0.0003  max mem: 28602
Epoch: [50]  [ 800/1255]  eta: 0:10:46  lr: 0.001243  loss: 4.4635 (4.0833)  time: 1.4138  data: 0.0003  max mem: 28602
Epoch: [50]  [ 900/1255]  eta: 0:08:24  lr: 0.001243  loss: 4.1165 (4.0801)  time: 1.4175  data: 0.0003  max mem: 28602
Epoch: [50]  [1000/1255]  eta: 0:06:02  lr: 0.001243  loss: 4.3434 (4.0714)  time: 1.4077  data: 0.0003  max mem: 28602
Epoch: [50]  [1100/1255]  eta: 0:03:40  lr: 0.001243  loss: 4.1009 (4.0734)  time: 1.4166  data: 0.0003  max mem: 28602
Epoch: [50]  [1200/1255]  eta: 0:01:18  lr: 0.001243  loss: 4.0958 (4.0801)  time: 1.4119  data: 0.0003  max mem: 28602
Epoch: [50]  [1254/1255]  eta: 0:00:01  lr: 0.001243  loss: 4.2001 (4.0843)  time: 1.3840  data: 0.0006  max mem: 28602
Epoch: [50] Total time: 0:29:40 (1.4187 s / it)
Averaged stats: lr: 0.001243  loss: 4.2001 (4.0820)
Test:  [  0/123]  eta: 0:24:29  loss: 1.1210 (1.1210)  acc1: 75.7353 (75.7353)  acc5: 92.6471 (92.6471)  time: 11.9464  data: 11.5092  max mem: 28602
Test:  [ 10/123]  eta: 0:03:23  loss: 1.1498 (1.1422)  acc1: 75.7353 (74.5544)  acc5: 92.4020 (92.5802)  time: 1.8030  data: 1.3883  max mem: 28602
Test:  [ 20/123]  eta: 0:02:17  loss: 1.0933 (1.1099)  acc1: 75.4902 (75.8287)  acc5: 92.4020 (92.6587)  time: 0.8023  data: 0.3942  max mem: 28602
Test:  [ 30/123]  eta: 0:01:46  loss: 1.2798 (1.1907)  acc1: 70.0980 (72.7072)  acc5: 92.8922 (92.4573)  time: 0.7751  data: 0.3699  max mem: 28602
Test:  [ 40/123]  eta: 0:01:30  loss: 1.2356 (1.1685)  acc1: 67.8922 (73.4517)  acc5: 92.8922 (92.7965)  time: 0.8311  data: 0.4157  max mem: 28602
Test:  [ 50/123]  eta: 0:01:15  loss: 1.1332 (1.1863)  acc1: 72.7941 (73.0200)  acc5: 92.8922 (92.5317)  time: 0.8737  data: 0.4539  max mem: 28602
Test:  [ 60/123]  eta: 0:01:02  loss: 1.4400 (1.2814)  acc1: 65.9314 (71.1588)  acc5: 85.7843 (91.0760)  time: 0.8049  data: 0.3910  max mem: 28602
Test:  [ 70/123]  eta: 0:00:51  loss: 1.6840 (1.3361)  acc1: 60.5392 (69.9841)  acc5: 84.5588 (90.3307)  time: 0.8140  data: 0.4029  max mem: 28602
Test:  [ 80/123]  eta: 0:00:40  loss: 1.7406 (1.3983)  acc1: 58.5784 (68.7394)  acc5: 83.0882 (89.4063)  time: 0.8246  data: 0.4159  max mem: 28602
Test:  [ 90/123]  eta: 0:00:30  loss: 1.7661 (1.4369)  acc1: 59.0686 (67.9972)  acc5: 83.0882 (88.8494)  time: 0.7949  data: 0.3875  max mem: 28602
Test:  [100/123]  eta: 0:00:21  loss: 1.7661 (1.4727)  acc1: 60.5392 (67.3000)  acc5: 83.0882 (88.2426)  time: 0.7725  data: 0.3686  max mem: 28602
Test:  [110/123]  eta: 0:00:11  loss: 1.8870 (1.5097)  acc1: 60.5392 (66.5121)  acc5: 81.6177 (87.7076)  time: 0.8183  data: 0.4101  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.6754 (1.5087)  acc1: 60.5392 (66.5127)  acc5: 84.8039 (87.7957)  time: 0.7643  data: 0.3521  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.5987 (1.5042)  acc1: 62.2549 (66.6560)  acc5: 87.0098 (87.8400)  time: 0.7561  data: 0.3521  max mem: 28602
Test: Total time: 0:01:48 (0.8849 s / it)
* Acc@1 66.656 Acc@5 87.840 loss 1.504
Accuracy of the network on the 50000 test images: 66.7%
Max accuracy: 66.92%
Epoch: [51]  [   0/1255]  eta: 3:55:07  lr: 0.001240  loss: 4.8792 (4.8792)  time: 11.2414  data: 9.7771  max mem: 28602
Epoch: [51]  [ 100/1255]  eta: 0:29:10  lr: 0.001240  loss: 4.1466 (4.0374)  time: 1.4133  data: 0.0004  max mem: 28602
Epoch: [51]  [ 200/1255]  eta: 0:25:45  lr: 0.001240  loss: 4.1292 (4.0182)  time: 1.4048  data: 0.0003  max mem: 28602
Epoch: [51]  [ 300/1255]  eta: 0:23:02  lr: 0.001240  loss: 4.1465 (4.0467)  time: 1.4102  data: 0.0003  max mem: 28602
Epoch: [51]  [ 400/1255]  eta: 0:20:29  lr: 0.001240  loss: 4.1642 (4.0213)  time: 1.4174  data: 0.0003  max mem: 28602
Epoch: [51]  [ 500/1255]  eta: 0:18:02  lr: 0.001240  loss: 4.2780 (4.0336)  time: 1.4161  data: 0.0003  max mem: 28602
Epoch: [51]  [ 600/1255]  eta: 0:15:36  lr: 0.001240  loss: 4.2476 (4.0262)  time: 1.4146  data: 0.0003  max mem: 28602
Epoch: [51]  [ 700/1255]  eta: 0:13:12  lr: 0.001240  loss: 4.0985 (4.0309)  time: 1.4182  data: 0.0003  max mem: 28602
Epoch: [51]  [ 800/1255]  eta: 0:10:48  lr: 0.001240  loss: 4.4072 (4.0427)  time: 1.4097  data: 0.0003  max mem: 28602
Epoch: [51]  [ 900/1255]  eta: 0:08:25  lr: 0.001240  loss: 4.3071 (4.0518)  time: 1.4127  data: 0.0003  max mem: 28602
Epoch: [51]  [1000/1255]  eta: 0:06:02  lr: 0.001240  loss: 4.2667 (4.0585)  time: 1.4107  data: 0.0003  max mem: 28602
Epoch: [51]  [1100/1255]  eta: 0:03:40  lr: 0.001240  loss: 3.7168 (4.0508)  time: 1.4061  data: 0.0004  max mem: 28602
Epoch: [51]  [1200/1255]  eta: 0:01:18  lr: 0.001240  loss: 4.0947 (4.0511)  time: 1.4134  data: 0.0003  max mem: 28602
Epoch: [51]  [1254/1255]  eta: 0:00:01  lr: 0.001240  loss: 4.2936 (4.0579)  time: 1.3772  data: 0.0008  max mem: 28602
Epoch: [51] Total time: 0:29:41 (1.4198 s / it)
Averaged stats: lr: 0.001240  loss: 4.2936 (4.0592)
Test:  [  0/123]  eta: 0:23:56  loss: 1.1242 (1.1242)  acc1: 73.5294 (73.5294)  acc5: 92.6471 (92.6471)  time: 11.6813  data: 11.2278  max mem: 28602
Test:  [ 10/123]  eta: 0:03:18  loss: 1.1242 (1.1527)  acc1: 73.0392 (74.0865)  acc5: 92.6471 (91.8672)  time: 1.7583  data: 1.3408  max mem: 28602
Test:  [ 20/123]  eta: 0:02:15  loss: 1.1708 (1.1263)  acc1: 73.2843 (75.0467)  acc5: 92.4020 (92.0752)  time: 0.7926  data: 0.3854  max mem: 28602
Test:  [ 30/123]  eta: 0:01:45  loss: 1.2192 (1.1923)  acc1: 71.5686 (72.6992)  acc5: 92.8922 (91.9829)  time: 0.7837  data: 0.3796  max mem: 28602
Test:  [ 40/123]  eta: 0:01:29  loss: 1.2328 (1.1546)  acc1: 68.3824 (73.4935)  acc5: 93.8726 (92.5873)  time: 0.8441  data: 0.4290  max mem: 28602
Test:  [ 50/123]  eta: 0:01:15  loss: 1.1137 (1.1733)  acc1: 75.0000 (73.2170)  acc5: 92.8922 (92.3683)  time: 0.8758  data: 0.4583  max mem: 28602
Test:  [ 60/123]  eta: 0:01:02  loss: 1.4240 (1.2754)  acc1: 67.4020 (70.9981)  acc5: 86.0294 (90.9354)  time: 0.7970  data: 0.3856  max mem: 28602
Test:  [ 70/123]  eta: 0:00:51  loss: 1.7432 (1.3282)  acc1: 60.7843 (69.9910)  acc5: 84.5588 (90.2133)  time: 0.8015  data: 0.3909  max mem: 28602
Test:  [ 80/123]  eta: 0:00:40  loss: 1.7432 (1.3860)  acc1: 61.5196 (68.9361)  acc5: 82.3529 (89.2944)  time: 0.8188  data: 0.4021  max mem: 28602
Test:  [ 90/123]  eta: 0:00:30  loss: 1.7550 (1.4288)  acc1: 61.5196 (68.1049)  acc5: 81.8627 (88.7120)  time: 0.8080  data: 0.3897  max mem: 28602
Test:  [100/123]  eta: 0:00:21  loss: 1.7520 (1.4626)  acc1: 61.5196 (67.5015)  acc5: 83.5784 (88.1407)  time: 0.7772  data: 0.3618  max mem: 28602
Test:  [110/123]  eta: 0:00:11  loss: 1.8458 (1.5004)  acc1: 60.0490 (66.6755)  acc5: 81.6177 (87.6634)  time: 0.8000  data: 0.3840  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.6474 (1.4997)  acc1: 60.0490 (66.5937)  acc5: 86.7647 (87.7431)  time: 0.7537  data: 0.3429  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.5296 (1.4926)  acc1: 63.4804 (66.7500)  acc5: 88.2353 (87.8040)  time: 0.7431  data: 0.3429  max mem: 28602
Test: Total time: 0:01:48 (0.8800 s / it)
* Acc@1 66.750 Acc@5 87.804 loss 1.493
Accuracy of the network on the 50000 test images: 66.8%
Max accuracy: 66.92%
Epoch: [52]  [   0/1255]  eta: 3:51:59  lr: 0.001236  loss: 2.8322 (2.8322)  time: 11.0910  data: 9.6587  max mem: 28602
Epoch: [52]  [ 100/1255]  eta: 0:29:08  lr: 0.001236  loss: 4.0946 (3.9408)  time: 1.4172  data: 0.0004  max mem: 28602
Epoch: [52]  [ 200/1255]  eta: 0:25:43  lr: 0.001236  loss: 4.3247 (4.0400)  time: 1.4160  data: 0.0003  max mem: 28602
Epoch: [52]  [ 300/1255]  eta: 0:23:03  lr: 0.001236  loss: 3.9659 (4.0546)  time: 1.4248  data: 0.0004  max mem: 28602
Epoch: [52]  [ 400/1255]  eta: 0:20:31  lr: 0.001236  loss: 4.0534 (4.0551)  time: 1.4080  data: 0.0004  max mem: 28602
Epoch: [52]  [ 500/1255]  eta: 0:18:00  lr: 0.001236  loss: 4.3266 (4.0572)  time: 1.3927  data: 0.0003  max mem: 28602
Epoch: [52]  [ 600/1255]  eta: 0:15:35  lr: 0.001236  loss: 4.0620 (4.0436)  time: 1.3998  data: 0.0003  max mem: 28602
Epoch: [52]  [ 700/1255]  eta: 0:13:10  lr: 0.001236  loss: 4.0975 (4.0478)  time: 1.4092  data: 0.0003  max mem: 28602
Epoch: [52]  [ 800/1255]  eta: 0:10:47  lr: 0.001236  loss: 4.1163 (4.0446)  time: 1.4073  data: 0.0003  max mem: 28602
Epoch: [52]  [ 900/1255]  eta: 0:08:24  lr: 0.001236  loss: 4.3818 (4.0570)  time: 1.3981  data: 0.0003  max mem: 28602
Epoch: [52]  [1000/1255]  eta: 0:06:01  lr: 0.001236  loss: 4.1088 (4.0600)  time: 1.3945  data: 0.0003  max mem: 28602
Epoch: [52]  [1100/1255]  eta: 0:03:39  lr: 0.001236  loss: 3.9032 (4.0591)  time: 1.4143  data: 0.0003  max mem: 28602
Epoch: [52]  [1200/1255]  eta: 0:01:17  lr: 0.001236  loss: 3.7226 (4.0550)  time: 1.4104  data: 0.0003  max mem: 28602
Epoch: [52]  [1254/1255]  eta: 0:00:01  lr: 0.001236  loss: 4.2474 (4.0610)  time: 1.3815  data: 0.0008  max mem: 28602
Epoch: [52] Total time: 0:29:38 (1.4171 s / it)
Averaged stats: lr: 0.001236  loss: 4.2474 (4.0495)
Test:  [  0/123]  eta: 0:23:32  loss: 0.9981 (0.9981)  acc1: 77.2059 (77.2059)  acc5: 93.6275 (93.6275)  time: 11.4859  data: 11.0554  max mem: 28602
Test:  [ 10/123]  eta: 0:03:16  loss: 1.0698 (1.1173)  acc1: 75.4902 (74.8663)  acc5: 92.8922 (92.1569)  time: 1.7372  data: 1.3225  max mem: 28602
Test:  [ 20/123]  eta: 0:02:13  loss: 1.1404 (1.0850)  acc1: 74.2647 (75.5952)  acc5: 92.8922 (92.4603)  time: 0.7845  data: 0.3752  max mem: 28602
Test:  [ 30/123]  eta: 0:01:45  loss: 1.1688 (1.1278)  acc1: 71.3235 (73.3634)  acc5: 93.6275 (92.6787)  time: 0.7948  data: 0.3789  max mem: 28602
Test:  [ 40/123]  eta: 0:01:29  loss: 1.1373 (1.1030)  acc1: 71.0784 (74.0256)  acc5: 94.1177 (93.1133)  time: 0.8489  data: 0.4250  max mem: 28602
Test:  [ 50/123]  eta: 0:01:15  loss: 1.0475 (1.1177)  acc1: 75.2451 (73.7505)  acc5: 93.8726 (92.8297)  time: 0.8825  data: 0.4621  max mem: 28602
Test:  [ 60/123]  eta: 0:01:02  loss: 1.3102 (1.2134)  acc1: 68.6275 (71.8177)  acc5: 87.5000 (91.4577)  time: 0.8040  data: 0.3869  max mem: 28602
Test:  [ 70/123]  eta: 0:00:51  loss: 1.6908 (1.2749)  acc1: 61.2745 (70.5296)  acc5: 84.8039 (90.6552)  time: 0.7915  data: 0.3786  max mem: 28602
Test:  [ 80/123]  eta: 0:00:40  loss: 1.7108 (1.3395)  acc1: 61.2745 (69.3295)  acc5: 83.3333 (89.6696)  time: 0.8242  data: 0.4079  max mem: 28602
Test:  [ 90/123]  eta: 0:00:30  loss: 1.7294 (1.3824)  acc1: 61.5196 (68.5009)  acc5: 83.3333 (89.0541)  time: 0.8002  data: 0.3812  max mem: 28602
Test:  [100/123]  eta: 0:00:21  loss: 1.7294 (1.4145)  acc1: 62.9902 (67.9480)  acc5: 83.0882 (88.4804)  time: 0.7802  data: 0.3594  max mem: 28602
Test:  [110/123]  eta: 0:00:11  loss: 1.7914 (1.4522)  acc1: 60.7843 (67.0995)  acc5: 82.3529 (87.9306)  time: 0.8138  data: 0.3924  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.6200 (1.4460)  acc1: 60.7843 (67.1184)  acc5: 85.7843 (88.0753)  time: 0.7543  data: 0.3442  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.5484 (1.4403)  acc1: 61.0294 (67.2360)  acc5: 88.4804 (88.1500)  time: 0.7429  data: 0.3442  max mem: 28602
Test: Total time: 0:01:48 (0.8805 s / it)
* Acc@1 67.236 Acc@5 88.150 loss 1.440
Accuracy of the network on the 50000 test images: 67.2%
Max accuracy: 67.24%
Epoch: [53]  [   0/1255]  eta: 3:42:17  lr: 0.001233  loss: 4.0448 (4.0448)  time: 10.6272  data: 9.0165  max mem: 28602
Epoch: [53]  [ 100/1255]  eta: 0:28:59  lr: 0.001233  loss: 4.4433 (4.1773)  time: 1.4232  data: 0.0003  max mem: 28602
Epoch: [53]  [ 200/1255]  eta: 0:25:37  lr: 0.001233  loss: 3.6530 (4.0715)  time: 1.4118  data: 0.0003  max mem: 28602
Epoch: [53]  [ 300/1255]  eta: 0:22:55  lr: 0.001233  loss: 3.9992 (4.0660)  time: 1.4062  data: 0.0003  max mem: 28602
Epoch: [53]  [ 400/1255]  eta: 0:20:25  lr: 0.001233  loss: 3.9994 (4.0522)  time: 1.4100  data: 0.0003  max mem: 28602
Epoch: [53]  [ 500/1255]  eta: 0:17:58  lr: 0.001233  loss: 3.9853 (4.0440)  time: 1.4040  data: 0.0003  max mem: 28602
Epoch: [53]  [ 600/1255]  eta: 0:15:33  lr: 0.001233  loss: 4.0564 (4.0391)  time: 1.4073  data: 0.0003  max mem: 28602
Epoch: [53]  [ 700/1255]  eta: 0:13:09  lr: 0.001233  loss: 4.1082 (4.0275)  time: 1.4055  data: 0.0003  max mem: 28602
Epoch: [53]  [ 800/1255]  eta: 0:10:46  lr: 0.001233  loss: 4.1089 (4.0209)  time: 1.4042  data: 0.0004  max mem: 28602
Epoch: [53]  [ 900/1255]  eta: 0:08:23  lr: 0.001233  loss: 4.4649 (4.0329)  time: 1.4004  data: 0.0004  max mem: 28602
Epoch: [53]  [1000/1255]  eta: 0:06:01  lr: 0.001233  loss: 4.3389 (4.0358)  time: 1.4175  data: 0.0003  max mem: 28602
Epoch: [53]  [1100/1255]  eta: 0:03:39  lr: 0.001233  loss: 4.0944 (4.0363)  time: 1.4013  data: 0.0003  max mem: 28602
Epoch: [53]  [1200/1255]  eta: 0:01:17  lr: 0.001233  loss: 4.2271 (4.0342)  time: 1.4147  data: 0.0003  max mem: 28602
Epoch: [53]  [1254/1255]  eta: 0:00:01  lr: 0.001233  loss: 4.2095 (4.0316)  time: 1.3842  data: 0.0006  max mem: 28602
Epoch: [53] Total time: 0:29:36 (1.4153 s / it)
Averaged stats: lr: 0.001233  loss: 4.2095 (4.0482)
Test:  [  0/123]  eta: 0:23:40  loss: 1.1574 (1.1574)  acc1: 74.7549 (74.7549)  acc5: 91.6667 (91.6667)  time: 11.5474  data: 11.1122  max mem: 28602
Test:  [ 10/123]  eta: 0:03:20  loss: 1.1713 (1.1850)  acc1: 74.2647 (74.1087)  acc5: 91.6667 (91.5330)  time: 1.7778  data: 1.3649  max mem: 28602
Test:  [ 20/123]  eta: 0:02:15  loss: 1.1534 (1.1474)  acc1: 74.2647 (74.9066)  acc5: 91.6667 (92.1335)  time: 0.8076  data: 0.3940  max mem: 28602
Test:  [ 30/123]  eta: 0:01:45  loss: 1.2294 (1.1967)  acc1: 70.8333 (72.7783)  acc5: 92.4020 (92.2438)  time: 0.7725  data: 0.3521  max mem: 28602
Test:  [ 40/123]  eta: 0:01:29  loss: 1.2505 (1.1590)  acc1: 69.1177 (73.6490)  acc5: 93.8726 (92.8025)  time: 0.8286  data: 0.4084  max mem: 28602
Test:  [ 50/123]  eta: 0:01:15  loss: 1.1553 (1.1776)  acc1: 74.0196 (73.4045)  acc5: 93.3824 (92.5077)  time: 0.8779  data: 0.4620  max mem: 28602
Test:  [ 60/123]  eta: 0:01:02  loss: 1.3789 (1.2711)  acc1: 69.6078 (71.5003)  acc5: 87.9902 (91.1765)  time: 0.8074  data: 0.3890  max mem: 28602
Test:  [ 70/123]  eta: 0:00:51  loss: 1.7159 (1.3173)  acc1: 60.2941 (70.4985)  acc5: 84.8039 (90.5482)  time: 0.8172  data: 0.3984  max mem: 28602
Test:  [ 80/123]  eta: 0:00:40  loss: 1.7652 (1.3829)  acc1: 58.8235 (69.1721)  acc5: 83.8235 (89.5606)  time: 0.8255  data: 0.4118  max mem: 28602
Test:  [ 90/123]  eta: 0:00:30  loss: 1.7714 (1.4233)  acc1: 58.8235 (68.3096)  acc5: 83.0882 (88.9598)  time: 0.8220  data: 0.4139  max mem: 28602
Test:  [100/123]  eta: 0:00:21  loss: 1.7507 (1.4547)  acc1: 61.2745 (67.6907)  acc5: 84.5588 (88.4561)  time: 0.7899  data: 0.3763  max mem: 28602
Test:  [110/123]  eta: 0:00:11  loss: 1.7710 (1.4913)  acc1: 58.8235 (66.8676)  acc5: 83.0882 (87.9284)  time: 0.7885  data: 0.3674  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.5945 (1.4910)  acc1: 62.5000 (66.8064)  acc5: 86.7647 (88.0125)  time: 0.7498  data: 0.3358  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.4907 (1.4856)  acc1: 62.7451 (66.9460)  acc5: 87.7451 (88.0840)  time: 0.7396  data: 0.3358  max mem: 28602
Test: Total time: 0:01:48 (0.8831 s / it)
* Acc@1 66.946 Acc@5 88.084 loss 1.486
Accuracy of the network on the 50000 test images: 66.9%
Max accuracy: 67.24%
Epoch: [54]  [   0/1255]  eta: 3:48:53  lr: 0.001229  loss: 4.5859 (4.5859)  time: 10.9429  data: 9.5764  max mem: 28602
Epoch: [54]  [ 100/1255]  eta: 0:29:11  lr: 0.001229  loss: 4.3073 (3.9795)  time: 1.4263  data: 0.0003  max mem: 28602
Epoch: [54]  [ 200/1255]  eta: 0:25:52  lr: 0.001229  loss: 3.5744 (4.0027)  time: 1.4284  data: 0.0004  max mem: 28602
Epoch: [54]  [ 300/1255]  eta: 0:23:09  lr: 0.001229  loss: 4.0225 (3.9906)  time: 1.4255  data: 0.0003  max mem: 28602
Epoch: [54]  [ 400/1255]  eta: 0:20:36  lr: 0.001229  loss: 3.8673 (4.0103)  time: 1.4072  data: 0.0003  max mem: 28602
Epoch: [54]  [ 500/1255]  eta: 0:18:05  lr: 0.001229  loss: 3.8244 (4.0015)  time: 1.4044  data: 0.0003  max mem: 28602
Epoch: [54]  [ 600/1255]  eta: 0:15:37  lr: 0.001229  loss: 4.0867 (4.0076)  time: 1.4024  data: 0.0003  max mem: 28602
Epoch: [54]  [ 700/1255]  eta: 0:13:12  lr: 0.001229  loss: 4.1106 (4.0052)  time: 1.4114  data: 0.0003  max mem: 28602
Epoch: [54]  [ 800/1255]  eta: 0:10:48  lr: 0.001229  loss: 4.3200 (4.0100)  time: 1.3983  data: 0.0003  max mem: 28602
Epoch: [54]  [ 900/1255]  eta: 0:08:25  lr: 0.001229  loss: 3.9165 (4.0155)  time: 1.4066  data: 0.0003  max mem: 28602
Epoch: [54]  [1000/1255]  eta: 0:06:02  lr: 0.001229  loss: 4.2288 (4.0227)  time: 1.4042  data: 0.0003  max mem: 28602
Epoch: [54]  [1100/1255]  eta: 0:03:40  lr: 0.001229  loss: 4.1882 (4.0335)  time: 1.4040  data: 0.0003  max mem: 28602
Epoch: [54]  [1200/1255]  eta: 0:01:18  lr: 0.001229  loss: 4.0441 (4.0298)  time: 1.4191  data: 0.0003  max mem: 28602
Epoch: [54]  [1254/1255]  eta: 0:00:01  lr: 0.001229  loss: 4.1912 (4.0358)  time: 1.3745  data: 0.0007  max mem: 28602
Epoch: [54] Total time: 0:29:41 (1.4194 s / it)
Averaged stats: lr: 0.001229  loss: 4.1912 (4.0241)
Test:  [  0/123]  eta: 0:24:11  loss: 1.1609 (1.1609)  acc1: 73.2843 (73.2843)  acc5: 92.6471 (92.6471)  time: 11.8010  data: 11.3462  max mem: 28602
Test:  [ 10/123]  eta: 0:03:21  loss: 1.1609 (1.1526)  acc1: 72.3039 (74.0642)  acc5: 92.6471 (92.5134)  time: 1.7867  data: 1.3629  max mem: 28602
Test:  [ 20/123]  eta: 0:02:14  loss: 1.1216 (1.1049)  acc1: 74.5098 (75.8520)  acc5: 92.1569 (92.7171)  time: 0.7811  data: 0.3580  max mem: 28602
Test:  [ 30/123]  eta: 0:01:44  loss: 1.1426 (1.1488)  acc1: 70.0980 (73.5373)  acc5: 92.1569 (92.8052)  time: 0.7622  data: 0.3339  max mem: 28602
Test:  [ 40/123]  eta: 0:01:29  loss: 1.1426 (1.1208)  acc1: 69.3627 (74.0555)  acc5: 94.1177 (93.2807)  time: 0.8379  data: 0.4120  max mem: 28602
Test:  [ 50/123]  eta: 0:01:15  loss: 1.1011 (1.1390)  acc1: 73.7745 (74.0244)  acc5: 92.8922 (92.9210)  time: 0.8819  data: 0.4582  max mem: 28602
Test:  [ 60/123]  eta: 0:01:02  loss: 1.5619 (1.2446)  acc1: 64.9510 (71.6570)  acc5: 86.0294 (91.4417)  time: 0.8079  data: 0.3879  max mem: 28602
Test:  [ 70/123]  eta: 0:00:51  loss: 1.6880 (1.3007)  acc1: 60.5392 (70.6400)  acc5: 84.0686 (90.5793)  time: 0.8118  data: 0.3986  max mem: 28602
Test:  [ 80/123]  eta: 0:00:40  loss: 1.7469 (1.3682)  acc1: 60.2941 (69.3264)  acc5: 82.8431 (89.5970)  time: 0.8132  data: 0.4019  max mem: 28602
Test:  [ 90/123]  eta: 0:00:30  loss: 1.7396 (1.3990)  acc1: 60.2941 (68.6005)  acc5: 84.3137 (89.1268)  time: 0.7955  data: 0.3754  max mem: 28602
Test:  [100/123]  eta: 0:00:21  loss: 1.6703 (1.4298)  acc1: 63.7255 (68.0936)  acc5: 84.5588 (88.6211)  time: 0.7880  data: 0.3635  max mem: 28602
Test:  [110/123]  eta: 0:00:11  loss: 1.7606 (1.4678)  acc1: 59.8039 (67.2231)  acc5: 84.3137 (88.0896)  time: 0.8102  data: 0.3936  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.6275 (1.4639)  acc1: 59.8039 (67.2338)  acc5: 87.7451 (88.1928)  time: 0.7604  data: 0.3521  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.4903 (1.4585)  acc1: 62.2549 (67.3600)  acc5: 88.2353 (88.2480)  time: 0.7493  data: 0.3521  max mem: 28602
Test: Total time: 0:01:48 (0.8816 s / it)
* Acc@1 67.360 Acc@5 88.248 loss 1.458
Accuracy of the network on the 50000 test images: 67.4%
Max accuracy: 67.36%
Epoch: [55]  [   0/1255]  eta: 3:49:28  lr: 0.001226  loss: 4.2170 (4.2170)  time: 10.9712  data: 9.5242  max mem: 28602
Epoch: [55]  [ 100/1255]  eta: 0:29:05  lr: 0.001226  loss: 4.2643 (4.0438)  time: 1.4082  data: 0.0003  max mem: 28602
Epoch: [55]  [ 200/1255]  eta: 0:25:43  lr: 0.001226  loss: 4.0743 (4.0489)  time: 1.4171  data: 0.0003  max mem: 28602
Epoch: [55]  [ 300/1255]  eta: 0:22:59  lr: 0.001226  loss: 4.0805 (4.0158)  time: 1.3905  data: 0.0003  max mem: 28602
Epoch: [55]  [ 400/1255]  eta: 0:20:25  lr: 0.001226  loss: 3.7653 (4.0002)  time: 1.4184  data: 0.0003  max mem: 28602
Epoch: [55]  [ 500/1255]  eta: 0:17:59  lr: 0.001226  loss: 4.1990 (4.0157)  time: 1.4091  data: 0.0003  max mem: 28602
Epoch: [55]  [ 600/1255]  eta: 0:15:34  lr: 0.001226  loss: 4.1999 (4.0078)  time: 1.4184  data: 0.0003  max mem: 28602
Epoch: [55]  [ 700/1255]  eta: 0:13:10  lr: 0.001226  loss: 4.4399 (4.0286)  time: 1.4117  data: 0.0004  max mem: 28602
Epoch: [55]  [ 800/1255]  eta: 0:10:47  lr: 0.001226  loss: 4.0398 (4.0204)  time: 1.4033  data: 0.0003  max mem: 28602
Epoch: [55]  [ 900/1255]  eta: 0:08:24  lr: 0.001226  loss: 4.3052 (4.0229)  time: 1.4231  data: 0.0004  max mem: 28602
Epoch: [55]  [1000/1255]  eta: 0:06:02  lr: 0.001226  loss: 4.0528 (4.0234)  time: 1.4190  data: 0.0004  max mem: 28602
Epoch: [55]  [1100/1255]  eta: 0:03:40  lr: 0.001226  loss: 4.2372 (4.0213)  time: 1.4202  data: 0.0003  max mem: 28602
Epoch: [55]  [1200/1255]  eta: 0:01:18  lr: 0.001226  loss: 4.1288 (4.0207)  time: 1.4179  data: 0.0003  max mem: 28602
Epoch: [55]  [1254/1255]  eta: 0:00:01  lr: 0.001226  loss: 4.4742 (4.0259)  time: 1.3833  data: 0.0004  max mem: 28602
Epoch: [55] Total time: 0:29:41 (1.4197 s / it)
Averaged stats: lr: 0.001226  loss: 4.4742 (4.0171)
Test:  [  0/123]  eta: 0:24:16  loss: 1.0617 (1.0617)  acc1: 76.9608 (76.9608)  acc5: 93.1373 (93.1373)  time: 11.8387  data: 11.3895  max mem: 28602
Test:  [ 10/123]  eta: 0:03:20  loss: 1.0761 (1.1127)  acc1: 74.2647 (74.3093)  acc5: 92.8922 (92.2237)  time: 1.7753  data: 1.3512  max mem: 28602
Test:  [ 20/123]  eta: 0:02:15  loss: 1.0989 (1.0681)  acc1: 75.0000 (76.2021)  acc5: 92.8922 (92.7054)  time: 0.7849  data: 0.3667  max mem: 28602
Test:  [ 30/123]  eta: 0:01:46  loss: 1.1679 (1.1183)  acc1: 72.5490 (74.0987)  acc5: 93.6275 (92.9001)  time: 0.7940  data: 0.3822  max mem: 28602
Test:  [ 40/123]  eta: 0:01:29  loss: 1.1726 (1.0965)  acc1: 71.3235 (74.5696)  acc5: 94.1177 (93.2927)  time: 0.8447  data: 0.4297  max mem: 28602
Test:  [ 50/123]  eta: 0:01:15  loss: 1.0831 (1.1209)  acc1: 75.2451 (74.2263)  acc5: 93.8726 (92.8874)  time: 0.8578  data: 0.4351  max mem: 28602
Test:  [ 60/123]  eta: 0:01:02  loss: 1.4428 (1.2228)  acc1: 66.9118 (72.0508)  acc5: 87.7451 (91.4457)  time: 0.8054  data: 0.3851  max mem: 28602
Test:  [ 70/123]  eta: 0:00:51  loss: 1.6536 (1.2710)  acc1: 62.0098 (71.1544)  acc5: 85.5392 (90.8485)  time: 0.8114  data: 0.3926  max mem: 28602
Test:  [ 80/123]  eta: 0:00:40  loss: 1.6744 (1.3291)  acc1: 61.2745 (69.9861)  acc5: 84.0686 (90.0145)  time: 0.8145  data: 0.3996  max mem: 28602
Test:  [ 90/123]  eta: 0:00:30  loss: 1.7622 (1.3722)  acc1: 61.2745 (69.0961)  acc5: 83.8235 (89.4150)  time: 0.7942  data: 0.3831  max mem: 28602
Test:  [100/123]  eta: 0:00:21  loss: 1.7448 (1.4071)  acc1: 62.0098 (68.4430)  acc5: 83.8235 (88.8565)  time: 0.7787  data: 0.3627  max mem: 28602
Test:  [110/123]  eta: 0:00:11  loss: 1.8486 (1.4464)  acc1: 58.0882 (67.5035)  acc5: 81.1275 (88.3302)  time: 0.8171  data: 0.3924  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.6287 (1.4479)  acc1: 58.5784 (67.4263)  acc5: 87.0098 (88.4460)  time: 0.7684  data: 0.3504  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.5277 (1.4430)  acc1: 61.6071 (67.5660)  acc5: 88.9706 (88.5140)  time: 0.7575  data: 0.3504  max mem: 28602
Test: Total time: 0:01:48 (0.8832 s / it)
* Acc@1 67.566 Acc@5 88.514 loss 1.443
Accuracy of the network on the 50000 test images: 67.6%
Max accuracy: 67.57%
Epoch: [56]  [   0/1255]  eta: 3:29:44  lr: 0.001222  loss: 4.4854 (4.4854)  time: 10.0278  data: 8.6133  max mem: 28602
Epoch: [56]  [ 100/1255]  eta: 0:28:50  lr: 0.001222  loss: 4.1213 (4.0649)  time: 1.4099  data: 0.0004  max mem: 28602
Epoch: [56]  [ 200/1255]  eta: 0:25:39  lr: 0.001222  loss: 4.0227 (4.0208)  time: 1.4376  data: 0.0004  max mem: 28602
Epoch: [56]  [ 300/1255]  eta: 0:23:01  lr: 0.001222  loss: 4.2779 (4.0468)  time: 1.4394  data: 0.0004  max mem: 28602
Epoch: [56]  [ 400/1255]  eta: 0:20:30  lr: 0.001222  loss: 3.8370 (4.0260)  time: 1.4136  data: 0.0003  max mem: 28602
Epoch: [56]  [ 500/1255]  eta: 0:18:01  lr: 0.001222  loss: 3.6810 (4.0277)  time: 1.4087  data: 0.0003  max mem: 28602
Epoch: [56]  [ 600/1255]  eta: 0:15:35  lr: 0.001222  loss: 4.3816 (4.0158)  time: 1.4089  data: 0.0003  max mem: 28602
Epoch: [56]  [ 700/1255]  eta: 0:13:10  lr: 0.001222  loss: 4.3021 (4.0168)  time: 1.3997  data: 0.0003  max mem: 28602
Epoch: [56]  [ 800/1255]  eta: 0:10:47  lr: 0.001222  loss: 4.1752 (4.0139)  time: 1.4174  data: 0.0003  max mem: 28602
Epoch: [56]  [ 900/1255]  eta: 0:08:24  lr: 0.001222  loss: 3.8259 (4.0080)  time: 1.4060  data: 0.0003  max mem: 28602
Epoch: [56]  [1000/1255]  eta: 0:06:02  lr: 0.001222  loss: 4.1744 (4.0175)  time: 1.4073  data: 0.0003  max mem: 28602
Epoch: [56]  [1100/1255]  eta: 0:03:39  lr: 0.001222  loss: 4.2266 (4.0184)  time: 1.4071  data: 0.0003  max mem: 28602
Epoch: [56]  [1200/1255]  eta: 0:01:17  lr: 0.001222  loss: 4.1446 (4.0164)  time: 1.4110  data: 0.0003  max mem: 28602
Epoch: [56]  [1254/1255]  eta: 0:00:01  lr: 0.001222  loss: 4.0830 (4.0149)  time: 1.3743  data: 0.0007  max mem: 28602
Epoch: [56] Total time: 0:29:39 (1.4176 s / it)
Averaged stats: lr: 0.001222  loss: 4.0830 (4.0211)
Test:  [  0/123]  eta: 0:24:40  loss: 1.0508 (1.0508)  acc1: 77.2059 (77.2059)  acc5: 93.3824 (93.3824)  time: 12.0391  data: 11.5882  max mem: 28602
Test:  [ 10/123]  eta: 0:03:25  loss: 1.1521 (1.1172)  acc1: 75.7353 (75.5348)  acc5: 91.6667 (92.9590)  time: 1.8211  data: 1.4111  max mem: 28602
Test:  [ 20/123]  eta: 0:02:16  loss: 1.1015 (1.0757)  acc1: 75.7353 (76.9608)  acc5: 92.8922 (93.2306)  time: 0.7915  data: 0.3744  max mem: 28602
Test:  [ 30/123]  eta: 0:01:46  loss: 1.1718 (1.1556)  acc1: 72.5490 (74.1461)  acc5: 93.3824 (93.2005)  time: 0.7693  data: 0.3447  max mem: 28602
Test:  [ 40/123]  eta: 0:01:30  loss: 1.1982 (1.1355)  acc1: 68.3824 (74.5517)  acc5: 93.3824 (93.5557)  time: 0.8402  data: 0.4222  max mem: 28602
Test:  [ 50/123]  eta: 0:01:15  loss: 1.1271 (1.1532)  acc1: 74.5098 (74.2311)  acc5: 93.3824 (93.2190)  time: 0.8726  data: 0.4564  max mem: 28602
Test:  [ 60/123]  eta: 0:01:02  loss: 1.3793 (1.2483)  acc1: 67.8922 (72.1713)  acc5: 87.2549 (91.8877)  time: 0.8019  data: 0.3843  max mem: 28602
Test:  [ 70/123]  eta: 0:00:51  loss: 1.6502 (1.3047)  acc1: 60.7843 (71.0025)  acc5: 85.0490 (91.0591)  time: 0.8223  data: 0.4017  max mem: 28602
Test:  [ 80/123]  eta: 0:00:41  loss: 1.6916 (1.3652)  acc1: 61.2745 (69.7591)  acc5: 83.5784 (90.0660)  time: 0.8275  data: 0.4047  max mem: 28602
Test:  [ 90/123]  eta: 0:00:30  loss: 1.7009 (1.4040)  acc1: 62.0098 (68.9964)  acc5: 84.5588 (89.5039)  time: 0.7938  data: 0.3720  max mem: 28602
Test:  [100/123]  eta: 0:00:21  loss: 1.7009 (1.4354)  acc1: 63.4804 (68.3896)  acc5: 85.0490 (88.9949)  time: 0.7747  data: 0.3523  max mem: 28602
Test:  [110/123]  eta: 0:00:11  loss: 1.8202 (1.4770)  acc1: 59.8039 (67.3931)  acc5: 82.1078 (88.4186)  time: 0.8042  data: 0.3790  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.7198 (1.4736)  acc1: 59.3137 (67.4080)  acc5: 86.2745 (88.5209)  time: 0.7504  data: 0.3382  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.5843 (1.4683)  acc1: 61.5196 (67.5200)  acc5: 88.4804 (88.5800)  time: 0.7365  data: 0.3382  max mem: 28602
Test: Total time: 0:01:48 (0.8835 s / it)
* Acc@1 67.520 Acc@5 88.580 loss 1.468
Accuracy of the network on the 50000 test images: 67.5%
Max accuracy: 67.57%
Epoch: [57]  [   0/1255]  eta: 4:09:03  lr: 0.001218  loss: 4.1354 (4.1354)  time: 11.9072  data: 10.4713  max mem: 28602
Epoch: [57]  [ 100/1255]  eta: 0:29:25  lr: 0.001218  loss: 3.9591 (4.0554)  time: 1.4144  data: 0.0003  max mem: 28602
Epoch: [57]  [ 200/1255]  eta: 0:25:53  lr: 0.001218  loss: 4.4476 (4.0812)  time: 1.4250  data: 0.0003  max mem: 28602
Epoch: [57]  [ 300/1255]  eta: 0:23:05  lr: 0.001218  loss: 3.9076 (4.0578)  time: 1.4108  data: 0.0004  max mem: 28602
Epoch: [57]  [ 400/1255]  eta: 0:20:32  lr: 0.001218  loss: 4.2291 (4.0415)  time: 1.4084  data: 0.0003  max mem: 28602
Epoch: [57]  [ 500/1255]  eta: 0:18:04  lr: 0.001218  loss: 3.9319 (4.0190)  time: 1.4109  data: 0.0003  max mem: 28602
Epoch: [57]  [ 600/1255]  eta: 0:15:37  lr: 0.001218  loss: 3.9017 (4.0175)  time: 1.4074  data: 0.0003  max mem: 28602
Epoch: [57]  [ 700/1255]  eta: 0:13:12  lr: 0.001218  loss: 3.8304 (4.0149)  time: 1.4131  data: 0.0003  max mem: 28602
Epoch: [57]  [ 800/1255]  eta: 0:10:48  lr: 0.001218  loss: 3.7920 (4.0211)  time: 1.4112  data: 0.0003  max mem: 28602
Epoch: [57]  [ 900/1255]  eta: 0:08:25  lr: 0.001218  loss: 3.6353 (4.0042)  time: 1.4102  data: 0.0003  max mem: 28602
Epoch: [57]  [1000/1255]  eta: 0:06:02  lr: 0.001218  loss: 4.1820 (4.0015)  time: 1.4153  data: 0.0003  max mem: 28602
Epoch: [57]  [1100/1255]  eta: 0:03:40  lr: 0.001218  loss: 4.1352 (3.9968)  time: 1.4057  data: 0.0003  max mem: 28602
Epoch: [57]  [1200/1255]  eta: 0:01:18  lr: 0.001218  loss: 4.0546 (3.9930)  time: 1.4076  data: 0.0003  max mem: 28602
Epoch: [57]  [1254/1255]  eta: 0:00:01  lr: 0.001218  loss: 3.9748 (3.9954)  time: 1.3783  data: 0.0008  max mem: 28602
Epoch: [57] Total time: 0:29:45 (1.4224 s / it)
Averaged stats: lr: 0.001218  loss: 3.9748 (4.0169)
Test:  [  0/123]  eta: 0:24:10  loss: 1.0740 (1.0740)  acc1: 73.2843 (73.2843)  acc5: 92.6471 (92.6471)  time: 11.7928  data: 11.3456  max mem: 28602
Test:  [ 10/123]  eta: 0:03:21  loss: 1.1499 (1.1151)  acc1: 72.5490 (74.4207)  acc5: 92.6471 (92.2683)  time: 1.7804  data: 1.3592  max mem: 28602
Test:  [ 20/123]  eta: 0:02:15  loss: 1.1499 (1.0867)  acc1: 73.2843 (75.6886)  acc5: 92.6471 (92.6937)  time: 0.7913  data: 0.3781  max mem: 28602
Test:  [ 30/123]  eta: 0:01:46  loss: 1.2171 (1.1334)  acc1: 71.3235 (73.6322)  acc5: 93.6275 (92.7973)  time: 0.7962  data: 0.3904  max mem: 28602
Test:  [ 40/123]  eta: 0:01:30  loss: 1.1791 (1.1007)  acc1: 70.3431 (74.4799)  acc5: 94.1177 (93.2748)  time: 0.8606  data: 0.4514  max mem: 28602
Test:  [ 50/123]  eta: 0:01:16  loss: 1.0863 (1.1176)  acc1: 74.0196 (74.1734)  acc5: 93.6275 (92.9642)  time: 0.9013  data: 0.4876  max mem: 28602
Test:  [ 60/123]  eta: 0:01:03  loss: 1.4205 (1.2207)  acc1: 67.1569 (71.8499)  acc5: 87.5000 (91.5461)  time: 0.8320  data: 0.4126  max mem: 28602
Test:  [ 70/123]  eta: 0:00:52  loss: 1.6092 (1.2580)  acc1: 63.9706 (71.1993)  acc5: 85.2941 (90.9245)  time: 0.8145  data: 0.3978  max mem: 28602
Test:  [ 80/123]  eta: 0:00:41  loss: 1.6179 (1.3156)  acc1: 63.7255 (70.0950)  acc5: 84.5588 (90.0085)  time: 0.8305  data: 0.4188  max mem: 28602
Test:  [ 90/123]  eta: 0:00:31  loss: 1.6859 (1.3546)  acc1: 61.2745 (69.2550)  acc5: 84.5588 (89.4716)  time: 0.8170  data: 0.4032  max mem: 28602
Test:  [100/123]  eta: 0:00:21  loss: 1.6551 (1.3974)  acc1: 61.7647 (68.4236)  acc5: 85.2941 (88.8080)  time: 0.7938  data: 0.3819  max mem: 28602
Test:  [110/123]  eta: 0:00:12  loss: 1.7873 (1.4399)  acc1: 60.2941 (67.4947)  acc5: 82.8431 (88.1956)  time: 0.8273  data: 0.4129  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.6771 (1.4409)  acc1: 60.0490 (67.3959)  acc5: 85.0490 (88.2535)  time: 0.7774  data: 0.3676  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.6620 (1.4352)  acc1: 62.7451 (67.5360)  acc5: 86.0294 (88.3280)  time: 0.7657  data: 0.3676  max mem: 28602
Test: Total time: 0:01:50 (0.8981 s / it)
* Acc@1 67.536 Acc@5 88.328 loss 1.435
Accuracy of the network on the 50000 test images: 67.5%
Max accuracy: 67.57%
Epoch: [58]  [   0/1255]  eta: 4:11:18  lr: 0.001214  loss: 4.3737 (4.3737)  time: 12.0144  data: 10.5904  max mem: 28602
Epoch: [58]  [ 100/1255]  eta: 0:29:17  lr: 0.001214  loss: 4.1106 (4.0113)  time: 1.4069  data: 0.0004  max mem: 28602
Epoch: [58]  [ 200/1255]  eta: 0:25:51  lr: 0.001214  loss: 3.7154 (4.0268)  time: 1.4078  data: 0.0004  max mem: 28602
Epoch: [58]  [ 300/1255]  eta: 0:23:07  lr: 0.001214  loss: 4.1168 (4.0272)  time: 1.4062  data: 0.0003  max mem: 28602
Epoch: [58]  [ 400/1255]  eta: 0:20:34  lr: 0.001214  loss: 4.1209 (4.0306)  time: 1.4125  data: 0.0004  max mem: 28602
Epoch: [58]  [ 500/1255]  eta: 0:18:03  lr: 0.001214  loss: 4.3126 (4.0345)  time: 1.4168  data: 0.0003  max mem: 28602
Epoch: [58]  [ 600/1255]  eta: 0:15:37  lr: 0.001214  loss: 4.4439 (4.0310)  time: 1.4083  data: 0.0003  max mem: 28602
Epoch: [58]  [ 700/1255]  eta: 0:13:12  lr: 0.001214  loss: 3.8998 (4.0241)  time: 1.4136  data: 0.0003  max mem: 28602
Epoch: [58]  [ 800/1255]  eta: 0:10:48  lr: 0.001214  loss: 4.1212 (4.0128)  time: 1.4070  data: 0.0003  max mem: 28602
Epoch: [58]  [ 900/1255]  eta: 0:08:25  lr: 0.001214  loss: 4.3742 (4.0119)  time: 1.4083  data: 0.0003  max mem: 28602
Epoch: [58]  [1000/1255]  eta: 0:06:02  lr: 0.001214  loss: 4.0751 (4.0050)  time: 1.4206  data: 0.0003  max mem: 28602
Epoch: [58]  [1100/1255]  eta: 0:03:40  lr: 0.001214  loss: 3.3388 (3.9920)  time: 1.4093  data: 0.0003  max mem: 28602
Epoch: [58]  [1200/1255]  eta: 0:01:18  lr: 0.001214  loss: 4.1473 (3.9920)  time: 1.3978  data: 0.0003  max mem: 28602
Epoch: [58]  [1254/1255]  eta: 0:00:01  lr: 0.001214  loss: 4.0165 (3.9976)  time: 1.3842  data: 0.0004  max mem: 28602
Epoch: [58] Total time: 0:29:42 (1.4201 s / it)
Averaged stats: lr: 0.001214  loss: 4.0165 (4.0004)
Test:  [  0/123]  eta: 0:24:01  loss: 1.1087 (1.1087)  acc1: 76.7157 (76.7157)  acc5: 93.1373 (93.1373)  time: 11.7208  data: 11.2877  max mem: 28602
Test:  [ 10/123]  eta: 0:03:20  loss: 1.1318 (1.1613)  acc1: 73.2843 (74.4875)  acc5: 93.1373 (92.2460)  time: 1.7754  data: 1.3581  max mem: 28602
Test:  [ 20/123]  eta: 0:02:15  loss: 1.1018 (1.0890)  acc1: 76.2255 (76.6106)  acc5: 93.1373 (92.8455)  time: 0.7937  data: 0.3786  max mem: 28602
Test:  [ 30/123]  eta: 0:01:46  loss: 1.1565 (1.1476)  acc1: 71.0784 (74.1856)  acc5: 93.3824 (92.9080)  time: 0.7933  data: 0.3823  max mem: 28602
Test:  [ 40/123]  eta: 0:01:30  loss: 1.1565 (1.1121)  acc1: 69.8529 (74.8506)  acc5: 94.3627 (93.4421)  time: 0.8636  data: 0.4518  max mem: 28602
Test:  [ 50/123]  eta: 0:01:16  loss: 1.1260 (1.1390)  acc1: 74.7549 (74.3849)  acc5: 93.3824 (92.9642)  time: 0.8868  data: 0.4774  max mem: 28602
Test:  [ 60/123]  eta: 0:01:02  loss: 1.3002 (1.2239)  acc1: 69.6078 (72.5611)  acc5: 87.7451 (91.6988)  time: 0.7988  data: 0.3882  max mem: 28602
Test:  [ 70/123]  eta: 0:00:51  loss: 1.6284 (1.2767)  acc1: 62.2549 (71.3857)  acc5: 86.0294 (90.9003)  time: 0.8140  data: 0.3971  max mem: 28602
Test:  [ 80/123]  eta: 0:00:41  loss: 1.7303 (1.3394)  acc1: 61.2745 (70.1313)  acc5: 84.3137 (89.9964)  time: 0.8215  data: 0.4080  max mem: 28602
Test:  [ 90/123]  eta: 0:00:30  loss: 1.6788 (1.3731)  acc1: 61.5196 (69.3816)  acc5: 84.3137 (89.5227)  time: 0.7834  data: 0.3702  max mem: 28602
Test:  [100/123]  eta: 0:00:21  loss: 1.6715 (1.4100)  acc1: 62.2549 (68.6687)  acc5: 84.5588 (88.9002)  time: 0.7807  data: 0.3688  max mem: 28602
Test:  [110/123]  eta: 0:00:11  loss: 1.7699 (1.4478)  acc1: 60.5392 (67.8215)  acc5: 82.8431 (88.3435)  time: 0.8175  data: 0.4088  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.6108 (1.4496)  acc1: 61.2745 (67.8294)  acc5: 86.2745 (88.3872)  time: 0.7584  data: 0.3497  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.4890 (1.4457)  acc1: 64.7059 (67.9620)  acc5: 87.0098 (88.4400)  time: 0.7495  data: 0.3497  max mem: 28602
Test: Total time: 0:01:48 (0.8859 s / it)
* Acc@1 67.962 Acc@5 88.440 loss 1.446
Accuracy of the network on the 50000 test images: 68.0%
Max accuracy: 67.96%
Epoch: [59]  [   0/1255]  eta: 3:48:55  lr: 0.001210  loss: 3.7013 (3.7013)  time: 10.9443  data: 9.5114  max mem: 28602
Epoch: [59]  [ 100/1255]  eta: 0:29:04  lr: 0.001210  loss: 4.1741 (3.9441)  time: 1.4147  data: 0.0003  max mem: 28602
Epoch: [59]  [ 200/1255]  eta: 0:25:39  lr: 0.001210  loss: 4.3895 (3.9698)  time: 1.4111  data: 0.0005  max mem: 28602
Epoch: [59]  [ 300/1255]  eta: 0:22:56  lr: 0.001210  loss: 4.0692 (4.0051)  time: 1.4023  data: 0.0003  max mem: 28602
Epoch: [59]  [ 400/1255]  eta: 0:20:27  lr: 0.001210  loss: 4.1782 (4.0086)  time: 1.4199  data: 0.0003  max mem: 28602
Epoch: [59]  [ 500/1255]  eta: 0:17:58  lr: 0.001210  loss: 3.8986 (3.9925)  time: 1.4096  data: 0.0003  max mem: 28602
Epoch: [59]  [ 600/1255]  eta: 0:15:33  lr: 0.001210  loss: 4.1620 (4.0028)  time: 1.4135  data: 0.0003  max mem: 28602
Epoch: [59]  [ 700/1255]  eta: 0:13:09  lr: 0.001210  loss: 4.1354 (4.0191)  time: 1.4049  data: 0.0003  max mem: 28602
Epoch: [59]  [ 800/1255]  eta: 0:10:46  lr: 0.001210  loss: 4.3383 (4.0261)  time: 1.4102  data: 0.0003  max mem: 28602
Epoch: [59]  [ 900/1255]  eta: 0:08:23  lr: 0.001210  loss: 3.7764 (4.0132)  time: 1.4108  data: 0.0003  max mem: 28602
Epoch: [59]  [1000/1255]  eta: 0:06:01  lr: 0.001210  loss: 4.1551 (4.0057)  time: 1.4290  data: 0.0003  max mem: 28602
Epoch: [59]  [1100/1255]  eta: 0:03:39  lr: 0.001210  loss: 4.2827 (4.0031)  time: 1.4094  data: 0.0003  max mem: 28602
Epoch: [59]  [1200/1255]  eta: 0:01:18  lr: 0.001210  loss: 4.2286 (4.0061)  time: 1.4519  data: 0.0004  max mem: 28602
Epoch: [59]  [1254/1255]  eta: 0:00:01  lr: 0.001210  loss: 4.0588 (4.0037)  time: 1.4142  data: 0.0007  max mem: 28602
Epoch: [59] Total time: 0:29:41 (1.4197 s / it)
Averaged stats: lr: 0.001210  loss: 4.0588 (3.9916)
Test:  [  0/123]  eta: 0:25:07  loss: 1.0959 (1.0959)  acc1: 76.9608 (76.9608)  acc5: 92.8922 (92.8922)  time: 12.2591  data: 11.8230  max mem: 28602
Test:  [ 10/123]  eta: 0:03:22  loss: 1.1304 (1.1322)  acc1: 74.0196 (74.1979)  acc5: 92.4020 (92.1123)  time: 1.7951  data: 1.3795  max mem: 28602
Test:  [ 20/123]  eta: 0:02:18  loss: 1.0546 (1.0706)  acc1: 75.2451 (76.0854)  acc5: 92.4020 (92.4837)  time: 0.7979  data: 0.3867  max mem: 28602
Test:  [ 30/123]  eta: 0:01:47  loss: 1.1807 (1.1388)  acc1: 70.8333 (73.2922)  acc5: 93.3824 (92.5917)  time: 0.8051  data: 0.3910  max mem: 28602
Test:  [ 40/123]  eta: 0:01:31  loss: 1.2109 (1.1088)  acc1: 68.3824 (73.8941)  acc5: 95.0980 (93.1552)  time: 0.8510  data: 0.4336  max mem: 28602
Test:  [ 50/123]  eta: 0:01:16  loss: 1.1027 (1.1327)  acc1: 75.0000 (73.4669)  acc5: 93.1373 (92.8057)  time: 0.8884  data: 0.4740  max mem: 28602
Test:  [ 60/123]  eta: 0:01:03  loss: 1.4506 (1.2319)  acc1: 64.4608 (71.4039)  acc5: 86.7647 (91.3251)  time: 0.7988  data: 0.3843  max mem: 28602
Test:  [ 70/123]  eta: 0:00:51  loss: 1.6511 (1.2848)  acc1: 61.5196 (70.5054)  acc5: 83.8235 (90.5931)  time: 0.8020  data: 0.3891  max mem: 28602
Test:  [ 80/123]  eta: 0:00:41  loss: 1.7095 (1.3498)  acc1: 61.2745 (69.2810)  acc5: 83.3333 (89.6484)  time: 0.8012  data: 0.3925  max mem: 28602
Test:  [ 90/123]  eta: 0:00:30  loss: 1.6857 (1.3845)  acc1: 61.5196 (68.5628)  acc5: 82.5980 (89.1430)  time: 0.7820  data: 0.3692  max mem: 28602
Test:  [100/123]  eta: 0:00:21  loss: 1.6639 (1.4176)  acc1: 62.9902 (67.8922)  acc5: 85.7843 (88.6551)  time: 0.7925  data: 0.3766  max mem: 28602
Test:  [110/123]  eta: 0:00:11  loss: 1.8262 (1.4528)  acc1: 61.0294 (67.1988)  acc5: 83.3333 (88.1757)  time: 0.8116  data: 0.3957  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.5387 (1.4486)  acc1: 62.0098 (67.2622)  acc5: 87.5000 (88.3325)  time: 0.7576  data: 0.3452  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.4704 (1.4430)  acc1: 64.9510 (67.3960)  acc5: 88.9706 (88.3800)  time: 0.7476  data: 0.3452  max mem: 28602
Test: Total time: 0:01:49 (0.8875 s / it)
* Acc@1 67.396 Acc@5 88.380 loss 1.443
Accuracy of the network on the 50000 test images: 67.4%
Max accuracy: 67.96%
Epoch: [60]  [   0/1255]  eta: 3:50:53  lr: 0.001206  loss: 2.9431 (2.9431)  time: 11.0388  data: 9.6010  max mem: 28602
Epoch: [60]  [ 100/1255]  eta: 0:29:14  lr: 0.001206  loss: 4.2032 (3.9705)  time: 1.4094  data: 0.0003  max mem: 28602
Epoch: [60]  [ 200/1255]  eta: 0:25:51  lr: 0.001206  loss: 4.2922 (3.9933)  time: 1.4195  data: 0.0003  max mem: 28602
Epoch: [60]  [ 300/1255]  eta: 0:23:08  lr: 0.001206  loss: 4.2912 (3.9942)  time: 1.4312  data: 0.0003  max mem: 28602
Epoch: [60]  [ 400/1255]  eta: 0:20:35  lr: 0.001206  loss: 4.0875 (3.9791)  time: 1.4140  data: 0.0003  max mem: 28602
Epoch: [60]  [ 500/1255]  eta: 0:18:04  lr: 0.001206  loss: 4.1784 (3.9904)  time: 1.4099  data: 0.0003  max mem: 28602
Epoch: [60]  [ 600/1255]  eta: 0:15:37  lr: 0.001206  loss: 3.9292 (3.9920)  time: 1.4050  data: 0.0003  max mem: 28602
Epoch: [60]  [ 700/1255]  eta: 0:13:12  lr: 0.001206  loss: 4.1849 (3.9924)  time: 1.4068  data: 0.0003  max mem: 28602
Epoch: [60]  [ 800/1255]  eta: 0:10:48  lr: 0.001206  loss: 4.2383 (3.9936)  time: 1.3999  data: 0.0003  max mem: 28602
Epoch: [60]  [ 900/1255]  eta: 0:08:25  lr: 0.001206  loss: 3.8962 (3.9890)  time: 1.4067  data: 0.0003  max mem: 28602
Epoch: [60]  [1000/1255]  eta: 0:06:02  lr: 0.001206  loss: 3.9572 (3.9844)  time: 1.4051  data: 0.0003  max mem: 28602
Epoch: [60]  [1100/1255]  eta: 0:03:40  lr: 0.001206  loss: 4.1268 (3.9893)  time: 1.4115  data: 0.0003  max mem: 28602
Epoch: [60]  [1200/1255]  eta: 0:01:18  lr: 0.001206  loss: 4.0260 (3.9881)  time: 1.4037  data: 0.0003  max mem: 28602
Epoch: [60]  [1254/1255]  eta: 0:00:01  lr: 0.001206  loss: 4.0167 (3.9859)  time: 1.3767  data: 0.0006  max mem: 28602
Epoch: [60] Total time: 0:29:41 (1.4195 s / it)
Averaged stats: lr: 0.001206  loss: 4.0167 (4.0014)
Test:  [  0/123]  eta: 0:23:43  loss: 1.1121 (1.1121)  acc1: 73.7745 (73.7745)  acc5: 92.4020 (92.4020)  time: 11.5707  data: 11.1515  max mem: 28602
Test:  [ 10/123]  eta: 0:03:16  loss: 1.1299 (1.1408)  acc1: 72.0588 (73.7745)  acc5: 92.6471 (92.3351)  time: 1.7395  data: 1.3329  max mem: 28602
Test:  [ 20/123]  eta: 0:02:13  loss: 1.0800 (1.0895)  acc1: 76.9608 (75.6536)  acc5: 92.6471 (92.6587)  time: 0.7783  data: 0.3650  max mem: 28602
Test:  [ 30/123]  eta: 0:01:43  loss: 1.1897 (1.1600)  acc1: 71.5686 (73.0629)  acc5: 93.1373 (92.5759)  time: 0.7624  data: 0.3446  max mem: 28602
Test:  [ 40/123]  eta: 0:01:27  loss: 1.1897 (1.1272)  acc1: 70.5882 (73.7626)  acc5: 93.8726 (93.0775)  time: 0.8136  data: 0.4006  max mem: 28602
Test:  [ 50/123]  eta: 0:01:13  loss: 1.0507 (1.1347)  acc1: 75.7353 (73.8562)  acc5: 93.3824 (92.8297)  time: 0.8643  data: 0.4458  max mem: 28602
Test:  [ 60/123]  eta: 0:01:01  loss: 1.4109 (1.2193)  acc1: 67.4020 (72.1030)  acc5: 87.7451 (91.6144)  time: 0.8219  data: 0.4053  max mem: 28602
Test:  [ 70/123]  eta: 0:00:50  loss: 1.6431 (1.2755)  acc1: 62.7451 (71.0232)  acc5: 85.2941 (90.8244)  time: 0.8095  data: 0.3952  max mem: 28602
Test:  [ 80/123]  eta: 0:00:40  loss: 1.7170 (1.3370)  acc1: 62.2549 (69.8076)  acc5: 83.8235 (89.9691)  time: 0.8042  data: 0.3878  max mem: 28602
Test:  [ 90/123]  eta: 0:00:30  loss: 1.7409 (1.3814)  acc1: 60.5392 (68.8672)  acc5: 83.3333 (89.3423)  time: 0.7946  data: 0.3779  max mem: 28602
Test:  [100/123]  eta: 0:00:20  loss: 1.7255 (1.4114)  acc1: 62.7451 (68.3411)  acc5: 83.3333 (88.8177)  time: 0.7664  data: 0.3474  max mem: 28602
Test:  [110/123]  eta: 0:00:11  loss: 1.7874 (1.4502)  acc1: 61.5196 (67.4572)  acc5: 81.8627 (88.2839)  time: 0.8108  data: 0.3917  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.5451 (1.4469)  acc1: 61.2745 (67.4627)  acc5: 87.0098 (88.4095)  time: 0.7847  data: 0.3705  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.5165 (1.4410)  acc1: 66.0714 (67.6140)  acc5: 88.2353 (88.4680)  time: 0.7603  data: 0.3568  max mem: 28602
Test: Total time: 0:01:47 (0.8768 s / it)
* Acc@1 67.614 Acc@5 88.468 loss 1.441
Accuracy of the network on the 50000 test images: 67.6%
Max accuracy: 67.96%
Epoch: [61]  [   0/1255]  eta: 3:51:36  lr: 0.001202  loss: 4.5328 (4.5328)  time: 11.0727  data: 9.6172  max mem: 28602
Epoch: [61]  [ 100/1255]  eta: 0:29:04  lr: 0.001202  loss: 3.9566 (3.9292)  time: 1.4178  data: 0.0003  max mem: 28602
Epoch: [61]  [ 200/1255]  eta: 0:25:42  lr: 0.001202  loss: 4.3263 (3.9805)  time: 1.4163  data: 0.0003  max mem: 28602
Epoch: [61]  [ 300/1255]  eta: 0:22:58  lr: 0.001202  loss: 3.9612 (3.9558)  time: 1.4117  data: 0.0004  max mem: 28602
Epoch: [61]  [ 400/1255]  eta: 0:20:28  lr: 0.001202  loss: 4.1314 (3.9689)  time: 1.4072  data: 0.0003  max mem: 28602
Epoch: [61]  [ 500/1255]  eta: 0:18:00  lr: 0.001202  loss: 4.0917 (3.9665)  time: 1.4119  data: 0.0003  max mem: 28602
Epoch: [61]  [ 600/1255]  eta: 0:15:34  lr: 0.001202  loss: 4.0724 (3.9712)  time: 1.4077  data: 0.0003  max mem: 28602
Epoch: [61]  [ 700/1255]  eta: 0:13:10  lr: 0.001202  loss: 4.0875 (3.9713)  time: 1.4121  data: 0.0003  max mem: 28602
Epoch: [61]  [ 800/1255]  eta: 0:10:47  lr: 0.001202  loss: 4.3093 (3.9693)  time: 1.4068  data: 0.0003  max mem: 28602
Epoch: [61]  [ 900/1255]  eta: 0:08:24  lr: 0.001202  loss: 4.1262 (3.9715)  time: 1.4426  data: 0.0003  max mem: 28602
Epoch: [61]  [1000/1255]  eta: 0:06:02  lr: 0.001202  loss: 4.1147 (3.9750)  time: 1.4123  data: 0.0003  max mem: 28602
Epoch: [61]  [1100/1255]  eta: 0:03:40  lr: 0.001202  loss: 4.1990 (3.9737)  time: 1.4003  data: 0.0003  max mem: 28602
Epoch: [61]  [1200/1255]  eta: 0:01:18  lr: 0.001202  loss: 4.1219 (3.9708)  time: 1.4081  data: 0.0003  max mem: 28602
Epoch: [61]  [1254/1255]  eta: 0:00:01  lr: 0.001202  loss: 4.2443 (3.9705)  time: 1.3808  data: 0.0004  max mem: 28602
Epoch: [61] Total time: 0:29:40 (1.4190 s / it)
Averaged stats: lr: 0.001202  loss: 4.2443 (3.9685)
Test:  [  0/123]  eta: 0:23:35  loss: 1.0716 (1.0716)  acc1: 76.9608 (76.9608)  acc5: 92.6471 (92.6471)  time: 11.5045  data: 11.0756  max mem: 28602
Test:  [ 10/123]  eta: 0:03:16  loss: 1.1260 (1.1041)  acc1: 73.0392 (75.0223)  acc5: 92.6471 (92.7585)  time: 1.7403  data: 1.3223  max mem: 28602
Test:  [ 20/123]  eta: 0:02:14  loss: 1.1260 (1.0807)  acc1: 75.0000 (76.1905)  acc5: 93.1373 (92.8338)  time: 0.7994  data: 0.3825  max mem: 28602
Test:  [ 30/123]  eta: 0:01:44  loss: 1.1778 (1.1465)  acc1: 72.3039 (73.3001)  acc5: 93.3824 (92.8052)  time: 0.7861  data: 0.3683  max mem: 28602
Test:  [ 40/123]  eta: 0:01:29  loss: 1.1778 (1.1275)  acc1: 66.9118 (73.7327)  acc5: 93.6275 (93.1492)  time: 0.8329  data: 0.4218  max mem: 28602
Test:  [ 50/123]  eta: 0:01:14  loss: 1.1032 (1.1421)  acc1: 74.2647 (73.4717)  acc5: 92.8922 (92.8585)  time: 0.8601  data: 0.4498  max mem: 28602
Test:  [ 60/123]  eta: 0:01:01  loss: 1.3427 (1.2322)  acc1: 67.8922 (71.4843)  acc5: 88.7255 (91.5140)  time: 0.7840  data: 0.3692  max mem: 28602
Test:  [ 70/123]  eta: 0:00:50  loss: 1.5998 (1.2749)  acc1: 65.4412 (70.7229)  acc5: 85.7843 (90.8313)  time: 0.7921  data: 0.3781  max mem: 28602
Test:  [ 80/123]  eta: 0:00:40  loss: 1.5998 (1.3322)  acc1: 61.2745 (69.4929)  acc5: 83.5784 (89.9691)  time: 0.8007  data: 0.3905  max mem: 28602
Test:  [ 90/123]  eta: 0:00:30  loss: 1.6379 (1.3626)  acc1: 62.2549 (69.1338)  acc5: 83.8235 (89.5173)  time: 0.7740  data: 0.3662  max mem: 28602
Test:  [100/123]  eta: 0:00:20  loss: 1.6180 (1.3963)  acc1: 64.2157 (68.5207)  acc5: 85.2941 (88.9488)  time: 0.7549  data: 0.3402  max mem: 28602
Test:  [110/123]  eta: 0:00:11  loss: 1.8224 (1.4337)  acc1: 59.8039 (67.6382)  acc5: 82.3529 (88.3854)  time: 0.8121  data: 0.3933  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.5451 (1.4293)  acc1: 60.5392 (67.6390)  acc5: 87.9902 (88.5108)  time: 0.7882  data: 0.3737  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.5194 (1.4226)  acc1: 62.9902 (67.7980)  acc5: 88.9706 (88.5740)  time: 0.7721  data: 0.3678  max mem: 28602
Test: Total time: 0:01:47 (0.8749 s / it)
* Acc@1 67.798 Acc@5 88.574 loss 1.423
Accuracy of the network on the 50000 test images: 67.8%
Max accuracy: 67.96%
Epoch: [62]  [   0/1255]  eta: 3:32:16  lr: 0.001198  loss: 4.3244 (4.3244)  time: 10.1487  data: 8.6725  max mem: 28602
Epoch: [62]  [ 100/1255]  eta: 0:29:11  lr: 0.001198  loss: 4.2184 (4.0025)  time: 1.4499  data: 0.0004  max mem: 28602
Epoch: [62]  [ 200/1255]  eta: 0:25:49  lr: 0.001198  loss: 4.2729 (3.9671)  time: 1.4059  data: 0.0004  max mem: 28602
Epoch: [62]  [ 300/1255]  eta: 0:23:06  lr: 0.001198  loss: 3.9339 (3.9416)  time: 1.4195  data: 0.0003  max mem: 28602
Epoch: [62]  [ 400/1255]  eta: 0:20:35  lr: 0.001198  loss: 4.0311 (3.9531)  time: 1.4174  data: 0.0004  max mem: 28602
Epoch: [62]  [ 500/1255]  eta: 0:18:04  lr: 0.001198  loss: 4.1221 (3.9431)  time: 1.4087  data: 0.0003  max mem: 28602
Epoch: [62]  [ 600/1255]  eta: 0:15:37  lr: 0.001198  loss: 4.0424 (3.9630)  time: 1.4172  data: 0.0003  max mem: 28602
Epoch: [62]  [ 700/1255]  eta: 0:13:13  lr: 0.001198  loss: 4.3005 (3.9815)  time: 1.4133  data: 0.0003  max mem: 28602
Epoch: [62]  [ 800/1255]  eta: 0:10:49  lr: 0.001198  loss: 3.8717 (3.9801)  time: 1.4070  data: 0.0003  max mem: 28602
Epoch: [62]  [ 900/1255]  eta: 0:08:25  lr: 0.001198  loss: 3.9253 (3.9785)  time: 1.4163  data: 0.0003  max mem: 28602
Epoch: [62]  [1000/1255]  eta: 0:06:03  lr: 0.001198  loss: 4.1334 (3.9812)  time: 1.4151  data: 0.0003  max mem: 28602
Epoch: [62]  [1100/1255]  eta: 0:03:40  lr: 0.001198  loss: 3.9807 (3.9769)  time: 1.4164  data: 0.0003  max mem: 28602
Epoch: [62]  [1200/1255]  eta: 0:01:18  lr: 0.001198  loss: 4.1317 (3.9705)  time: 1.4161  data: 0.0003  max mem: 28602
Epoch: [62]  [1254/1255]  eta: 0:00:01  lr: 0.001198  loss: 3.8512 (3.9724)  time: 1.3816  data: 0.0008  max mem: 28602
Epoch: [62] Total time: 0:29:45 (1.4225 s / it)
Averaged stats: lr: 0.001198  loss: 3.8512 (3.9744)
Test:  [  0/123]  eta: 0:25:16  loss: 1.1225 (1.1225)  acc1: 71.5686 (71.5686)  acc5: 92.1569 (92.1569)  time: 12.3319  data: 11.8238  max mem: 28602
Test:  [ 10/123]  eta: 0:03:28  loss: 1.1225 (1.0527)  acc1: 71.5686 (75.1337)  acc5: 92.1569 (93.0704)  time: 1.8424  data: 1.4141  max mem: 28602
Test:  [ 20/123]  eta: 0:02:19  loss: 0.9887 (1.0404)  acc1: 76.2255 (76.1555)  acc5: 93.8726 (92.9855)  time: 0.8047  data: 0.3818  max mem: 28602
Test:  [ 30/123]  eta: 0:01:49  loss: 1.1554 (1.0954)  acc1: 70.8333 (73.9405)  acc5: 93.6275 (92.8763)  time: 0.8141  data: 0.3920  max mem: 28602
Test:  [ 40/123]  eta: 0:01:33  loss: 1.1554 (1.0767)  acc1: 69.6078 (74.3305)  acc5: 94.3627 (93.2987)  time: 0.8779  data: 0.4565  max mem: 28602
Test:  [ 50/123]  eta: 0:01:17  loss: 1.0698 (1.0887)  acc1: 73.2843 (74.1542)  acc5: 94.1177 (93.0796)  time: 0.8918  data: 0.4654  max mem: 28602
Test:  [ 60/123]  eta: 0:01:04  loss: 1.2530 (1.1762)  acc1: 68.1373 (72.3039)  acc5: 88.9706 (91.9680)  time: 0.8131  data: 0.3858  max mem: 28602
Test:  [ 70/123]  eta: 0:00:52  loss: 1.5458 (1.2299)  acc1: 62.7451 (71.2959)  acc5: 86.5196 (91.1972)  time: 0.8227  data: 0.4014  max mem: 28602
Test:  [ 80/123]  eta: 0:00:41  loss: 1.7030 (1.2998)  acc1: 61.5196 (69.8590)  acc5: 83.8235 (90.2052)  time: 0.8394  data: 0.4200  max mem: 28602
Test:  [ 90/123]  eta: 0:00:31  loss: 1.7371 (1.3365)  acc1: 60.7843 (69.0826)  acc5: 83.8235 (89.7059)  time: 0.8134  data: 0.3866  max mem: 28602
Test:  [100/123]  eta: 0:00:21  loss: 1.7344 (1.3689)  acc1: 62.9902 (68.4576)  acc5: 85.5392 (89.2181)  time: 0.7994  data: 0.3678  max mem: 28602
Test:  [110/123]  eta: 0:00:12  loss: 1.7464 (1.4048)  acc1: 62.0098 (67.6471)  acc5: 85.0490 (88.7476)  time: 0.8350  data: 0.4025  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.4604 (1.3982)  acc1: 62.2549 (67.6815)  acc5: 88.7255 (88.8997)  time: 0.7683  data: 0.3455  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.4259 (1.3926)  acc1: 65.4412 (67.8180)  acc5: 88.9706 (88.9540)  time: 0.7573  data: 0.3454  max mem: 28602
Test: Total time: 0:01:51 (0.9047 s / it)
* Acc@1 67.818 Acc@5 88.954 loss 1.393
Accuracy of the network on the 50000 test images: 67.8%
Max accuracy: 67.96%
Epoch: [63]  [   0/1255]  eta: 4:01:24  lr: 0.001194  loss: 4.3641 (4.3641)  time: 11.5413  data: 10.0876  max mem: 28602
Epoch: [63]  [ 100/1255]  eta: 0:29:27  lr: 0.001194  loss: 3.9706 (3.9655)  time: 1.4152  data: 0.0003  max mem: 28602
Epoch: [63]  [ 200/1255]  eta: 0:25:55  lr: 0.001194  loss: 4.0824 (3.9331)  time: 1.4223  data: 0.0003  max mem: 28602
Epoch: [63]  [ 300/1255]  eta: 0:23:09  lr: 0.001194  loss: 4.1443 (3.9569)  time: 1.4173  data: 0.0003  max mem: 28602
Epoch: [63]  [ 400/1255]  eta: 0:20:35  lr: 0.001194  loss: 4.2952 (3.9721)  time: 1.4047  data: 0.0003  max mem: 28602
Epoch: [63]  [ 500/1255]  eta: 0:18:06  lr: 0.001194  loss: 3.9362 (3.9559)  time: 1.4191  data: 0.0003  max mem: 28602
Epoch: [63]  [ 600/1255]  eta: 0:15:39  lr: 0.001194  loss: 4.3076 (3.9589)  time: 1.4129  data: 0.0003  max mem: 28602
Epoch: [63]  [ 700/1255]  eta: 0:13:13  lr: 0.001194  loss: 4.2627 (3.9676)  time: 1.4118  data: 0.0003  max mem: 28602
Epoch: [63]  [ 800/1255]  eta: 0:10:49  lr: 0.001194  loss: 4.0153 (3.9773)  time: 1.4082  data: 0.0003  max mem: 28602
Epoch: [63]  [ 900/1255]  eta: 0:08:26  lr: 0.001194  loss: 3.8373 (3.9709)  time: 1.4129  data: 0.0003  max mem: 28602
Epoch: [63]  [1000/1255]  eta: 0:06:03  lr: 0.001194  loss: 3.8311 (3.9633)  time: 1.4094  data: 0.0003  max mem: 28602
Epoch: [63]  [1100/1255]  eta: 0:03:40  lr: 0.001194  loss: 4.0679 (3.9690)  time: 1.4133  data: 0.0003  max mem: 28602
Epoch: [63]  [1200/1255]  eta: 0:01:18  lr: 0.001194  loss: 4.0200 (3.9666)  time: 1.4275  data: 0.0003  max mem: 28602
Epoch: [63]  [1254/1255]  eta: 0:00:01  lr: 0.001194  loss: 4.2294 (3.9746)  time: 1.3773  data: 0.0008  max mem: 28602
Epoch: [63] Total time: 0:29:44 (1.4222 s / it)
Averaged stats: lr: 0.001194  loss: 4.2294 (3.9686)
Test:  [  0/123]  eta: 0:24:42  loss: 1.0679 (1.0679)  acc1: 74.2647 (74.2647)  acc5: 92.4020 (92.4020)  time: 12.0514  data: 11.6121  max mem: 28602
Test:  [ 10/123]  eta: 0:03:21  loss: 1.1501 (1.1502)  acc1: 73.2843 (73.9528)  acc5: 92.4020 (92.1123)  time: 1.7855  data: 1.3603  max mem: 28602
Test:  [ 20/123]  eta: 0:02:18  loss: 1.0580 (1.0819)  acc1: 75.7353 (76.2138)  acc5: 92.8922 (92.6937)  time: 0.8057  data: 0.3904  max mem: 28602
Test:  [ 30/123]  eta: 0:01:47  loss: 1.1861 (1.1501)  acc1: 72.3039 (73.8694)  acc5: 93.3824 (92.6392)  time: 0.8119  data: 0.4001  max mem: 28602
Test:  [ 40/123]  eta: 0:01:31  loss: 1.1734 (1.1162)  acc1: 71.0784 (74.6832)  acc5: 93.6275 (93.1970)  time: 0.8497  data: 0.4260  max mem: 28602
Test:  [ 50/123]  eta: 0:01:16  loss: 1.0720 (1.1340)  acc1: 74.0196 (74.2935)  acc5: 94.1177 (92.9354)  time: 0.8756  data: 0.4477  max mem: 28602
Test:  [ 60/123]  eta: 0:01:03  loss: 1.4178 (1.2239)  acc1: 66.9118 (72.3280)  acc5: 88.9706 (91.7631)  time: 0.8063  data: 0.3869  max mem: 28602
Test:  [ 70/123]  eta: 0:00:51  loss: 1.6265 (1.2744)  acc1: 64.7059 (71.3684)  acc5: 86.0294 (91.0764)  time: 0.8105  data: 0.3941  max mem: 28602
Test:  [ 80/123]  eta: 0:00:41  loss: 1.6265 (1.3370)  acc1: 63.2353 (70.1222)  acc5: 83.5784 (90.1840)  time: 0.8284  data: 0.4088  max mem: 28602
Test:  [ 90/123]  eta: 0:00:31  loss: 1.6738 (1.3725)  acc1: 62.0098 (69.4085)  acc5: 83.5784 (89.6412)  time: 0.8117  data: 0.3970  max mem: 28602
Test:  [100/123]  eta: 0:00:21  loss: 1.6670 (1.4065)  acc1: 62.5000 (68.7197)  acc5: 84.8039 (89.0361)  time: 0.7809  data: 0.3714  max mem: 28602
Test:  [110/123]  eta: 0:00:11  loss: 1.8265 (1.4448)  acc1: 59.5588 (67.8060)  acc5: 83.0882 (88.5488)  time: 0.8119  data: 0.4029  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.5553 (1.4433)  acc1: 62.2549 (67.7706)  acc5: 85.0490 (88.6404)  time: 0.7625  data: 0.3514  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.5241 (1.4387)  acc1: 62.2549 (67.9040)  acc5: 87.9902 (88.6900)  time: 0.7539  data: 0.3513  max mem: 28602
Test: Total time: 0:01:49 (0.8911 s / it)
* Acc@1 67.904 Acc@5 88.690 loss 1.439
Accuracy of the network on the 50000 test images: 67.9%
Max accuracy: 67.96%
Epoch: [64]  [   0/1255]  eta: 4:06:05  lr: 0.001190  loss: 4.0998 (4.0998)  time: 11.7651  data: 10.3496  max mem: 28602
Epoch: [64]  [ 100/1255]  eta: 0:29:23  lr: 0.001190  loss: 3.4795 (3.8832)  time: 1.4132  data: 0.0004  max mem: 28602
Epoch: [64]  [ 200/1255]  eta: 0:25:57  lr: 0.001190  loss: 4.0562 (3.9032)  time: 1.4221  data: 0.0004  max mem: 28602
Epoch: [64]  [ 300/1255]  eta: 0:23:11  lr: 0.001190  loss: 4.2077 (3.9154)  time: 1.4188  data: 0.0004  max mem: 28602
Epoch: [64]  [ 400/1255]  eta: 0:20:37  lr: 0.001190  loss: 4.2387 (3.9350)  time: 1.4148  data: 0.0004  max mem: 28602
Epoch: [64]  [ 500/1255]  eta: 0:18:06  lr: 0.001190  loss: 4.0892 (3.9480)  time: 1.4053  data: 0.0003  max mem: 28602
Epoch: [64]  [ 600/1255]  eta: 0:15:38  lr: 0.001190  loss: 4.0292 (3.9653)  time: 1.3980  data: 0.0003  max mem: 28602
Epoch: [64]  [ 700/1255]  eta: 0:13:12  lr: 0.001190  loss: 4.2632 (3.9659)  time: 1.3937  data: 0.0003  max mem: 28602
Epoch: [64]  [ 800/1255]  eta: 0:10:48  lr: 0.001190  loss: 4.0269 (3.9674)  time: 1.3962  data: 0.0003  max mem: 28602
Epoch: [64]  [ 900/1255]  eta: 0:08:24  lr: 0.001190  loss: 4.1184 (3.9592)  time: 1.4063  data: 0.0003  max mem: 28602
Epoch: [64]  [1000/1255]  eta: 0:06:02  lr: 0.001190  loss: 3.7168 (3.9535)  time: 1.3947  data: 0.0003  max mem: 28602
Epoch: [64]  [1100/1255]  eta: 0:03:39  lr: 0.001190  loss: 3.8685 (3.9503)  time: 1.4029  data: 0.0003  max mem: 28602
Epoch: [64]  [1200/1255]  eta: 0:01:17  lr: 0.001190  loss: 4.1443 (3.9596)  time: 1.4076  data: 0.0003  max mem: 28602
Epoch: [64]  [1254/1255]  eta: 0:00:01  lr: 0.001190  loss: 4.1162 (3.9505)  time: 1.3656  data: 0.0004  max mem: 28602
Epoch: [64] Total time: 0:29:36 (1.4159 s / it)
Averaged stats: lr: 0.001190  loss: 4.1162 (3.9561)
Test:  [  0/123]  eta: 0:22:47  loss: 1.1012 (1.1012)  acc1: 71.8137 (71.8137)  acc5: 94.1177 (94.1177)  time: 11.1158  data: 10.6666  max mem: 28602
Test:  [ 10/123]  eta: 0:03:12  loss: 1.1012 (1.0938)  acc1: 71.8137 (74.5544)  acc5: 94.1177 (92.7808)  time: 1.7036  data: 1.2905  max mem: 28602
Test:  [ 20/123]  eta: 0:02:09  loss: 1.1157 (1.0672)  acc1: 74.7549 (75.7703)  acc5: 92.8922 (92.9739)  time: 0.7667  data: 0.3574  max mem: 28602
Test:  [ 30/123]  eta: 0:01:40  loss: 1.1624 (1.1142)  acc1: 71.8137 (73.7508)  acc5: 93.1373 (92.9317)  time: 0.7420  data: 0.3362  max mem: 28602
Test:  [ 40/123]  eta: 0:01:26  loss: 1.0955 (1.0901)  acc1: 71.0784 (74.4680)  acc5: 94.1177 (93.3345)  time: 0.8030  data: 0.3976  max mem: 28602
Test:  [ 50/123]  eta: 0:01:11  loss: 1.0684 (1.1017)  acc1: 75.0000 (74.1974)  acc5: 93.8726 (93.1997)  time: 0.8296  data: 0.4162  max mem: 28602
Test:  [ 60/123]  eta: 0:00:59  loss: 1.2415 (1.1937)  acc1: 67.6471 (72.2477)  acc5: 88.2353 (91.8716)  time: 0.7561  data: 0.3386  max mem: 28602
Test:  [ 70/123]  eta: 0:00:49  loss: 1.5569 (1.2425)  acc1: 62.5000 (71.3408)  acc5: 86.2745 (91.1316)  time: 0.7789  data: 0.3661  max mem: 28602
Test:  [ 80/123]  eta: 0:00:39  loss: 1.5569 (1.2937)  acc1: 62.7451 (70.2856)  acc5: 85.5392 (90.3837)  time: 0.8042  data: 0.3935  max mem: 28602
Test:  [ 90/123]  eta: 0:00:29  loss: 1.6528 (1.3341)  acc1: 61.5196 (69.4543)  acc5: 85.5392 (89.7948)  time: 0.7699  data: 0.3560  max mem: 28602
Test:  [100/123]  eta: 0:00:20  loss: 1.6528 (1.3683)  acc1: 62.5000 (68.8337)  acc5: 86.0294 (89.2788)  time: 0.7383  data: 0.3216  max mem: 28602
Test:  [110/123]  eta: 0:00:11  loss: 1.8157 (1.4052)  acc1: 60.2941 (68.0534)  acc5: 82.8431 (88.7630)  time: 0.7716  data: 0.3561  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.4991 (1.4024)  acc1: 60.2941 (68.0988)  acc5: 87.2549 (88.9017)  time: 0.7032  data: 0.2917  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.4784 (1.3968)  acc1: 63.8393 (68.2400)  acc5: 88.4804 (88.9660)  time: 0.6925  data: 0.2917  max mem: 28602
Test: Total time: 0:01:43 (0.8409 s / it)
* Acc@1 68.240 Acc@5 88.966 loss 1.397
Accuracy of the network on the 50000 test images: 68.2%
Max accuracy: 68.24%
Epoch: [65]  [   0/1255]  eta: 3:56:08  lr: 0.001186  loss: 4.1193 (4.1193)  time: 11.2894  data: 9.8538  max mem: 28602
Epoch: [65]  [ 100/1255]  eta: 0:28:59  lr: 0.001186  loss: 4.0488 (3.9579)  time: 1.3963  data: 0.0003  max mem: 28602
Epoch: [65]  [ 200/1255]  eta: 0:25:37  lr: 0.001186  loss: 4.0031 (3.9014)  time: 1.4065  data: 0.0003  max mem: 28602
Epoch: [65]  [ 300/1255]  eta: 0:22:55  lr: 0.001186  loss: 4.2843 (3.8896)  time: 1.4218  data: 0.0003  max mem: 28602
Epoch: [65]  [ 400/1255]  eta: 0:20:23  lr: 0.001186  loss: 4.1784 (3.9179)  time: 1.3991  data: 0.0003  max mem: 28602
Epoch: [65]  [ 500/1255]  eta: 0:17:56  lr: 0.001186  loss: 4.3450 (3.9301)  time: 1.4027  data: 0.0003  max mem: 28602
Epoch: [65]  [ 600/1255]  eta: 0:15:31  lr: 0.001186  loss: 4.0911 (3.9394)  time: 1.4032  data: 0.0003  max mem: 28602
Epoch: [65]  [ 700/1255]  eta: 0:13:08  lr: 0.001186  loss: 3.6530 (3.9353)  time: 1.4205  data: 0.0003  max mem: 28602
Epoch: [65]  [ 800/1255]  eta: 0:10:45  lr: 0.001186  loss: 3.8910 (3.9352)  time: 1.4152  data: 0.0003  max mem: 28602
Epoch: [65]  [ 900/1255]  eta: 0:08:23  lr: 0.001186  loss: 4.0546 (3.9381)  time: 1.4130  data: 0.0003  max mem: 28602
Epoch: [65]  [1000/1255]  eta: 0:06:01  lr: 0.001186  loss: 4.4060 (3.9550)  time: 1.4226  data: 0.0003  max mem: 28602
Epoch: [65]  [1100/1255]  eta: 0:03:39  lr: 0.001186  loss: 4.0225 (3.9601)  time: 1.4132  data: 0.0003  max mem: 28602
Epoch: [65]  [1200/1255]  eta: 0:01:17  lr: 0.001186  loss: 4.0305 (3.9680)  time: 1.4165  data: 0.0003  max mem: 28602
Epoch: [65]  [1254/1255]  eta: 0:00:01  lr: 0.001186  loss: 4.0445 (3.9628)  time: 1.3847  data: 0.0008  max mem: 28602
Epoch: [65] Total time: 0:29:37 (1.4163 s / it)
Averaged stats: lr: 0.001186  loss: 4.0445 (3.9673)
Test:  [  0/123]  eta: 0:24:59  loss: 0.9332 (0.9332)  acc1: 79.6569 (79.6569)  acc5: 94.8529 (94.8529)  time: 12.1896  data: 11.7016  max mem: 28602
Test:  [ 10/123]  eta: 0:03:23  loss: 1.1244 (1.0666)  acc1: 74.7549 (75.2674)  acc5: 92.6471 (92.6471)  time: 1.8002  data: 1.3815  max mem: 28602
Test:  [ 20/123]  eta: 0:02:18  loss: 1.1244 (1.0279)  acc1: 74.7549 (76.4239)  acc5: 92.4020 (92.9622)  time: 0.8001  data: 0.3840  max mem: 28602
Test:  [ 30/123]  eta: 0:01:46  loss: 1.1384 (1.0837)  acc1: 72.3039 (74.1066)  acc5: 92.1569 (93.0582)  time: 0.7889  data: 0.3657  max mem: 28602
Test:  [ 40/123]  eta: 0:01:31  loss: 1.1384 (1.0563)  acc1: 70.5882 (74.7429)  acc5: 94.1177 (93.5438)  time: 0.8435  data: 0.4169  max mem: 28602
Test:  [ 50/123]  eta: 0:01:16  loss: 1.0609 (1.0745)  acc1: 75.0000 (74.4281)  acc5: 93.6275 (93.2190)  time: 0.8983  data: 0.4737  max mem: 28602
Test:  [ 60/123]  eta: 0:01:03  loss: 1.3524 (1.1633)  acc1: 68.6275 (72.5289)  acc5: 88.2353 (91.9158)  time: 0.8047  data: 0.3822  max mem: 28602
Test:  [ 70/123]  eta: 0:00:51  loss: 1.5504 (1.2154)  acc1: 62.9902 (71.5997)  acc5: 86.7647 (91.2179)  time: 0.7991  data: 0.3766  max mem: 28602
Test:  [ 80/123]  eta: 0:00:41  loss: 1.6323 (1.2757)  acc1: 62.5000 (70.4763)  acc5: 84.0686 (90.3383)  time: 0.8591  data: 0.4406  max mem: 28602
Test:  [ 90/123]  eta: 0:00:31  loss: 1.7213 (1.3145)  acc1: 62.5000 (69.6779)  acc5: 84.0686 (89.7759)  time: 0.8129  data: 0.3942  max mem: 28602
Test:  [100/123]  eta: 0:00:21  loss: 1.6672 (1.3503)  acc1: 63.7255 (68.9818)  acc5: 84.3137 (89.1987)  time: 0.7539  data: 0.3342  max mem: 28602
Test:  [110/123]  eta: 0:00:11  loss: 1.7180 (1.3893)  acc1: 61.5196 (68.1086)  acc5: 83.5784 (88.6703)  time: 0.8228  data: 0.4040  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.4888 (1.3841)  acc1: 62.0098 (68.1109)  acc5: 87.5000 (88.8187)  time: 0.7802  data: 0.3647  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.4014 (1.3786)  acc1: 62.5000 (68.2480)  acc5: 90.1786 (88.8800)  time: 0.7707  data: 0.3646  max mem: 28602
Test: Total time: 0:01:49 (0.8939 s / it)
* Acc@1 68.248 Acc@5 88.880 loss 1.379
Accuracy of the network on the 50000 test images: 68.2%
Max accuracy: 68.25%
Epoch: [66]  [   0/1255]  eta: 3:46:53  lr: 0.001181  loss: 4.6649 (4.6649)  time: 10.8473  data: 9.2219  max mem: 28602
Epoch: [66]  [ 100/1255]  eta: 0:29:15  lr: 0.001181  loss: 3.5113 (3.9383)  time: 1.4139  data: 0.0004  max mem: 28602
Epoch: [66]  [ 200/1255]  eta: 0:25:48  lr: 0.001181  loss: 4.2391 (3.9554)  time: 1.4167  data: 0.0003  max mem: 28602
Epoch: [66]  [ 300/1255]  eta: 0:23:04  lr: 0.001181  loss: 3.7594 (3.9335)  time: 1.4307  data: 0.0004  max mem: 28602
Epoch: [66]  [ 400/1255]  eta: 0:20:33  lr: 0.001181  loss: 4.1718 (3.9401)  time: 1.4125  data: 0.0003  max mem: 28602
Epoch: [66]  [ 500/1255]  eta: 0:18:04  lr: 0.001181  loss: 4.0136 (3.9330)  time: 1.4324  data: 0.0004  max mem: 28602
Epoch: [66]  [ 600/1255]  eta: 0:15:40  lr: 0.001181  loss: 4.0009 (3.9281)  time: 1.4255  data: 0.0004  max mem: 28602
Epoch: [66]  [ 700/1255]  eta: 0:13:16  lr: 0.001181  loss: 4.0314 (3.9366)  time: 1.4337  data: 0.0004  max mem: 28602
Epoch: [66]  [ 800/1255]  eta: 0:10:53  lr: 0.001181  loss: 3.3917 (3.9371)  time: 1.4359  data: 0.0004  max mem: 28602
Epoch: [66]  [ 900/1255]  eta: 0:08:30  lr: 0.001181  loss: 4.0978 (3.9361)  time: 1.4413  data: 0.0004  max mem: 28602
Epoch: [66]  [1000/1255]  eta: 0:06:06  lr: 0.001181  loss: 4.0080 (3.9397)  time: 1.4474  data: 0.0004  max mem: 28602
Epoch: [66]  [1100/1255]  eta: 0:03:42  lr: 0.001181  loss: 4.2983 (3.9467)  time: 1.4243  data: 0.0004  max mem: 28602
Epoch: [66]  [1200/1255]  eta: 0:01:19  lr: 0.001181  loss: 3.6287 (3.9439)  time: 1.4193  data: 0.0003  max mem: 28602
Epoch: [66]  [1254/1255]  eta: 0:00:01  lr: 0.001181  loss: 4.1563 (3.9419)  time: 1.3947  data: 0.0008  max mem: 28602
Epoch: [66] Total time: 0:30:03 (1.4369 s / it)
Averaged stats: lr: 0.001181  loss: 4.1563 (3.9440)
Test:  [  0/123]  eta: 0:25:17  loss: 1.0603 (1.0603)  acc1: 73.2843 (73.2843)  acc5: 93.8726 (93.8726)  time: 12.3342  data: 11.8645  max mem: 28602
Test:  [ 10/123]  eta: 0:03:27  loss: 1.0603 (1.0943)  acc1: 73.2843 (74.7326)  acc5: 92.6471 (92.4020)  time: 1.8391  data: 1.4148  max mem: 28602
Test:  [ 20/123]  eta: 0:02:20  loss: 1.0504 (1.0334)  acc1: 75.0000 (76.4239)  acc5: 92.6471 (92.9155)  time: 0.8132  data: 0.3844  max mem: 28602
Test:  [ 30/123]  eta: 0:01:48  loss: 1.1455 (1.0827)  acc1: 73.0392 (74.1303)  acc5: 93.1373 (92.8843)  time: 0.8023  data: 0.3669  max mem: 28602
Test:  [ 40/123]  eta: 0:01:32  loss: 1.0861 (1.0643)  acc1: 71.3235 (74.6712)  acc5: 94.6078 (93.3046)  time: 0.8536  data: 0.4194  max mem: 28602
Test:  [ 50/123]  eta: 0:01:17  loss: 1.0498 (1.0814)  acc1: 75.7353 (74.4473)  acc5: 94.1177 (93.0075)  time: 0.8982  data: 0.4629  max mem: 28602
Test:  [ 60/123]  eta: 0:01:04  loss: 1.2874 (1.1647)  acc1: 70.8333 (72.7700)  acc5: 87.9902 (91.8354)  time: 0.8237  data: 0.3922  max mem: 28602
Test:  [ 70/123]  eta: 0:00:52  loss: 1.4924 (1.2122)  acc1: 63.4804 (71.7758)  acc5: 86.5196 (91.1868)  time: 0.8235  data: 0.3861  max mem: 28602
Test:  [ 80/123]  eta: 0:00:41  loss: 1.5677 (1.2719)  acc1: 63.4804 (70.6911)  acc5: 85.2941 (90.3322)  time: 0.8371  data: 0.3965  max mem: 28602
Test:  [ 90/123]  eta: 0:00:31  loss: 1.6272 (1.3087)  acc1: 62.9902 (69.9122)  acc5: 84.5588 (89.7948)  time: 0.8275  data: 0.3960  max mem: 28602
Test:  [100/123]  eta: 0:00:21  loss: 1.6235 (1.3383)  acc1: 64.2157 (69.4477)  acc5: 85.0490 (89.3249)  time: 0.8184  data: 0.3768  max mem: 28602
Test:  [110/123]  eta: 0:00:12  loss: 1.7246 (1.3737)  acc1: 61.7647 (68.6871)  acc5: 83.3333 (88.8315)  time: 0.8396  data: 0.3983  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.4935 (1.3751)  acc1: 62.2549 (68.5221)  acc5: 87.7451 (88.9118)  time: 0.7768  data: 0.3564  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.4033 (1.3687)  acc1: 63.8393 (68.6660)  acc5: 87.9902 (88.9760)  time: 0.7633  data: 0.3563  max mem: 28602
Test: Total time: 0:01:51 (0.9081 s / it)
* Acc@1 68.666 Acc@5 88.976 loss 1.369
Accuracy of the network on the 50000 test images: 68.7%
Max accuracy: 68.67%
Epoch: [67]  [   0/1255]  eta: 4:21:39  lr: 0.001177  loss: 2.9275 (2.9275)  time: 12.5092  data: 11.0010  max mem: 28602
Epoch: [67]  [ 100/1255]  eta: 0:32:01  lr: 0.001177  loss: 4.0063 (3.9662)  time: 1.5961  data: 0.0004  max mem: 28602
Epoch: [67]  [ 200/1255]  eta: 0:27:57  lr: 0.001177  loss: 3.7787 (3.9591)  time: 1.4690  data: 0.0003  max mem: 28602
Epoch: [67]  [ 300/1255]  eta: 0:24:51  lr: 0.001177  loss: 4.0170 (3.9615)  time: 1.5046  data: 0.0004  max mem: 28602
Epoch: [67]  [ 400/1255]  eta: 0:21:52  lr: 0.001177  loss: 4.0581 (3.9559)  time: 1.4338  data: 0.0004  max mem: 28602
Epoch: [67]  [ 500/1255]  eta: 0:19:06  lr: 0.001177  loss: 3.9036 (3.9596)  time: 1.4296  data: 0.0004  max mem: 28602
Epoch: [67]  [ 600/1255]  eta: 0:16:24  lr: 0.001177  loss: 3.9217 (3.9422)  time: 1.4341  data: 0.0004  max mem: 28602
Epoch: [67]  [ 700/1255]  eta: 0:13:49  lr: 0.001177  loss: 4.2134 (3.9486)  time: 1.4154  data: 0.0003  max mem: 28602
Epoch: [67]  [ 800/1255]  eta: 0:11:18  lr: 0.001177  loss: 4.1403 (3.9510)  time: 1.4436  data: 0.0004  max mem: 28602
Epoch: [67]  [ 900/1255]  eta: 0:08:48  lr: 0.001177  loss: 4.3269 (3.9634)  time: 1.4722  data: 0.0004  max mem: 28602
Epoch: [67]  [1000/1255]  eta: 0:06:19  lr: 0.001177  loss: 3.8953 (3.9589)  time: 1.6964  data: 0.0005  max mem: 28602
Epoch: [67]  [1100/1255]  eta: 0:03:50  lr: 0.001177  loss: 4.1915 (3.9580)  time: 1.4309  data: 0.0003  max mem: 28602
Epoch: [67]  [1200/1255]  eta: 0:01:21  lr: 0.001177  loss: 4.1123 (3.9609)  time: 1.5014  data: 0.0004  max mem: 28602
Epoch: [67]  [1254/1255]  eta: 0:00:01  lr: 0.001177  loss: 4.0755 (3.9609)  time: 1.4785  data: 0.0007  max mem: 28602
Epoch: [67] Total time: 0:30:58 (1.4810 s / it)
Averaged stats: lr: 0.001177  loss: 4.0755 (3.9538)
Test:  [  0/123]  eta: 0:25:53  loss: 1.0674 (1.0674)  acc1: 75.7353 (75.7353)  acc5: 93.8726 (93.8726)  time: 12.6338  data: 12.0996  max mem: 28602
Test:  [ 10/123]  eta: 0:03:30  loss: 1.2147 (1.1395)  acc1: 74.7549 (74.7549)  acc5: 91.9118 (92.2683)  time: 1.8621  data: 1.4232  max mem: 28602
Test:  [ 20/123]  eta: 0:02:18  loss: 1.2025 (1.1031)  acc1: 75.7353 (76.0621)  acc5: 91.9118 (92.5654)  time: 0.7760  data: 0.3500  max mem: 28602
Test:  [ 30/123]  eta: 0:01:49  loss: 1.1876 (1.1454)  acc1: 72.0588 (74.1619)  acc5: 93.3824 (92.7973)  time: 0.7933  data: 0.3670  max mem: 28602
Test:  [ 40/123]  eta: 0:01:30  loss: 1.1313 (1.1105)  acc1: 73.2843 (75.0598)  acc5: 94.1177 (93.3824)  time: 0.8305  data: 0.4104  max mem: 28602
Test:  [ 50/123]  eta: 0:01:15  loss: 1.0950 (1.1294)  acc1: 74.7549 (74.7068)  acc5: 93.8726 (93.0988)  time: 0.8354  data: 0.4175  max mem: 28602
Test:  [ 60/123]  eta: 0:01:02  loss: 1.3223 (1.2131)  acc1: 68.8726 (72.7097)  acc5: 89.9510 (91.9801)  time: 0.8099  data: 0.3876  max mem: 28602
Test:  [ 70/123]  eta: 0:00:52  loss: 1.6211 (1.2635)  acc1: 63.7255 (71.5962)  acc5: 86.2745 (91.2800)  time: 0.8338  data: 0.4132  max mem: 28602
Test:  [ 80/123]  eta: 0:00:41  loss: 1.6521 (1.3247)  acc1: 61.5196 (70.2796)  acc5: 84.3137 (90.3625)  time: 0.8314  data: 0.4105  max mem: 28602
Test:  [ 90/123]  eta: 0:00:31  loss: 1.6716 (1.3622)  acc1: 61.0294 (69.4920)  acc5: 84.8039 (89.8028)  time: 0.8018  data: 0.3814  max mem: 28602
Test:  [100/123]  eta: 0:00:21  loss: 1.6644 (1.3900)  acc1: 62.5000 (68.9551)  acc5: 85.2941 (89.3516)  time: 0.7913  data: 0.3666  max mem: 28602
Test:  [110/123]  eta: 0:00:11  loss: 1.7282 (1.4225)  acc1: 62.5000 (68.2984)  acc5: 83.3333 (88.8734)  time: 0.8314  data: 0.4050  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.4635 (1.4204)  acc1: 65.4412 (68.2669)  acc5: 88.4804 (88.9564)  time: 0.8010  data: 0.3834  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.4194 (1.4126)  acc1: 65.6863 (68.4200)  acc5: 89.2157 (89.0380)  time: 0.7914  data: 0.3833  max mem: 28602
Test: Total time: 0:01:50 (0.8975 s / it)
* Acc@1 68.420 Acc@5 89.038 loss 1.413
Accuracy of the network on the 50000 test images: 68.4%
Max accuracy: 68.67%
Epoch: [68]  [   0/1255]  eta: 4:08:55  lr: 0.001172  loss: 4.3850 (4.3850)  time: 11.9008  data: 10.4149  max mem: 28602
Epoch: [68]  [ 100/1255]  eta: 0:30:52  lr: 0.001172  loss: 3.9816 (3.8543)  time: 1.4977  data: 0.0004  max mem: 28602
Epoch: [68]  [ 200/1255]  eta: 0:26:43  lr: 0.001172  loss: 4.1149 (3.9376)  time: 1.4147  data: 0.0003  max mem: 28602
Epoch: [68]  [ 300/1255]  eta: 0:23:39  lr: 0.001172  loss: 4.0017 (3.9335)  time: 1.4307  data: 0.0004  max mem: 28602
Epoch: [68]  [ 400/1255]  eta: 0:20:56  lr: 0.001172  loss: 3.6200 (3.9202)  time: 1.4301  data: 0.0004  max mem: 28602
Epoch: [68]  [ 500/1255]  eta: 0:18:22  lr: 0.001172  loss: 4.0061 (3.9053)  time: 1.4187  data: 0.0004  max mem: 28602
Epoch: [68]  [ 600/1255]  eta: 0:15:52  lr: 0.001172  loss: 3.4716 (3.8962)  time: 1.4223  data: 0.0003  max mem: 28602
Epoch: [68]  [ 700/1255]  eta: 0:13:22  lr: 0.001172  loss: 3.8673 (3.9032)  time: 1.4184  data: 0.0004  max mem: 28602
Epoch: [68]  [ 800/1255]  eta: 0:10:56  lr: 0.001172  loss: 3.6595 (3.9071)  time: 1.4241  data: 0.0003  max mem: 28602
Epoch: [68]  [ 900/1255]  eta: 0:08:30  lr: 0.001172  loss: 3.7531 (3.8972)  time: 1.4115  data: 0.0003  max mem: 28602
Epoch: [68]  [1000/1255]  eta: 0:06:06  lr: 0.001172  loss: 3.9963 (3.8958)  time: 1.4133  data: 0.0003  max mem: 28602
Epoch: [68]  [1100/1255]  eta: 0:03:42  lr: 0.001172  loss: 4.1062 (3.8977)  time: 1.4158  data: 0.0003  max mem: 28602
Epoch: [68]  [1200/1255]  eta: 0:01:18  lr: 0.001172  loss: 4.1172 (3.9065)  time: 1.4192  data: 0.0003  max mem: 28602
Epoch: [68]  [1254/1255]  eta: 0:00:01  lr: 0.001172  loss: 3.9301 (3.9074)  time: 1.3767  data: 0.0007  max mem: 28602
Epoch: [68] Total time: 0:29:57 (1.4323 s / it)
Averaged stats: lr: 0.001172  loss: 3.9301 (3.9271)
Test:  [  0/123]  eta: 0:24:27  loss: 1.0741 (1.0741)  acc1: 74.0196 (74.0196)  acc5: 93.3824 (93.3824)  time: 11.9329  data: 11.4691  max mem: 28602
Test:  [ 10/123]  eta: 0:03:25  loss: 1.1294 (1.0711)  acc1: 74.0196 (75.4456)  acc5: 92.8922 (92.8030)  time: 1.8180  data: 1.3990  max mem: 28602
Test:  [ 20/123]  eta: 0:02:16  loss: 1.0403 (1.0136)  acc1: 76.2255 (76.9725)  acc5: 93.1373 (93.2773)  time: 0.7974  data: 0.3847  max mem: 28602
Test:  [ 30/123]  eta: 0:01:47  loss: 1.1054 (1.0758)  acc1: 74.0196 (74.6126)  acc5: 94.1177 (93.1768)  time: 0.7896  data: 0.3721  max mem: 28602
Test:  [ 40/123]  eta: 0:01:30  loss: 1.1054 (1.0444)  acc1: 70.5882 (75.2511)  acc5: 94.6078 (93.7171)  time: 0.8504  data: 0.4264  max mem: 28602
Test:  [ 50/123]  eta: 0:01:16  loss: 1.0165 (1.0637)  acc1: 74.5098 (74.8799)  acc5: 94.3627 (93.3968)  time: 0.8669  data: 0.4434  max mem: 28602
Test:  [ 60/123]  eta: 0:01:02  loss: 1.2320 (1.1570)  acc1: 69.3627 (72.9428)  acc5: 88.2353 (92.0323)  time: 0.8046  data: 0.3803  max mem: 28602
Test:  [ 70/123]  eta: 0:00:51  loss: 1.6346 (1.2086)  acc1: 62.0098 (71.9932)  acc5: 85.7843 (91.3111)  time: 0.8204  data: 0.3943  max mem: 28602
Test:  [ 80/123]  eta: 0:00:41  loss: 1.6376 (1.2692)  acc1: 62.2549 (70.7274)  acc5: 84.8039 (90.5168)  time: 0.8405  data: 0.4149  max mem: 28602
Test:  [ 90/123]  eta: 0:00:31  loss: 1.6582 (1.3088)  acc1: 62.0098 (69.9688)  acc5: 84.5588 (89.9133)  time: 0.8075  data: 0.3833  max mem: 28602
Test:  [100/123]  eta: 0:00:21  loss: 1.6197 (1.3386)  acc1: 62.9902 (69.3506)  acc5: 84.5588 (89.4171)  time: 0.7677  data: 0.3469  max mem: 28602
Test:  [110/123]  eta: 0:00:11  loss: 1.7571 (1.3793)  acc1: 59.3137 (68.3404)  acc5: 84.0686 (88.8580)  time: 0.8182  data: 0.3977  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.6539 (1.3776)  acc1: 59.3137 (68.3580)  acc5: 86.7647 (88.9503)  time: 0.7897  data: 0.3743  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.4690 (1.3723)  acc1: 65.6250 (68.4940)  acc5: 87.5000 (88.9980)  time: 0.7785  data: 0.3742  max mem: 28602
Test: Total time: 0:01:49 (0.8930 s / it)
* Acc@1 68.494 Acc@5 88.998 loss 1.372
Accuracy of the network on the 50000 test images: 68.5%
Max accuracy: 68.67%
Epoch: [69]  [   0/1255]  eta: 4:04:28  lr: 0.001168  loss: 4.0209 (4.0209)  time: 11.6879  data: 10.2376  max mem: 28602
Epoch: [69]  [ 100/1255]  eta: 0:29:22  lr: 0.001168  loss: 4.1013 (3.9898)  time: 1.4184  data: 0.0003  max mem: 28602
Epoch: [69]  [ 200/1255]  eta: 0:25:53  lr: 0.001168  loss: 4.3683 (3.9662)  time: 1.4151  data: 0.0003  max mem: 28602
Epoch: [69]  [ 300/1255]  eta: 0:23:06  lr: 0.001168  loss: 4.2123 (3.9513)  time: 1.4159  data: 0.0003  max mem: 28602
Epoch: [69]  [ 400/1255]  eta: 0:20:33  lr: 0.001168  loss: 3.6867 (3.9581)  time: 1.4077  data: 0.0003  max mem: 28602
Epoch: [69]  [ 500/1255]  eta: 0:18:04  lr: 0.001168  loss: 4.0327 (3.9582)  time: 1.4135  data: 0.0003  max mem: 28602
Epoch: [69]  [ 600/1255]  eta: 0:15:38  lr: 0.001168  loss: 4.3335 (3.9648)  time: 1.4177  data: 0.0003  max mem: 28602
Epoch: [69]  [ 700/1255]  eta: 0:13:13  lr: 0.001168  loss: 4.1220 (3.9594)  time: 1.4132  data: 0.0004  max mem: 28602
Epoch: [69]  [ 800/1255]  eta: 0:10:49  lr: 0.001168  loss: 4.1032 (3.9683)  time: 1.4027  data: 0.0003  max mem: 28602
Epoch: [69]  [ 900/1255]  eta: 0:08:25  lr: 0.001168  loss: 4.1196 (3.9570)  time: 1.4077  data: 0.0004  max mem: 28602
Epoch: [69]  [1000/1255]  eta: 0:06:03  lr: 0.001168  loss: 3.7334 (3.9531)  time: 1.4132  data: 0.0003  max mem: 28602
Epoch: [69]  [1100/1255]  eta: 0:03:40  lr: 0.001168  loss: 4.0884 (3.9531)  time: 1.4061  data: 0.0004  max mem: 28602
Epoch: [69]  [1200/1255]  eta: 0:01:18  lr: 0.001168  loss: 4.2975 (3.9524)  time: 1.4090  data: 0.0003  max mem: 28602
Epoch: [69]  [1254/1255]  eta: 0:00:01  lr: 0.001168  loss: 3.6496 (3.9482)  time: 1.3784  data: 0.0007  max mem: 28602
Epoch: [69] Total time: 0:29:43 (1.4213 s / it)
Averaged stats: lr: 0.001168  loss: 3.6496 (3.9372)
Test:  [  0/123]  eta: 0:24:39  loss: 0.9998 (0.9998)  acc1: 75.2451 (75.2451)  acc5: 93.8726 (93.8726)  time: 12.0319  data: 11.5404  max mem: 28602
Test:  [ 10/123]  eta: 0:03:24  loss: 1.1136 (1.0800)  acc1: 73.2843 (74.9777)  acc5: 92.8922 (92.5134)  time: 1.8091  data: 1.3724  max mem: 28602
Test:  [ 20/123]  eta: 0:02:16  loss: 1.1014 (1.0133)  acc1: 77.2059 (77.2176)  acc5: 92.8922 (93.1373)  time: 0.7944  data: 0.3715  max mem: 28602
Test:  [ 30/123]  eta: 0:01:47  loss: 1.1247 (1.0722)  acc1: 73.7745 (75.0791)  acc5: 93.1373 (93.2084)  time: 0.7989  data: 0.3807  max mem: 28602
Test:  [ 40/123]  eta: 0:01:32  loss: 1.1400 (1.0447)  acc1: 72.0588 (75.7891)  acc5: 94.6078 (93.6275)  time: 0.8771  data: 0.4545  max mem: 28602
Test:  [ 50/123]  eta: 0:01:16  loss: 0.9854 (1.0544)  acc1: 76.9608 (75.6536)  acc5: 93.8726 (93.4112)  time: 0.8902  data: 0.4673  max mem: 28602
Test:  [ 60/123]  eta: 0:01:03  loss: 1.2890 (1.1459)  acc1: 69.8529 (73.6741)  acc5: 89.2157 (92.1287)  time: 0.8232  data: 0.4019  max mem: 28602
Test:  [ 70/123]  eta: 0:00:52  loss: 1.5317 (1.1973)  acc1: 64.7059 (72.5007)  acc5: 84.8039 (91.3836)  time: 0.8333  data: 0.4133  max mem: 28602
Test:  [ 80/123]  eta: 0:00:41  loss: 1.6107 (1.2584)  acc1: 60.2941 (71.1117)  acc5: 84.5588 (90.5531)  time: 0.8270  data: 0.4034  max mem: 28602
Test:  [ 90/123]  eta: 0:00:31  loss: 1.5664 (1.2869)  acc1: 64.9510 (70.5909)  acc5: 85.7843 (90.1287)  time: 0.8139  data: 0.3905  max mem: 28602
Test:  [100/123]  eta: 0:00:21  loss: 1.5197 (1.3198)  acc1: 66.6667 (69.9694)  acc5: 85.7843 (89.6404)  time: 0.7769  data: 0.3564  max mem: 28602
Test:  [110/123]  eta: 0:00:12  loss: 1.6963 (1.3566)  acc1: 62.7451 (69.0514)  acc5: 84.0686 (89.1671)  time: 0.8100  data: 0.3885  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.4214 (1.3550)  acc1: 62.7451 (69.0407)  acc5: 87.5000 (89.2825)  time: 0.7702  data: 0.3573  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.3847 (1.3500)  acc1: 65.4412 (69.1660)  acc5: 88.4804 (89.3480)  time: 0.7603  data: 0.3572  max mem: 28602
Test: Total time: 0:01:50 (0.8974 s / it)
* Acc@1 69.166 Acc@5 89.348 loss 1.350
Accuracy of the network on the 50000 test images: 69.2%
Max accuracy: 69.17%
Epoch: [70]  [   0/1255]  eta: 4:00:18  lr: 0.001163  loss: 4.2039 (4.2039)  time: 11.4889  data: 10.0430  max mem: 28602
Epoch: [70]  [ 100/1255]  eta: 0:29:19  lr: 0.001163  loss: 4.0599 (3.9014)  time: 1.4217  data: 0.0003  max mem: 28602
Epoch: [70]  [ 200/1255]  eta: 0:25:48  lr: 0.001163  loss: 4.1358 (3.8940)  time: 1.4136  data: 0.0004  max mem: 28602
Epoch: [70]  [ 300/1255]  eta: 0:23:05  lr: 0.001163  loss: 3.6162 (3.9179)  time: 1.4178  data: 0.0003  max mem: 28602
Epoch: [70]  [ 400/1255]  eta: 0:20:32  lr: 0.001163  loss: 3.9930 (3.9249)  time: 1.4190  data: 0.0004  max mem: 28602
Epoch: [70]  [ 500/1255]  eta: 0:18:05  lr: 0.001163  loss: 3.8386 (3.9262)  time: 1.4280  data: 0.0004  max mem: 28602
Epoch: [70]  [ 600/1255]  eta: 0:15:39  lr: 0.001163  loss: 4.1149 (3.9211)  time: 1.4171  data: 0.0004  max mem: 28602
Epoch: [70]  [ 700/1255]  eta: 0:13:13  lr: 0.001163  loss: 4.0125 (3.9229)  time: 1.4228  data: 0.0004  max mem: 28602
Epoch: [70]  [ 800/1255]  eta: 0:10:50  lr: 0.001163  loss: 3.8519 (3.9138)  time: 1.4265  data: 0.0004  max mem: 28602
Epoch: [70]  [ 900/1255]  eta: 0:08:27  lr: 0.001163  loss: 4.2666 (3.9133)  time: 1.4236  data: 0.0003  max mem: 28602
Epoch: [70]  [1000/1255]  eta: 0:06:04  lr: 0.001163  loss: 4.0424 (3.9177)  time: 1.4307  data: 0.0004  max mem: 28602
Epoch: [70]  [1100/1255]  eta: 0:03:41  lr: 0.001163  loss: 4.3032 (3.9272)  time: 1.4307  data: 0.0004  max mem: 28602
Epoch: [70]  [1200/1255]  eta: 0:01:18  lr: 0.001163  loss: 4.1548 (3.9270)  time: 1.4304  data: 0.0003  max mem: 28602
Epoch: [70]  [1254/1255]  eta: 0:00:01  lr: 0.001163  loss: 4.3277 (3.9269)  time: 1.3934  data: 0.0007  max mem: 28602
Epoch: [70] Total time: 0:29:53 (1.4295 s / it)
Averaged stats: lr: 0.001163  loss: 4.3277 (3.9224)
Test:  [  0/123]  eta: 0:25:38  loss: 1.1151 (1.1151)  acc1: 73.2843 (73.2843)  acc5: 94.1177 (94.1177)  time: 12.5088  data: 11.9885  max mem: 28602
Test:  [ 10/123]  eta: 0:03:27  loss: 1.1151 (1.0852)  acc1: 73.2843 (75.0891)  acc5: 92.8922 (93.3155)  time: 1.8343  data: 1.3953  max mem: 28602
Test:  [ 20/123]  eta: 0:02:21  loss: 1.0701 (1.0455)  acc1: 76.4706 (76.9958)  acc5: 92.8922 (93.4290)  time: 0.8176  data: 0.3829  max mem: 28602
Test:  [ 30/123]  eta: 0:01:49  loss: 1.1413 (1.0971)  acc1: 73.5294 (74.8656)  acc5: 94.1177 (93.5010)  time: 0.8205  data: 0.3867  max mem: 28602
Test:  [ 40/123]  eta: 0:01:33  loss: 1.1287 (1.0691)  acc1: 70.0980 (75.4603)  acc5: 95.3431 (93.9981)  time: 0.8559  data: 0.4256  max mem: 28602
Test:  [ 50/123]  eta: 0:01:18  loss: 1.0639 (1.0922)  acc1: 74.7549 (75.0769)  acc5: 94.6078 (93.6515)  time: 0.8992  data: 0.4619  max mem: 28602
Test:  [ 60/123]  eta: 0:01:04  loss: 1.4778 (1.1827)  acc1: 66.6667 (73.2281)  acc5: 88.7255 (92.3899)  time: 0.8330  data: 0.3936  max mem: 28602
Test:  [ 70/123]  eta: 0:00:53  loss: 1.5346 (1.2330)  acc1: 64.9510 (72.1762)  acc5: 87.0098 (91.5769)  time: 0.8261  data: 0.3887  max mem: 28602
Test:  [ 80/123]  eta: 0:00:42  loss: 1.6663 (1.3041)  acc1: 60.0490 (70.7486)  acc5: 84.0686 (90.5531)  time: 0.8405  data: 0.4035  max mem: 28602
Test:  [ 90/123]  eta: 0:00:31  loss: 1.6730 (1.3399)  acc1: 60.0490 (69.9768)  acc5: 84.5588 (90.0291)  time: 0.8199  data: 0.3834  max mem: 28602
Test:  [100/123]  eta: 0:00:21  loss: 1.5871 (1.3710)  acc1: 64.2157 (69.3870)  acc5: 85.2941 (89.5117)  time: 0.7991  data: 0.3652  max mem: 28602
Test:  [110/123]  eta: 0:00:12  loss: 1.7086 (1.4087)  acc1: 60.5392 (68.4442)  acc5: 83.3333 (88.9684)  time: 0.8392  data: 0.4102  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.5183 (1.4048)  acc1: 62.2549 (68.5059)  acc5: 86.5196 (89.0779)  time: 0.7781  data: 0.3593  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.4882 (1.3986)  acc1: 63.7255 (68.6560)  acc5: 88.2353 (89.1440)  time: 0.7668  data: 0.3592  max mem: 28602
Test: Total time: 0:01:51 (0.9097 s / it)
* Acc@1 68.656 Acc@5 89.144 loss 1.399
Accuracy of the network on the 50000 test images: 68.7%
Max accuracy: 69.17%
Epoch: [71]  [   0/1255]  eta: 3:55:49  lr: 0.001159  loss: 4.4731 (4.4731)  time: 11.2744  data: 9.6535  max mem: 28602
Epoch: [71]  [ 100/1255]  eta: 0:29:29  lr: 0.001159  loss: 3.9250 (3.8111)  time: 1.4244  data: 0.0004  max mem: 28602
Epoch: [71]  [ 200/1255]  eta: 0:25:59  lr: 0.001159  loss: 4.0823 (3.8764)  time: 1.4166  data: 0.0003  max mem: 28602
Epoch: [71]  [ 300/1255]  eta: 0:23:12  lr: 0.001159  loss: 4.0959 (3.8791)  time: 1.4117  data: 0.0003  max mem: 28602
Epoch: [71]  [ 400/1255]  eta: 0:20:37  lr: 0.001159  loss: 3.9516 (3.8736)  time: 1.4120  data: 0.0003  max mem: 28602
Epoch: [71]  [ 500/1255]  eta: 0:18:08  lr: 0.001159  loss: 3.6330 (3.9090)  time: 1.4167  data: 0.0003  max mem: 28602
Epoch: [71]  [ 600/1255]  eta: 0:15:42  lr: 0.001159  loss: 3.8894 (3.9093)  time: 1.4176  data: 0.0004  max mem: 28602
Epoch: [71]  [ 700/1255]  eta: 0:13:16  lr: 0.001159  loss: 4.0964 (3.9149)  time: 1.4277  data: 0.0003  max mem: 28602
Epoch: [71]  [ 800/1255]  eta: 0:10:52  lr: 0.001159  loss: 4.0239 (3.9106)  time: 1.4098  data: 0.0003  max mem: 28602
Epoch: [71]  [ 900/1255]  eta: 0:08:28  lr: 0.001159  loss: 3.9993 (3.9140)  time: 1.4402  data: 0.0003  max mem: 28602
Epoch: [71]  [1000/1255]  eta: 0:06:04  lr: 0.001159  loss: 4.0251 (3.9168)  time: 1.4134  data: 0.0004  max mem: 28602
Epoch: [71]  [1100/1255]  eta: 0:03:41  lr: 0.001159  loss: 4.3091 (3.9157)  time: 1.4034  data: 0.0003  max mem: 28602
Epoch: [71]  [1200/1255]  eta: 0:01:18  lr: 0.001159  loss: 3.9986 (3.9161)  time: 1.4143  data: 0.0003  max mem: 28602
Epoch: [71]  [1254/1255]  eta: 0:00:01  lr: 0.001159  loss: 4.3133 (3.9195)  time: 1.3849  data: 0.0008  max mem: 28602
Epoch: [71] Total time: 0:29:51 (1.4275 s / it)
Averaged stats: lr: 0.001159  loss: 4.3133 (3.9142)
Test:  [  0/123]  eta: 0:24:39  loss: 0.9837 (0.9837)  acc1: 76.9608 (76.9608)  acc5: 94.6078 (94.6078)  time: 12.0279  data: 11.5927  max mem: 28602
Test:  [ 10/123]  eta: 0:03:24  loss: 1.0272 (1.0462)  acc1: 76.9608 (75.7353)  acc5: 94.3627 (93.2487)  time: 1.8060  data: 1.3939  max mem: 28602
Test:  [ 20/123]  eta: 0:02:15  loss: 0.9818 (1.0045)  acc1: 77.6961 (77.2526)  acc5: 93.3824 (93.4874)  time: 0.7848  data: 0.3757  max mem: 28602
Test:  [ 30/123]  eta: 0:01:46  loss: 1.0798 (1.0560)  acc1: 73.5294 (75.2372)  acc5: 93.6275 (93.4219)  time: 0.7834  data: 0.3694  max mem: 28602
Test:  [ 40/123]  eta: 0:01:30  loss: 1.1275 (1.0298)  acc1: 70.8333 (75.7233)  acc5: 94.6078 (93.9084)  time: 0.8540  data: 0.4335  max mem: 28602
Test:  [ 50/123]  eta: 0:01:15  loss: 1.0633 (1.0548)  acc1: 75.4902 (75.4085)  acc5: 93.8726 (93.5794)  time: 0.8693  data: 0.4499  max mem: 28602
Test:  [ 60/123]  eta: 0:01:02  loss: 1.2902 (1.1512)  acc1: 68.8726 (73.4611)  acc5: 89.4608 (92.2774)  time: 0.7956  data: 0.3780  max mem: 28602
Test:  [ 70/123]  eta: 0:00:51  loss: 1.5393 (1.1954)  acc1: 63.2353 (72.5904)  acc5: 85.7843 (91.6770)  time: 0.8197  data: 0.3972  max mem: 28602
Test:  [ 80/123]  eta: 0:00:41  loss: 1.5716 (1.2577)  acc1: 62.9902 (71.3750)  acc5: 85.7843 (90.7619)  time: 0.8295  data: 0.4051  max mem: 28602
Test:  [ 90/123]  eta: 0:00:30  loss: 1.6170 (1.2951)  acc1: 63.2353 (70.6179)  acc5: 84.3137 (90.1934)  time: 0.8081  data: 0.3864  max mem: 28602
Test:  [100/123]  eta: 0:00:21  loss: 1.5894 (1.3261)  acc1: 64.7059 (70.1199)  acc5: 86.0294 (89.6574)  time: 0.7762  data: 0.3535  max mem: 28602
Test:  [110/123]  eta: 0:00:11  loss: 1.5987 (1.3648)  acc1: 62.2549 (69.1419)  acc5: 83.8235 (89.1517)  time: 0.8057  data: 0.3883  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.5199 (1.3674)  acc1: 62.0098 (68.9921)  acc5: 87.2549 (89.1792)  time: 0.7797  data: 0.3713  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.4227 (1.3620)  acc1: 62.5000 (69.1160)  acc5: 88.9706 (89.2340)  time: 0.7699  data: 0.3713  max mem: 28602
Test: Total time: 0:01:49 (0.8888 s / it)
* Acc@1 69.116 Acc@5 89.234 loss 1.362
Accuracy of the network on the 50000 test images: 69.1%
Max accuracy: 69.17%
Epoch: [72]  [   0/1255]  eta: 3:45:39  lr: 0.001154  loss: 3.1234 (3.1234)  time: 10.7883  data: 9.3279  max mem: 28602
Epoch: [72]  [ 100/1255]  eta: 0:29:12  lr: 0.001154  loss: 3.7115 (3.9681)  time: 1.4182  data: 0.0003  max mem: 28602
Epoch: [72]  [ 200/1255]  eta: 0:25:45  lr: 0.001154  loss: 4.0571 (3.9350)  time: 1.4179  data: 0.0003  max mem: 28602
Epoch: [72]  [ 300/1255]  eta: 0:23:05  lr: 0.001154  loss: 4.2145 (3.9170)  time: 1.4093  data: 0.0003  max mem: 28602
Epoch: [72]  [ 400/1255]  eta: 0:20:34  lr: 0.001154  loss: 3.5130 (3.9144)  time: 1.4299  data: 0.0004  max mem: 28602
Epoch: [72]  [ 500/1255]  eta: 0:18:04  lr: 0.001154  loss: 4.0018 (3.9018)  time: 1.3982  data: 0.0003  max mem: 28602
Epoch: [72]  [ 600/1255]  eta: 0:15:38  lr: 0.001154  loss: 3.9315 (3.8977)  time: 1.4116  data: 0.0003  max mem: 28602
Epoch: [72]  [ 700/1255]  eta: 0:13:12  lr: 0.001154  loss: 4.3445 (3.9222)  time: 1.3826  data: 0.0003  max mem: 28602
Epoch: [72]  [ 800/1255]  eta: 0:10:48  lr: 0.001154  loss: 3.9673 (3.9317)  time: 1.4114  data: 0.0003  max mem: 28602
Epoch: [72]  [ 900/1255]  eta: 0:08:25  lr: 0.001154  loss: 3.9674 (3.9228)  time: 1.4181  data: 0.0003  max mem: 28602
Epoch: [72]  [1000/1255]  eta: 0:06:03  lr: 0.001154  loss: 4.0067 (3.9388)  time: 1.4146  data: 0.0003  max mem: 28602
Epoch: [72]  [1100/1255]  eta: 0:03:40  lr: 0.001154  loss: 3.8739 (3.9382)  time: 1.4228  data: 0.0004  max mem: 28602
Epoch: [72]  [1200/1255]  eta: 0:01:18  lr: 0.001154  loss: 3.8811 (3.9350)  time: 1.4129  data: 0.0003  max mem: 28602
Epoch: [72]  [1254/1255]  eta: 0:00:01  lr: 0.001154  loss: 3.9623 (3.9381)  time: 1.3828  data: 0.0007  max mem: 28602
Epoch: [72] Total time: 0:29:45 (1.4224 s / it)
Averaged stats: lr: 0.001154  loss: 3.9623 (3.9371)
Test:  [  0/123]  eta: 0:25:25  loss: 0.9684 (0.9684)  acc1: 76.2255 (76.2255)  acc5: 94.1177 (94.1177)  time: 12.4039  data: 11.8779  max mem: 28602
Test:  [ 10/123]  eta: 0:03:26  loss: 1.0961 (1.0627)  acc1: 72.7941 (75.5125)  acc5: 94.1177 (93.3824)  time: 1.8286  data: 1.3910  max mem: 28602
Test:  [ 20/123]  eta: 0:02:17  loss: 1.0666 (1.0217)  acc1: 76.9608 (77.0308)  acc5: 93.6275 (93.5574)  time: 0.7856  data: 0.3616  max mem: 28602
Test:  [ 30/123]  eta: 0:01:47  loss: 1.1588 (1.0723)  acc1: 74.5098 (75.0474)  acc5: 93.6275 (93.5958)  time: 0.7863  data: 0.3652  max mem: 28602
Test:  [ 40/123]  eta: 0:01:31  loss: 1.1588 (1.0463)  acc1: 72.3039 (75.7532)  acc5: 94.8529 (94.0220)  time: 0.8564  data: 0.4317  max mem: 28602
Test:  [ 50/123]  eta: 0:01:16  loss: 1.0109 (1.0762)  acc1: 75.4902 (75.1394)  acc5: 94.3627 (93.6226)  time: 0.8943  data: 0.4714  max mem: 28602
Test:  [ 60/123]  eta: 0:01:03  loss: 1.3650 (1.1620)  acc1: 67.6471 (73.3365)  acc5: 89.4608 (92.3618)  time: 0.8058  data: 0.3851  max mem: 28602
Test:  [ 70/123]  eta: 0:00:52  loss: 1.5555 (1.2055)  acc1: 65.4412 (72.4144)  acc5: 85.7843 (91.6701)  time: 0.8181  data: 0.3943  max mem: 28602
Test:  [ 80/123]  eta: 0:00:41  loss: 1.5978 (1.2677)  acc1: 61.7647 (70.9846)  acc5: 86.5196 (90.8285)  time: 0.8241  data: 0.4020  max mem: 28602
Test:  [ 90/123]  eta: 0:00:31  loss: 1.6414 (1.3066)  acc1: 62.5000 (70.2273)  acc5: 85.2941 (90.2095)  time: 0.7750  data: 0.3523  max mem: 28602
Test:  [100/123]  eta: 0:00:21  loss: 1.6414 (1.3353)  acc1: 64.4608 (69.7729)  acc5: 85.2941 (89.7617)  time: 0.7680  data: 0.3428  max mem: 28602
Test:  [110/123]  eta: 0:00:11  loss: 1.6511 (1.3712)  acc1: 63.7255 (69.0360)  acc5: 84.8039 (89.2267)  time: 0.8249  data: 0.4015  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.5045 (1.3736)  acc1: 64.2157 (68.9657)  acc5: 87.2549 (89.2886)  time: 0.7902  data: 0.3734  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.3746 (1.3669)  acc1: 65.6863 (69.1260)  acc5: 87.9902 (89.3540)  time: 0.7790  data: 0.3734  max mem: 28602
Test: Total time: 0:01:49 (0.8942 s / it)
* Acc@1 69.126 Acc@5 89.354 loss 1.367
Accuracy of the network on the 50000 test images: 69.1%
Max accuracy: 69.17%
Epoch: [73]  [   0/1255]  eta: 4:01:20  lr: 0.001149  loss: 4.5642 (4.5642)  time: 11.5379  data: 10.0965  max mem: 28602
Epoch: [73]  [ 100/1255]  eta: 0:29:24  lr: 0.001149  loss: 4.1480 (3.9512)  time: 1.4239  data: 0.0003  max mem: 28602
Epoch: [73]  [ 200/1255]  eta: 0:25:53  lr: 0.001149  loss: 4.1580 (3.9228)  time: 1.4102  data: 0.0003  max mem: 28602
Epoch: [73]  [ 300/1255]  eta: 0:23:10  lr: 0.001149  loss: 4.0346 (3.9239)  time: 1.4338  data: 0.0003  max mem: 28602
Epoch: [73]  [ 400/1255]  eta: 0:20:38  lr: 0.001149  loss: 4.3613 (3.9337)  time: 1.4314  data: 0.0004  max mem: 28602
Epoch: [73]  [ 500/1255]  eta: 0:18:08  lr: 0.001149  loss: 4.0892 (3.9317)  time: 1.4154  data: 0.0003  max mem: 28602
Epoch: [73]  [ 600/1255]  eta: 0:15:40  lr: 0.001149  loss: 3.7627 (3.9269)  time: 1.4051  data: 0.0003  max mem: 28602
Epoch: [73]  [ 700/1255]  eta: 0:13:15  lr: 0.001149  loss: 4.1429 (3.9163)  time: 1.4153  data: 0.0003  max mem: 28602
Epoch: [73]  [ 800/1255]  eta: 0:10:50  lr: 0.001149  loss: 4.2283 (3.9292)  time: 1.4136  data: 0.0003  max mem: 28602
Epoch: [73]  [ 900/1255]  eta: 0:08:26  lr: 0.001149  loss: 4.0917 (3.9318)  time: 1.4211  data: 0.0003  max mem: 28602
Epoch: [73]  [1000/1255]  eta: 0:06:03  lr: 0.001149  loss: 3.7053 (3.9363)  time: 1.4116  data: 0.0003  max mem: 28602
Epoch: [73]  [1100/1255]  eta: 0:03:40  lr: 0.001149  loss: 4.2399 (3.9343)  time: 1.4103  data: 0.0003  max mem: 28602
Epoch: [73]  [1200/1255]  eta: 0:01:18  lr: 0.001149  loss: 4.2829 (3.9282)  time: 1.3998  data: 0.0003  max mem: 28602
Epoch: [73]  [1254/1255]  eta: 0:00:01  lr: 0.001149  loss: 3.6405 (3.9249)  time: 1.3835  data: 0.0007  max mem: 28602
Epoch: [73] Total time: 0:29:46 (1.4236 s / it)
Averaged stats: lr: 0.001149  loss: 3.6405 (3.9185)
Test:  [  0/123]  eta: 0:24:17  loss: 1.0250 (1.0250)  acc1: 76.9608 (76.9608)  acc5: 93.3824 (93.3824)  time: 11.8472  data: 11.4149  max mem: 28602
Test:  [ 10/123]  eta: 0:03:21  loss: 1.0961 (1.1013)  acc1: 76.9608 (75.3119)  acc5: 92.8922 (92.7139)  time: 1.7834  data: 1.3728  max mem: 28602
Test:  [ 20/123]  eta: 0:02:18  loss: 1.0512 (1.0344)  acc1: 77.4510 (77.5327)  acc5: 93.1373 (93.1956)  time: 0.8175  data: 0.4038  max mem: 28602
Test:  [ 30/123]  eta: 0:01:47  loss: 1.0607 (1.0877)  acc1: 73.5294 (74.7549)  acc5: 93.6275 (93.3270)  time: 0.8036  data: 0.3811  max mem: 28602
Test:  [ 40/123]  eta: 0:01:31  loss: 1.1001 (1.0625)  acc1: 70.0980 (75.4603)  acc5: 94.6078 (93.6693)  time: 0.8519  data: 0.4275  max mem: 28602
Test:  [ 50/123]  eta: 0:01:16  loss: 1.0876 (1.0848)  acc1: 74.0196 (74.9471)  acc5: 93.6275 (93.3679)  time: 0.8886  data: 0.4682  max mem: 28602
Test:  [ 60/123]  eta: 0:01:03  loss: 1.3404 (1.1752)  acc1: 67.1569 (73.0593)  acc5: 89.2157 (92.2011)  time: 0.8017  data: 0.3842  max mem: 28602
Test:  [ 70/123]  eta: 0:00:51  loss: 1.5730 (1.2251)  acc1: 63.7255 (72.0761)  acc5: 86.2745 (91.4906)  time: 0.7987  data: 0.3769  max mem: 28602
Test:  [ 80/123]  eta: 0:00:41  loss: 1.6930 (1.2884)  acc1: 61.0294 (70.7365)  acc5: 83.5784 (90.5471)  time: 0.8134  data: 0.3897  max mem: 28602
Test:  [ 90/123]  eta: 0:00:31  loss: 1.6930 (1.3258)  acc1: 61.0294 (69.9230)  acc5: 83.5784 (90.0264)  time: 0.8122  data: 0.3941  max mem: 28602
Test:  [100/123]  eta: 0:00:21  loss: 1.6318 (1.3577)  acc1: 63.2353 (69.2681)  acc5: 85.0490 (89.5020)  time: 0.7829  data: 0.3671  max mem: 28602
Test:  [110/123]  eta: 0:00:11  loss: 1.7266 (1.3932)  acc1: 63.2353 (68.5016)  acc5: 84.3137 (88.9816)  time: 0.7991  data: 0.3792  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.5704 (1.3877)  acc1: 63.4804 (68.5323)  acc5: 87.5000 (89.1488)  time: 0.7569  data: 0.3420  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.5022 (1.3811)  acc1: 65.1961 (68.6960)  acc5: 89.7059 (89.2060)  time: 0.7453  data: 0.3419  max mem: 28602
Test: Total time: 0:01:49 (0.8879 s / it)
* Acc@1 68.696 Acc@5 89.206 loss 1.381
Accuracy of the network on the 50000 test images: 68.7%
Max accuracy: 69.17%
Epoch: [74]  [   0/1255]  eta: 3:52:07  lr: 0.001145  loss: 4.3970 (4.3970)  time: 11.0978  data: 9.6513  max mem: 28602
Epoch: [74]  [ 100/1255]  eta: 0:29:13  lr: 0.001145  loss: 4.1969 (3.9286)  time: 1.4213  data: 0.0003  max mem: 28602
Epoch: [74]  [ 200/1255]  eta: 0:25:49  lr: 0.001145  loss: 4.2588 (3.9527)  time: 1.4222  data: 0.0004  max mem: 28602
Epoch: [74]  [ 300/1255]  eta: 0:23:05  lr: 0.001145  loss: 3.9745 (3.9335)  time: 1.4377  data: 0.0004  max mem: 28602
Epoch: [74]  [ 400/1255]  eta: 0:20:32  lr: 0.001145  loss: 4.1508 (3.9246)  time: 1.4031  data: 0.0004  max mem: 28602
Epoch: [74]  [ 500/1255]  eta: 0:18:04  lr: 0.001145  loss: 4.1172 (3.9410)  time: 1.4187  data: 0.0003  max mem: 28602
Epoch: [74]  [ 600/1255]  eta: 0:15:38  lr: 0.001145  loss: 3.5497 (3.9199)  time: 1.4203  data: 0.0003  max mem: 28602
Epoch: [74]  [ 700/1255]  eta: 0:13:13  lr: 0.001145  loss: 4.1820 (3.9351)  time: 1.3694  data: 0.0003  max mem: 28602
Epoch: [74]  [ 800/1255]  eta: 0:10:49  lr: 0.001145  loss: 4.0153 (3.9226)  time: 1.4420  data: 0.0003  max mem: 28602
Epoch: [74]  [ 900/1255]  eta: 0:08:27  lr: 0.001145  loss: 4.1789 (3.9321)  time: 1.4459  data: 0.0004  max mem: 28602
Epoch: [74]  [1000/1255]  eta: 0:06:05  lr: 0.001145  loss: 4.3380 (3.9408)  time: 1.4438  data: 0.0004  max mem: 28602
Epoch: [74]  [1100/1255]  eta: 0:03:42  lr: 0.001145  loss: 3.5371 (3.9258)  time: 1.4509  data: 0.0004  max mem: 28602
Epoch: [74]  [1200/1255]  eta: 0:01:18  lr: 0.001145  loss: 4.1375 (3.9243)  time: 1.4462  data: 0.0004  max mem: 28602
Epoch: [74]  [1254/1255]  eta: 0:00:01  lr: 0.001145  loss: 4.0678 (3.9303)  time: 1.4221  data: 0.0007  max mem: 28602
Epoch: [74] Total time: 0:30:01 (1.4351 s / it)
Averaged stats: lr: 0.001145  loss: 4.0678 (3.9135)
Test:  [  0/123]  eta: 0:27:26  loss: 1.0298 (1.0298)  acc1: 77.6961 (77.6961)  acc5: 92.6471 (92.6471)  time: 13.3869  data: 12.8978  max mem: 28602
Test:  [ 10/123]  eta: 0:03:41  loss: 1.0837 (1.0657)  acc1: 75.7353 (76.0918)  acc5: 92.6471 (92.8699)  time: 1.9576  data: 1.5089  max mem: 28602
Test:  [ 20/123]  eta: 0:02:22  loss: 1.0784 (1.0187)  acc1: 75.9804 (77.5444)  acc5: 93.1373 (93.4874)  time: 0.7814  data: 0.3354  max mem: 28602
Test:  [ 30/123]  eta: 0:01:50  loss: 1.0908 (1.0685)  acc1: 72.3039 (75.3242)  acc5: 93.6275 (93.4930)  time: 0.7668  data: 0.3179  max mem: 28602
Test:  [ 40/123]  eta: 0:01:33  loss: 1.0976 (1.0438)  acc1: 71.3235 (75.8847)  acc5: 94.1177 (93.8188)  time: 0.8629  data: 0.4131  max mem: 28602
Test:  [ 50/123]  eta: 0:01:18  loss: 1.0392 (1.0635)  acc1: 75.0000 (75.5431)  acc5: 93.3824 (93.4977)  time: 0.8982  data: 0.4487  max mem: 28602
Test:  [ 60/123]  eta: 0:01:04  loss: 1.2726 (1.1434)  acc1: 69.6078 (73.8910)  acc5: 90.1961 (92.3256)  time: 0.8252  data: 0.3813  max mem: 28602
Test:  [ 70/123]  eta: 0:00:53  loss: 1.5708 (1.1883)  acc1: 64.9510 (72.8459)  acc5: 87.0098 (91.7495)  time: 0.8479  data: 0.4025  max mem: 28602
Test:  [ 80/123]  eta: 0:00:42  loss: 1.5970 (1.2503)  acc1: 62.5000 (71.5565)  acc5: 85.0490 (90.8315)  time: 0.8732  data: 0.4192  max mem: 28602
Test:  [ 90/123]  eta: 0:00:31  loss: 1.6616 (1.2849)  acc1: 62.0098 (70.8091)  acc5: 84.0686 (90.3361)  time: 0.8145  data: 0.3624  max mem: 28602
Test:  [100/123]  eta: 0:00:21  loss: 1.5997 (1.3188)  acc1: 65.1961 (70.0908)  acc5: 84.8039 (89.7787)  time: 0.7888  data: 0.3357  max mem: 28602
Test:  [110/123]  eta: 0:00:12  loss: 1.6331 (1.3605)  acc1: 63.7255 (69.2435)  acc5: 84.0686 (89.1914)  time: 0.8448  data: 0.3934  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.5243 (1.3617)  acc1: 62.9902 (69.1197)  acc5: 87.5000 (89.3008)  time: 0.8025  data: 0.3719  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.4467 (1.3569)  acc1: 65.6863 (69.2520)  acc5: 88.4804 (89.3480)  time: 0.7788  data: 0.3615  max mem: 28602
Test: Total time: 0:01:52 (0.9185 s / it)
* Acc@1 69.252 Acc@5 89.348 loss 1.357
Accuracy of the network on the 50000 test images: 69.3%
Max accuracy: 69.25%
Epoch: [75]  [   0/1255]  eta: 4:18:25  lr: 0.001140  loss: 2.7143 (2.7143)  time: 12.3549  data: 10.8327  max mem: 28602
Epoch: [75]  [ 100/1255]  eta: 0:30:08  lr: 0.001140  loss: 3.9286 (3.7696)  time: 1.4262  data: 0.0003  max mem: 28602
Epoch: [75]  [ 200/1255]  eta: 0:26:26  lr: 0.001140  loss: 3.6366 (3.8196)  time: 1.4452  data: 0.0003  max mem: 28602
Epoch: [75]  [ 300/1255]  eta: 0:23:33  lr: 0.001140  loss: 4.1237 (3.8424)  time: 1.4365  data: 0.0004  max mem: 28602
Epoch: [75]  [ 400/1255]  eta: 0:20:56  lr: 0.001140  loss: 4.1740 (3.8411)  time: 1.4516  data: 0.0004  max mem: 28602
Epoch: [75]  [ 500/1255]  eta: 0:18:24  lr: 0.001140  loss: 4.2053 (3.8677)  time: 1.4336  data: 0.0004  max mem: 28602
Epoch: [75]  [ 600/1255]  eta: 0:15:53  lr: 0.001140  loss: 4.0826 (3.8735)  time: 1.4237  data: 0.0003  max mem: 28602
Epoch: [75]  [ 700/1255]  eta: 0:13:25  lr: 0.001140  loss: 4.0722 (3.8776)  time: 1.4343  data: 0.0003  max mem: 28602
Epoch: [75]  [ 800/1255]  eta: 0:10:59  lr: 0.001140  loss: 4.0899 (3.8678)  time: 1.4523  data: 0.0003  max mem: 28602
Epoch: [75]  [ 900/1255]  eta: 0:08:33  lr: 0.001140  loss: 4.1977 (3.8883)  time: 1.4213  data: 0.0003  max mem: 28602
Epoch: [75]  [1000/1255]  eta: 0:06:08  lr: 0.001140  loss: 4.0506 (3.8890)  time: 1.4532  data: 0.0003  max mem: 28602
Epoch: [75]  [1100/1255]  eta: 0:03:43  lr: 0.001140  loss: 3.8264 (3.8921)  time: 1.4864  data: 0.0004  max mem: 28602
Epoch: [75]  [1200/1255]  eta: 0:01:19  lr: 0.001140  loss: 4.0108 (3.8892)  time: 1.4499  data: 0.0003  max mem: 28602
Epoch: [75]  [1254/1255]  eta: 0:00:01  lr: 0.001140  loss: 4.2873 (3.8965)  time: 1.3961  data: 0.0009  max mem: 28602
Epoch: [75] Total time: 0:30:15 (1.4463 s / it)
Averaged stats: lr: 0.001140  loss: 4.2873 (3.8891)
Test:  [  0/123]  eta: 0:25:37  loss: 0.9779 (0.9779)  acc1: 78.4314 (78.4314)  acc5: 93.3824 (93.3824)  time: 12.4998  data: 12.0391  max mem: 28602
Test:  [ 10/123]  eta: 0:03:26  loss: 1.1015 (1.0678)  acc1: 75.2451 (75.1114)  acc5: 92.1569 (92.8030)  time: 1.8277  data: 1.3961  max mem: 28602
Test:  [ 20/123]  eta: 0:02:17  loss: 1.0806 (1.0214)  acc1: 76.2255 (76.5523)  acc5: 92.8922 (93.2306)  time: 0.7736  data: 0.3546  max mem: 28602
Test:  [ 30/123]  eta: 0:01:46  loss: 1.0842 (1.0764)  acc1: 74.7549 (74.2489)  acc5: 93.1373 (93.2559)  time: 0.7760  data: 0.3521  max mem: 28602
Test:  [ 40/123]  eta: 0:01:32  loss: 1.1114 (1.0435)  acc1: 72.3039 (75.2272)  acc5: 94.3627 (93.7709)  time: 0.8950  data: 0.4595  max mem: 28602
Test:  [ 50/123]  eta: 0:01:18  loss: 0.9639 (1.0588)  acc1: 74.5098 (75.2115)  acc5: 93.8726 (93.5217)  time: 0.9577  data: 0.5279  max mem: 28602
Test:  [ 60/123]  eta: 0:01:05  loss: 1.2830 (1.1366)  acc1: 70.8333 (73.6258)  acc5: 89.9510 (92.4542)  time: 0.8606  data: 0.4377  max mem: 28602
Test:  [ 70/123]  eta: 0:00:53  loss: 1.5056 (1.1871)  acc1: 65.4412 (72.5559)  acc5: 86.5196 (91.7530)  time: 0.8325  data: 0.4127  max mem: 28602
Test:  [ 80/123]  eta: 0:00:42  loss: 1.5725 (1.2442)  acc1: 64.9510 (71.4204)  acc5: 84.8039 (90.9102)  time: 0.8375  data: 0.4121  max mem: 28602
Test:  [ 90/123]  eta: 0:00:32  loss: 1.5828 (1.2777)  acc1: 63.2353 (70.7014)  acc5: 85.7843 (90.5112)  time: 0.8566  data: 0.4211  max mem: 28602
Test:  [100/123]  eta: 0:00:21  loss: 1.5828 (1.3152)  acc1: 63.4804 (70.0665)  acc5: 85.2941 (89.9122)  time: 0.8340  data: 0.4036  max mem: 28602
Test:  [110/123]  eta: 0:00:12  loss: 1.6836 (1.3511)  acc1: 61.2745 (69.1883)  acc5: 83.0882 (89.4166)  time: 0.8723  data: 0.4498  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.4759 (1.3504)  acc1: 61.2745 (69.1784)  acc5: 88.4804 (89.4972)  time: 0.8380  data: 0.4179  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.4585 (1.3457)  acc1: 62.7451 (69.2780)  acc5: 89.7059 (89.5540)  time: 0.8273  data: 0.4179  max mem: 28602
Test: Total time: 0:01:54 (0.9294 s / it)
* Acc@1 69.278 Acc@5 89.554 loss 1.346
Accuracy of the network on the 50000 test images: 69.3%
Max accuracy: 69.28%
Epoch: [76]  [   0/1255]  eta: 3:46:51  lr: 0.001135  loss: 3.8162 (3.8162)  time: 10.8455  data: 9.1712  max mem: 28602
Epoch: [76]  [ 100/1255]  eta: 0:29:44  lr: 0.001135  loss: 3.9247 (3.9847)  time: 1.4577  data: 0.0004  max mem: 28602
Epoch: [76]  [ 200/1255]  eta: 0:26:22  lr: 0.001135  loss: 3.9552 (3.9301)  time: 1.4491  data: 0.0004  max mem: 28602
Epoch: [76]  [ 300/1255]  eta: 0:23:32  lr: 0.001135  loss: 3.9222 (3.8827)  time: 1.4244  data: 0.0004  max mem: 28602
Epoch: [76]  [ 400/1255]  eta: 0:20:51  lr: 0.001135  loss: 3.5397 (3.8764)  time: 1.4146  data: 0.0003  max mem: 28602
Epoch: [76]  [ 500/1255]  eta: 0:18:17  lr: 0.001135  loss: 4.0722 (3.9086)  time: 1.4059  data: 0.0003  max mem: 28602
Epoch: [76]  [ 600/1255]  eta: 0:15:47  lr: 0.001135  loss: 3.9551 (3.8874)  time: 1.4076  data: 0.0003  max mem: 28602
Epoch: [76]  [ 700/1255]  eta: 0:13:19  lr: 0.001135  loss: 4.0395 (3.8919)  time: 1.4097  data: 0.0003  max mem: 28602
Epoch: [76]  [ 800/1255]  eta: 0:10:53  lr: 0.001135  loss: 4.0362 (3.8826)  time: 1.3993  data: 0.0003  max mem: 28602
Epoch: [76]  [ 900/1255]  eta: 0:08:30  lr: 0.001135  loss: 4.1445 (3.8772)  time: 1.4428  data: 0.0004  max mem: 28602
Epoch: [76]  [1000/1255]  eta: 0:06:06  lr: 0.001135  loss: 3.9946 (3.8722)  time: 1.4569  data: 0.0004  max mem: 28602
Epoch: [76]  [1100/1255]  eta: 0:03:42  lr: 0.001135  loss: 4.0205 (3.8742)  time: 1.4433  data: 0.0004  max mem: 28602
Epoch: [76]  [1200/1255]  eta: 0:01:19  lr: 0.001135  loss: 3.3890 (3.8736)  time: 1.4541  data: 0.0003  max mem: 28602
Epoch: [76]  [1254/1255]  eta: 0:00:01  lr: 0.001135  loss: 4.0060 (3.8739)  time: 1.3944  data: 0.0006  max mem: 28602
Epoch: [76] Total time: 0:30:05 (1.4387 s / it)
Averaged stats: lr: 0.001135  loss: 4.0060 (3.8801)
Test:  [  0/123]  eta: 0:27:35  loss: 1.0674 (1.0674)  acc1: 75.2451 (75.2451)  acc5: 92.1569 (92.1569)  time: 13.4591  data: 12.9393  max mem: 28602
Test:  [ 10/123]  eta: 0:03:45  loss: 1.0893 (1.0807)  acc1: 75.2451 (75.0000)  acc5: 92.8922 (92.5357)  time: 1.9923  data: 1.5293  max mem: 28602
Test:  [ 20/123]  eta: 0:02:25  loss: 1.0474 (1.0271)  acc1: 76.9608 (76.8674)  acc5: 93.3824 (93.0906)  time: 0.8077  data: 0.3451  max mem: 28602
Test:  [ 30/123]  eta: 0:01:51  loss: 1.0588 (1.0727)  acc1: 75.4902 (74.7391)  acc5: 94.6078 (93.2163)  time: 0.7576  data: 0.2856  max mem: 28602
Test:  [ 40/123]  eta: 0:01:34  loss: 1.0821 (1.0435)  acc1: 71.8137 (75.4424)  acc5: 94.8529 (93.7470)  time: 0.8538  data: 0.3790  max mem: 28602
Test:  [ 50/123]  eta: 0:01:19  loss: 1.0157 (1.0601)  acc1: 74.5098 (75.0913)  acc5: 94.1177 (93.5458)  time: 0.9163  data: 0.4454  max mem: 28602
Test:  [ 60/123]  eta: 0:01:06  loss: 1.3437 (1.1488)  acc1: 69.6078 (73.2924)  acc5: 89.7059 (92.4100)  time: 0.8642  data: 0.3992  max mem: 28602
Test:  [ 70/123]  eta: 0:00:54  loss: 1.4854 (1.1903)  acc1: 65.6863 (72.4938)  acc5: 86.2745 (91.8117)  time: 0.8565  data: 0.3969  max mem: 28602
Test:  [ 80/123]  eta: 0:00:42  loss: 1.6187 (1.2515)  acc1: 62.7451 (71.2539)  acc5: 85.5392 (90.8920)  time: 0.8384  data: 0.3842  max mem: 28602
Test:  [ 90/123]  eta: 0:00:32  loss: 1.6410 (1.2894)  acc1: 62.0098 (70.4078)  acc5: 85.5392 (90.3954)  time: 0.8405  data: 0.3841  max mem: 28602
Test:  [100/123]  eta: 0:00:22  loss: 1.5772 (1.3184)  acc1: 64.9510 (69.8432)  acc5: 85.7843 (89.9049)  time: 0.8122  data: 0.3472  max mem: 28602
Test:  [110/123]  eta: 0:00:12  loss: 1.6873 (1.3542)  acc1: 63.7255 (69.0845)  acc5: 84.8039 (89.4166)  time: 0.8463  data: 0.3797  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.4688 (1.3529)  acc1: 64.7059 (69.1237)  acc5: 89.2157 (89.4729)  time: 0.8210  data: 0.3769  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.4374 (1.3480)  acc1: 64.9510 (69.2460)  acc5: 89.7059 (89.5160)  time: 0.8038  data: 0.3769  max mem: 28602
Test: Total time: 0:01:54 (0.9294 s / it)
* Acc@1 69.246 Acc@5 89.516 loss 1.348
Accuracy of the network on the 50000 test images: 69.2%
Max accuracy: 69.28%
Epoch: [77]  [   0/1255]  eta: 4:25:45  lr: 0.001130  loss: 4.2763 (4.2763)  time: 12.7053  data: 11.1975  max mem: 28602
Epoch: [77]  [ 100/1255]  eta: 0:29:54  lr: 0.001130  loss: 4.0638 (3.8728)  time: 1.4454  data: 0.0004  max mem: 28602
Epoch: [77]  [ 200/1255]  eta: 0:26:24  lr: 0.001130  loss: 4.2399 (3.8855)  time: 1.4360  data: 0.0004  max mem: 28602
Epoch: [77]  [ 300/1255]  eta: 0:23:33  lr: 0.001130  loss: 3.8830 (3.8863)  time: 1.4388  data: 0.0004  max mem: 28602
Epoch: [77]  [ 400/1255]  eta: 0:20:57  lr: 0.001130  loss: 3.5125 (3.8803)  time: 1.4541  data: 0.0004  max mem: 28602
Epoch: [77]  [ 500/1255]  eta: 0:18:24  lr: 0.001130  loss: 4.0131 (3.8808)  time: 1.3965  data: 0.0003  max mem: 28602
Epoch: [77]  [ 600/1255]  eta: 0:15:55  lr: 0.001130  loss: 4.2020 (3.8947)  time: 1.4519  data: 0.0004  max mem: 28602
Epoch: [77]  [ 700/1255]  eta: 0:13:28  lr: 0.001130  loss: 3.6934 (3.8877)  time: 1.4338  data: 0.0004  max mem: 28602
Epoch: [77]  [ 800/1255]  eta: 0:11:01  lr: 0.001130  loss: 3.6514 (3.8882)  time: 1.4431  data: 0.0004  max mem: 28602
Epoch: [77]  [ 900/1255]  eta: 0:08:35  lr: 0.001130  loss: 4.2304 (3.8888)  time: 1.4308  data: 0.0004  max mem: 28602
Epoch: [77]  [1000/1255]  eta: 0:06:10  lr: 0.001130  loss: 4.1034 (3.8952)  time: 1.4425  data: 0.0003  max mem: 28602
Epoch: [77]  [1100/1255]  eta: 0:03:44  lr: 0.001130  loss: 3.7067 (3.8876)  time: 1.4326  data: 0.0004  max mem: 28602
Epoch: [77]  [1200/1255]  eta: 0:01:19  lr: 0.001130  loss: 4.1537 (3.8893)  time: 1.4229  data: 0.0003  max mem: 28602
Epoch: [77]  [1254/1255]  eta: 0:00:01  lr: 0.001130  loss: 4.2527 (3.8918)  time: 1.3950  data: 0.0009  max mem: 28602
Epoch: [77] Total time: 0:30:18 (1.4490 s / it)
Averaged stats: lr: 0.001130  loss: 4.2527 (3.8857)
Test:  [  0/123]  eta: 0:28:01  loss: 1.0703 (1.0703)  acc1: 76.7157 (76.7157)  acc5: 92.8922 (92.8922)  time: 13.6720  data: 13.1555  max mem: 28602
Test:  [ 10/123]  eta: 0:03:37  loss: 1.1377 (1.0882)  acc1: 74.5098 (75.4011)  acc5: 93.1373 (93.4492)  time: 1.9214  data: 1.4571  max mem: 28602
Test:  [ 20/123]  eta: 0:02:24  loss: 1.1377 (1.0570)  acc1: 74.7549 (76.8091)  acc5: 93.1373 (93.4757)  time: 0.7904  data: 0.3323  max mem: 28602
Test:  [ 30/123]  eta: 0:01:53  loss: 1.1642 (1.1169)  acc1: 74.0196 (74.7865)  acc5: 94.1177 (93.4772)  time: 0.8281  data: 0.3689  max mem: 28602
Test:  [ 40/123]  eta: 0:01:36  loss: 1.1463 (1.0869)  acc1: 73.2843 (75.4364)  acc5: 95.3431 (94.0280)  time: 0.9063  data: 0.4509  max mem: 28602
Test:  [ 50/123]  eta: 0:01:20  loss: 1.1084 (1.1092)  acc1: 74.2647 (74.9279)  acc5: 94.8529 (93.7140)  time: 0.9280  data: 0.4736  max mem: 28602
Test:  [ 60/123]  eta: 0:01:06  loss: 1.3004 (1.1974)  acc1: 68.8726 (73.0673)  acc5: 88.9706 (92.5185)  time: 0.8173  data: 0.3527  max mem: 28602
Test:  [ 70/123]  eta: 0:00:54  loss: 1.5676 (1.2487)  acc1: 63.4804 (72.0519)  acc5: 86.2745 (91.8048)  time: 0.8362  data: 0.3643  max mem: 28602
Test:  [ 80/123]  eta: 0:00:43  loss: 1.6813 (1.3044)  acc1: 63.2353 (70.9604)  acc5: 84.3137 (90.9677)  time: 0.8738  data: 0.4097  max mem: 28602
Test:  [ 90/123]  eta: 0:00:32  loss: 1.6292 (1.3324)  acc1: 63.2353 (70.3593)  acc5: 85.5392 (90.5732)  time: 0.8515  data: 0.3890  max mem: 28602
Test:  [100/123]  eta: 0:00:22  loss: 1.6292 (1.3652)  acc1: 64.7059 (69.7025)  acc5: 86.0294 (89.9704)  time: 0.8243  data: 0.3606  max mem: 28602
Test:  [110/123]  eta: 0:00:12  loss: 1.6864 (1.4047)  acc1: 62.9902 (68.7975)  acc5: 83.5784 (89.4210)  time: 0.8422  data: 0.3837  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.5649 (1.4036)  acc1: 62.2549 (68.7692)  acc5: 87.9902 (89.5114)  time: 0.7904  data: 0.3562  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.5538 (1.3983)  acc1: 62.9902 (68.8940)  acc5: 89.2857 (89.5740)  time: 0.7732  data: 0.3562  max mem: 28602
Test: Total time: 0:01:54 (0.9321 s / it)
* Acc@1 68.894 Acc@5 89.574 loss 1.398
Accuracy of the network on the 50000 test images: 68.9%
Max accuracy: 69.28%
Epoch: [78]  [   0/1255]  eta: 4:06:33  lr: 0.001125  loss: 2.8773 (2.8773)  time: 11.7875  data: 10.0926  max mem: 28602
Epoch: [78]  [ 100/1255]  eta: 0:29:42  lr: 0.001125  loss: 3.4276 (3.8337)  time: 1.4301  data: 0.0004  max mem: 28602
Epoch: [78]  [ 200/1255]  eta: 0:26:16  lr: 0.001125  loss: 4.0105 (3.8335)  time: 1.4410  data: 0.0003  max mem: 28602
Epoch: [78]  [ 300/1255]  eta: 0:23:30  lr: 0.001125  loss: 3.4987 (3.8544)  time: 1.4516  data: 0.0004  max mem: 28602
Epoch: [78]  [ 400/1255]  eta: 0:20:55  lr: 0.001125  loss: 4.1083 (3.8427)  time: 1.4457  data: 0.0004  max mem: 28602
Epoch: [78]  [ 500/1255]  eta: 0:18:23  lr: 0.001125  loss: 4.1462 (3.8638)  time: 1.4409  data: 0.0004  max mem: 28602
Epoch: [78]  [ 600/1255]  eta: 0:15:53  lr: 0.001125  loss: 3.9800 (3.8725)  time: 1.4092  data: 0.0003  max mem: 28602
Epoch: [78]  [ 700/1255]  eta: 0:13:25  lr: 0.001125  loss: 3.8049 (3.8664)  time: 1.4230  data: 0.0003  max mem: 28602
Epoch: [78]  [ 800/1255]  eta: 0:10:58  lr: 0.001125  loss: 4.0675 (3.8681)  time: 1.4268  data: 0.0003  max mem: 28602
Epoch: [78]  [ 900/1255]  eta: 0:08:32  lr: 0.001125  loss: 3.4665 (3.8669)  time: 1.4259  data: 0.0003  max mem: 28602
Epoch: [78]  [1000/1255]  eta: 0:06:07  lr: 0.001125  loss: 3.8759 (3.8649)  time: 1.3982  data: 0.0003  max mem: 28602
Epoch: [78]  [1100/1255]  eta: 0:03:43  lr: 0.001125  loss: 4.0922 (3.8679)  time: 1.4390  data: 0.0004  max mem: 28602
Epoch: [78]  [1200/1255]  eta: 0:01:19  lr: 0.001125  loss: 3.7840 (3.8567)  time: 1.4562  data: 0.0004  max mem: 28602
Epoch: [78]  [1254/1255]  eta: 0:00:01  lr: 0.001125  loss: 4.1921 (3.8653)  time: 1.3713  data: 0.0006  max mem: 28602
Epoch: [78] Total time: 0:30:06 (1.4391 s / it)
Averaged stats: lr: 0.001125  loss: 4.1921 (3.8733)
Test:  [  0/123]  eta: 0:28:17  loss: 1.1145 (1.1145)  acc1: 74.5098 (74.5098)  acc5: 94.3627 (94.3627)  time: 13.8038  data: 13.3179  max mem: 28602
Test:  [ 10/123]  eta: 0:03:38  loss: 1.1324 (1.1308)  acc1: 73.2843 (74.3761)  acc5: 93.3824 (92.8476)  time: 1.9314  data: 1.4600  max mem: 28602
Test:  [ 20/123]  eta: 0:02:24  loss: 1.0933 (1.0743)  acc1: 77.4510 (76.4122)  acc5: 93.3824 (93.4174)  time: 0.7814  data: 0.3122  max mem: 28602
Test:  [ 30/123]  eta: 0:01:51  loss: 1.1526 (1.1280)  acc1: 74.0196 (74.3359)  acc5: 94.1177 (93.3982)  time: 0.7970  data: 0.3296  max mem: 28602
Test:  [ 40/123]  eta: 0:01:34  loss: 1.1588 (1.1018)  acc1: 71.0784 (75.0897)  acc5: 94.6078 (93.8486)  time: 0.8718  data: 0.4067  max mem: 28602
Test:  [ 50/123]  eta: 0:01:19  loss: 1.0922 (1.1195)  acc1: 76.2255 (74.9856)  acc5: 94.3627 (93.5361)  time: 0.9189  data: 0.4544  max mem: 28602
Test:  [ 60/123]  eta: 0:01:05  loss: 1.2845 (1.2074)  acc1: 66.9118 (73.0714)  acc5: 89.2157 (92.3698)  time: 0.8469  data: 0.3798  max mem: 28602
Test:  [ 70/123]  eta: 0:00:54  loss: 1.5753 (1.2475)  acc1: 63.7255 (72.2798)  acc5: 86.0294 (91.6977)  time: 0.8512  data: 0.3821  max mem: 28602
Test:  [ 80/123]  eta: 0:00:42  loss: 1.5694 (1.3027)  acc1: 62.0098 (71.0694)  acc5: 85.2941 (90.8406)  time: 0.8466  data: 0.3809  max mem: 28602
Test:  [ 90/123]  eta: 0:00:32  loss: 1.6086 (1.3369)  acc1: 64.7059 (70.4563)  acc5: 85.2941 (90.3011)  time: 0.8310  data: 0.3615  max mem: 28602
Test:  [100/123]  eta: 0:00:22  loss: 1.6088 (1.3703)  acc1: 64.7059 (69.8020)  acc5: 85.2941 (89.7884)  time: 0.8350  data: 0.3691  max mem: 28602
Test:  [110/123]  eta: 0:00:12  loss: 1.6386 (1.4036)  acc1: 63.7255 (69.1000)  acc5: 85.0490 (89.3680)  time: 0.8490  data: 0.3931  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.4200 (1.4010)  acc1: 65.1961 (69.0407)  acc5: 87.7451 (89.4709)  time: 0.7843  data: 0.3444  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.4073 (1.3953)  acc1: 67.4020 (69.1740)  acc5: 88.8393 (89.5180)  time: 0.7716  data: 0.3444  max mem: 28602
Test: Total time: 0:01:54 (0.9273 s / it)
* Acc@1 69.174 Acc@5 89.518 loss 1.395
Accuracy of the network on the 50000 test images: 69.2%
Max accuracy: 69.28%
Epoch: [79]  [   0/1255]  eta: 3:56:20  lr: 0.001120  loss: 4.2297 (4.2297)  time: 11.2990  data: 9.5850  max mem: 28602
Epoch: [79]  [ 100/1255]  eta: 0:29:36  lr: 0.001120  loss: 3.7988 (3.8674)  time: 1.4576  data: 0.0004  max mem: 28602
Epoch: [79]  [ 200/1255]  eta: 0:26:13  lr: 0.001120  loss: 4.1947 (3.8883)  time: 1.4521  data: 0.0004  max mem: 28602
Epoch: [79]  [ 300/1255]  eta: 0:23:28  lr: 0.001120  loss: 3.7617 (3.8813)  time: 1.4466  data: 0.0004  max mem: 28602
Epoch: [79]  [ 400/1255]  eta: 0:20:54  lr: 0.001120  loss: 3.6608 (3.8779)  time: 1.4271  data: 0.0004  max mem: 28602
Epoch: [79]  [ 500/1255]  eta: 0:18:24  lr: 0.001120  loss: 4.1592 (3.8808)  time: 1.4429  data: 0.0004  max mem: 28602
Epoch: [79]  [ 600/1255]  eta: 0:15:55  lr: 0.001120  loss: 4.0322 (3.8884)  time: 1.4400  data: 0.0004  max mem: 28602
Epoch: [79]  [ 700/1255]  eta: 0:13:28  lr: 0.001120  loss: 4.2286 (3.8960)  time: 1.4256  data: 0.0004  max mem: 28602
Epoch: [79]  [ 800/1255]  eta: 0:11:01  lr: 0.001120  loss: 3.9174 (3.9001)  time: 1.4378  data: 0.0004  max mem: 28602
Epoch: [79]  [ 900/1255]  eta: 0:08:35  lr: 0.001120  loss: 3.9331 (3.8936)  time: 1.4419  data: 0.0004  max mem: 28602
Epoch: [79]  [1000/1255]  eta: 0:06:09  lr: 0.001120  loss: 3.6338 (3.8919)  time: 1.4254  data: 0.0004  max mem: 28602
Epoch: [79]  [1100/1255]  eta: 0:03:44  lr: 0.001120  loss: 4.1901 (3.8940)  time: 1.4326  data: 0.0004  max mem: 28602
Epoch: [79]  [1200/1255]  eta: 0:01:19  lr: 0.001120  loss: 4.2385 (3.8884)  time: 1.4096  data: 0.0004  max mem: 28602
Epoch: [79]  [1254/1255]  eta: 0:00:01  lr: 0.001120  loss: 3.9753 (3.8903)  time: 1.3971  data: 0.0009  max mem: 28602
Epoch: [79] Total time: 0:30:12 (1.4445 s / it)
Averaged stats: lr: 0.001120  loss: 3.9753 (3.8944)
Test:  [  0/123]  eta: 0:24:58  loss: 0.9686 (0.9686)  acc1: 78.6765 (78.6765)  acc5: 94.3627 (94.3627)  time: 12.1841  data: 11.7203  max mem: 28602
Test:  [ 10/123]  eta: 0:03:28  loss: 1.2081 (1.0623)  acc1: 72.5490 (75.8467)  acc5: 92.8922 (93.0036)  time: 1.8441  data: 1.4088  max mem: 28602
Test:  [ 20/123]  eta: 0:02:20  loss: 1.0746 (1.0108)  acc1: 74.0196 (77.3459)  acc5: 92.4020 (93.3473)  time: 0.8183  data: 0.3865  max mem: 28602
Test:  [ 30/123]  eta: 0:01:48  loss: 1.1001 (1.0661)  acc1: 73.5294 (75.3716)  acc5: 93.6275 (93.4772)  time: 0.7991  data: 0.3618  max mem: 28602
Test:  [ 40/123]  eta: 0:01:32  loss: 1.1099 (1.0457)  acc1: 72.7941 (75.8608)  acc5: 94.1177 (93.8845)  time: 0.8502  data: 0.4088  max mem: 28602
Test:  [ 50/123]  eta: 0:01:17  loss: 1.0329 (1.0680)  acc1: 77.2059 (75.6969)  acc5: 93.6275 (93.5361)  time: 0.8859  data: 0.4446  max mem: 28602
Test:  [ 60/123]  eta: 0:01:04  loss: 1.3642 (1.1561)  acc1: 67.8922 (73.6580)  acc5: 89.4608 (92.4060)  time: 0.8335  data: 0.3951  max mem: 28602
Test:  [ 70/123]  eta: 0:00:52  loss: 1.5140 (1.1951)  acc1: 66.4216 (72.9736)  acc5: 87.2549 (91.8117)  time: 0.8311  data: 0.3955  max mem: 28602
Test:  [ 80/123]  eta: 0:00:42  loss: 1.4983 (1.2501)  acc1: 64.7059 (71.9075)  acc5: 86.2745 (91.0282)  time: 0.8735  data: 0.4356  max mem: 28602
Test:  [ 90/123]  eta: 0:00:31  loss: 1.5829 (1.2883)  acc1: 63.9706 (71.0919)  acc5: 85.5392 (90.4573)  time: 0.8438  data: 0.4030  max mem: 28602
Test:  [100/123]  eta: 0:00:21  loss: 1.5829 (1.3180)  acc1: 64.7059 (70.5009)  acc5: 85.5392 (89.9898)  time: 0.7843  data: 0.3446  max mem: 28602
Test:  [110/123]  eta: 0:00:12  loss: 1.6564 (1.3532)  acc1: 61.5196 (69.6101)  acc5: 84.8039 (89.5226)  time: 0.8293  data: 0.3885  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.5718 (1.3495)  acc1: 61.5196 (69.6362)  acc5: 87.7451 (89.6431)  time: 0.7858  data: 0.3498  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.4165 (1.3446)  acc1: 68.1373 (69.7760)  acc5: 88.8393 (89.6900)  time: 0.7734  data: 0.3497  max mem: 28602
Test: Total time: 0:01:52 (0.9110 s / it)
* Acc@1 69.776 Acc@5 89.690 loss 1.345
Accuracy of the network on the 50000 test images: 69.8%
Max accuracy: 69.78%
Epoch: [80]  [   0/1255]  eta: 3:43:39  lr: 0.001115  loss: 4.3995 (4.3995)  time: 10.6925  data: 9.0243  max mem: 28602
Epoch: [80]  [ 100/1255]  eta: 0:29:21  lr: 0.001115  loss: 3.9565 (3.8390)  time: 1.4308  data: 0.0003  max mem: 28602
Epoch: [80]  [ 200/1255]  eta: 0:25:56  lr: 0.001115  loss: 3.8140 (3.8901)  time: 1.4302  data: 0.0004  max mem: 28602
Epoch: [80]  [ 300/1255]  eta: 0:23:11  lr: 0.001115  loss: 4.2134 (3.8912)  time: 1.4242  data: 0.0004  max mem: 28602
Epoch: [80]  [ 400/1255]  eta: 0:20:37  lr: 0.001115  loss: 3.4728 (3.8840)  time: 1.4200  data: 0.0003  max mem: 28602
Epoch: [80]  [ 500/1255]  eta: 0:18:08  lr: 0.001115  loss: 3.9528 (3.8830)  time: 1.4133  data: 0.0003  max mem: 28602
Epoch: [80]  [ 600/1255]  eta: 0:15:42  lr: 0.001115  loss: 4.0665 (3.8777)  time: 1.4235  data: 0.0003  max mem: 28602
Epoch: [80]  [ 700/1255]  eta: 0:13:16  lr: 0.001115  loss: 3.9312 (3.8610)  time: 1.4238  data: 0.0003  max mem: 28602
Epoch: [80]  [ 800/1255]  eta: 0:10:52  lr: 0.001115  loss: 3.8033 (3.8552)  time: 1.4169  data: 0.0004  max mem: 28602
Epoch: [80]  [ 900/1255]  eta: 0:08:28  lr: 0.001115  loss: 3.7798 (3.8619)  time: 1.4320  data: 0.0003  max mem: 28602
Epoch: [80]  [1000/1255]  eta: 0:06:05  lr: 0.001115  loss: 4.0381 (3.8777)  time: 1.4207  data: 0.0003  max mem: 28602
Epoch: [80]  [1100/1255]  eta: 0:03:41  lr: 0.001115  loss: 4.0003 (3.8718)  time: 1.4245  data: 0.0003  max mem: 28602
Epoch: [80]  [1200/1255]  eta: 0:01:18  lr: 0.001115  loss: 3.9516 (3.8747)  time: 1.3806  data: 0.0003  max mem: 28602
Epoch: [80]  [1254/1255]  eta: 0:00:01  lr: 0.001115  loss: 3.8932 (3.8773)  time: 1.3757  data: 0.0007  max mem: 28602
Epoch: [80] Total time: 0:29:51 (1.4275 s / it)
Averaged stats: lr: 0.001115  loss: 3.8932 (3.8854)
Test:  [  0/123]  eta: 0:24:17  loss: 0.9453 (0.9453)  acc1: 78.9216 (78.9216)  acc5: 94.8529 (94.8529)  time: 11.8512  data: 11.4135  max mem: 28602
Test:  [ 10/123]  eta: 0:03:22  loss: 1.0849 (1.0153)  acc1: 76.4706 (77.0499)  acc5: 93.8726 (93.8057)  time: 1.7933  data: 1.3699  max mem: 28602
Test:  [ 20/123]  eta: 0:02:16  loss: 0.9929 (0.9744)  acc1: 77.6961 (78.3613)  acc5: 93.8726 (94.0243)  time: 0.7999  data: 0.3779  max mem: 28602
Test:  [ 30/123]  eta: 0:01:46  loss: 1.1178 (1.0432)  acc1: 72.3039 (75.8460)  acc5: 94.1177 (93.7619)  time: 0.7897  data: 0.3670  max mem: 28602
Test:  [ 40/123]  eta: 0:01:30  loss: 1.1178 (1.0268)  acc1: 70.0980 (76.2614)  acc5: 94.6078 (93.9981)  time: 0.8447  data: 0.4193  max mem: 28602
Test:  [ 50/123]  eta: 0:01:15  loss: 1.0236 (1.0436)  acc1: 75.7353 (75.8506)  acc5: 94.3627 (93.7140)  time: 0.8649  data: 0.4409  max mem: 28602
Test:  [ 60/123]  eta: 0:01:02  loss: 1.3743 (1.1399)  acc1: 67.8922 (73.7504)  acc5: 88.7255 (92.4060)  time: 0.7891  data: 0.3703  max mem: 28602
Test:  [ 70/123]  eta: 0:00:51  loss: 1.5723 (1.1841)  acc1: 62.5000 (72.7354)  acc5: 86.5196 (91.8186)  time: 0.8181  data: 0.3942  max mem: 28602
Test:  [ 80/123]  eta: 0:00:40  loss: 1.5946 (1.2445)  acc1: 64.2157 (71.5565)  acc5: 84.5588 (90.9344)  time: 0.8244  data: 0.4026  max mem: 28602
Test:  [ 90/123]  eta: 0:00:30  loss: 1.5946 (1.2802)  acc1: 63.4804 (70.8010)  acc5: 84.8039 (90.4089)  time: 0.7774  data: 0.3616  max mem: 28602
Test:  [100/123]  eta: 0:00:21  loss: 1.5902 (1.3128)  acc1: 63.9706 (70.1733)  acc5: 85.5392 (89.9291)  time: 0.7743  data: 0.3531  max mem: 28602
Test:  [110/123]  eta: 0:00:11  loss: 1.6300 (1.3462)  acc1: 62.9902 (69.4113)  acc5: 85.5392 (89.5116)  time: 0.8132  data: 0.3873  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.4583 (1.3450)  acc1: 62.7451 (69.3425)  acc5: 87.7451 (89.6168)  time: 0.7636  data: 0.3429  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.3819 (1.3384)  acc1: 66.4216 (69.4820)  acc5: 89.7059 (89.6800)  time: 0.7539  data: 0.3429  max mem: 28602
Test: Total time: 0:01:48 (0.8835 s / it)
* Acc@1 69.482 Acc@5 89.680 loss 1.338
Accuracy of the network on the 50000 test images: 69.5%
Max accuracy: 69.78%
Epoch: [81]  [   0/1255]  eta: 3:56:28  lr: 0.001110  loss: 2.5550 (2.5550)  time: 11.3058  data: 9.8573  max mem: 28602
Epoch: [81]  [ 100/1255]  eta: 0:29:14  lr: 0.001110  loss: 4.0299 (3.7763)  time: 1.4112  data: 0.0003  max mem: 28602
Epoch: [81]  [ 200/1255]  eta: 0:25:44  lr: 0.001110  loss: 3.7226 (3.8253)  time: 1.4099  data: 0.0003  max mem: 28602
Epoch: [81]  [ 300/1255]  eta: 0:23:01  lr: 0.001110  loss: 3.8835 (3.8086)  time: 1.4102  data: 0.0003  max mem: 28602
Epoch: [81]  [ 400/1255]  eta: 0:20:29  lr: 0.001110  loss: 3.8911 (3.8042)  time: 1.4131  data: 0.0003  max mem: 28602
Epoch: [81]  [ 500/1255]  eta: 0:18:02  lr: 0.001110  loss: 4.0994 (3.8125)  time: 1.4114  data: 0.0003  max mem: 28602
Epoch: [81]  [ 600/1255]  eta: 0:15:36  lr: 0.001110  loss: 3.7975 (3.8263)  time: 1.4136  data: 0.0003  max mem: 28602
Epoch: [81]  [ 700/1255]  eta: 0:13:12  lr: 0.001110  loss: 3.8346 (3.8337)  time: 1.4094  data: 0.0003  max mem: 28602
Epoch: [81]  [ 800/1255]  eta: 0:10:49  lr: 0.001110  loss: 3.9311 (3.8429)  time: 1.4065  data: 0.0003  max mem: 28602
Epoch: [81]  [ 900/1255]  eta: 0:08:26  lr: 0.001110  loss: 4.0625 (3.8435)  time: 1.4297  data: 0.0003  max mem: 28602
Epoch: [81]  [1000/1255]  eta: 0:06:03  lr: 0.001110  loss: 3.8373 (3.8479)  time: 1.4090  data: 0.0003  max mem: 28602
Epoch: [81]  [1100/1255]  eta: 0:03:40  lr: 0.001110  loss: 4.1302 (3.8544)  time: 1.4158  data: 0.0003  max mem: 28602
Epoch: [81]  [1200/1255]  eta: 0:01:18  lr: 0.001110  loss: 3.5216 (3.8499)  time: 1.4145  data: 0.0003  max mem: 28602
Epoch: [81]  [1254/1255]  eta: 0:00:01  lr: 0.001110  loss: 3.9864 (3.8525)  time: 1.3840  data: 0.0007  max mem: 28602
Epoch: [81] Total time: 0:29:44 (1.4221 s / it)
Averaged stats: lr: 0.001110  loss: 3.9864 (3.8575)
Test:  [  0/123]  eta: 0:23:59  loss: 0.8675 (0.8675)  acc1: 78.9216 (78.9216)  acc5: 96.0784 (96.0784)  time: 11.7013  data: 11.2424  max mem: 28602
Test:  [ 10/123]  eta: 0:03:19  loss: 1.0763 (1.0160)  acc1: 75.0000 (76.2032)  acc5: 93.3824 (93.7166)  time: 1.7645  data: 1.3464  max mem: 28602
Test:  [ 20/123]  eta: 0:02:13  loss: 1.0042 (0.9875)  acc1: 77.6961 (77.5560)  acc5: 93.3824 (93.6275)  time: 0.7775  data: 0.3563  max mem: 28602
Test:  [ 30/123]  eta: 0:01:44  loss: 1.0992 (1.0424)  acc1: 73.2843 (75.5139)  acc5: 93.8726 (93.5958)  time: 0.7739  data: 0.3469  max mem: 28602
Test:  [ 40/123]  eta: 0:01:29  loss: 1.1066 (1.0121)  acc1: 71.8137 (76.3391)  acc5: 94.1177 (94.0758)  time: 0.8466  data: 0.4216  max mem: 28602
Test:  [ 50/123]  eta: 0:01:15  loss: 0.9782 (1.0342)  acc1: 75.2451 (75.7834)  acc5: 94.1177 (93.8053)  time: 0.8767  data: 0.4509  max mem: 28602
Test:  [ 60/123]  eta: 0:01:02  loss: 1.2023 (1.1320)  acc1: 68.1373 (73.7102)  acc5: 88.2353 (92.4783)  time: 0.8226  data: 0.4000  max mem: 28602
Test:  [ 70/123]  eta: 0:00:51  loss: 1.5334 (1.1854)  acc1: 62.9902 (72.6353)  acc5: 86.0294 (91.8186)  time: 0.8486  data: 0.4334  max mem: 28602
Test:  [ 80/123]  eta: 0:00:40  loss: 1.6729 (1.2457)  acc1: 62.0098 (71.4143)  acc5: 85.0490 (90.9768)  time: 0.8211  data: 0.4033  max mem: 28602
Test:  [ 90/123]  eta: 0:00:30  loss: 1.5878 (1.2816)  acc1: 62.2549 (70.5963)  acc5: 85.0490 (90.5274)  time: 0.7806  data: 0.3561  max mem: 28602
Test:  [100/123]  eta: 0:00:21  loss: 1.5694 (1.3127)  acc1: 65.1961 (70.1757)  acc5: 85.7843 (90.0311)  time: 0.7848  data: 0.3606  max mem: 28602
Test:  [110/123]  eta: 0:00:11  loss: 1.6358 (1.3485)  acc1: 64.9510 (69.5041)  acc5: 84.8039 (89.5513)  time: 0.8261  data: 0.4028  max mem: 28602
Test:  [120/123]  eta: 0:00:02  loss: 1.4611 (1.3474)  acc1: 64.4608 (69.5572)  acc5: 87.2549 (89.5884)  time: 0.7784  data: 0.3637  max mem: 28602
Test:  [122/123]  eta: 0:00:00  loss: 1.4573 (1.3424)  acc1: 66.6667 (69.6920)  acc5: 88.9706 (89.6500)  time: 0.7664  data: 0.3636  max mem: 28602
Test: Total time: 0:01:49 (0.8880 s / it)
* Acc@1 69.692 Acc@5 89.650 loss 1.342
Accuracy of the network on the 50000 test images: 69.7%
Max accuracy: 69.78%
Epoch: [82]  [   0/1255]  eta: 4:02:44  lr: 0.001105  loss: 2.7093 (2.7093)  time: 11.6049  data: 10.1749  max mem: 28602
Epoch: [82]  [ 100/1255]  eta: 0:29:20  lr: 0.001105  loss: 3.8137 (3.8416)  time: 1.4155  data: 0.0003  max mem: 28602
Epoch: [82]  [ 200/1255]  eta: 0:25:49  lr: 0.001105  loss: 4.0492 (3.8558)  time: 1.4105  data: 0.0003  max mem: 28602
Epoch: [82]  [ 300/1255]  eta: 0:23:05  lr: 0.001105  loss: 4.0066 (3.8207)  time: 1.4147  data: 0.0003  max mem: 28602
